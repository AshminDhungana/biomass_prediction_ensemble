{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e548bd",
   "metadata": {},
   "source": [
    "# ðŸŒ¾ Image2Biomass Prediction\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements a **6-model ensemble learning system** which is used to predict dry biomass  by combining  imagery and environmental tabular features, which is  **Cheap, affordable and better** then other large models.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "- **Vision Models** (3): ViT-Base, ResNet-50, DenseNet-121 for image patch processing  \n",
    "- **Species Classification Model**: ViT-Base (16-class classifier) for predicting pasture species from imagery\n",
    "- **Tabular Model**: XGBoost trained on environmental and spectral features  \n",
    "- **Meta-Learner**: Fully connected neural network that fuses base model predictions and tabular features  \n",
    "\n",
    "```\n",
    "                            System Parameter Breakdown:\n",
    "                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                            1. ViT-Base (Biomass):      86.6M\n",
    "                            2. ResNet-50 (Biomass):     25.6M\n",
    "                            3. DenseNet-121 (Biomass):  8.0M\n",
    "                            4. Species Classifier:      86.6M\n",
    "                            5. Meta-Learner:            5.1K\n",
    "                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                            Total Parameters:          ~207M\n",
    "\n",
    "```\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "- **Input images**: 2000Ã—1000 pixel  images  \n",
    "- **Patch extraction**: Splits each image into 8 patches (500Ã—500 pixels), resized to 224Ã—224 for model inputs  \n",
    "- **Tabular features**: 29-dimensional vector combining:\n",
    "  - Numeric features: NDVI, height, month, day of year, quarter (normalized)\n",
    "  - Categorical features: state (4 dims), species (15 dims), target type (5 dims)\n",
    "- **Targets**: Predicts 5 biomass target types â€” Dry_Green_g, Dry_Dead_g, Dry_Clover_g, Dry_Total_g, GDM_g  \n",
    "\n",
    "### Species Classification Model\n",
    "\n",
    "The **Species ViT** is a ViT-Base model trained for 15-class species classification:\n",
    "\n",
    "- **Input**: Same 8 image patches as biomass models (224Ã—224 each)\n",
    "- **Output**: Species class prediction (15 unique species)\n",
    "- **Purpose**: Predicts pasture species from satellite imagery for intelligent feature fallback\n",
    "- **Usage**: During test inference with missing features, species prediction improves fallback feature generation accuracy (Level 1 , 2 & 3 fallback levels)\n",
    "- **Training**: Trained on training set species labels, achieves high accuracy to ensure reliable predictions\n",
    "\n",
    "### Key Features\n",
    "\n",
    "âœ… **6-model ensemble** (3 vision + 1 species + 1 tabular + 1 meta-learner)  \n",
    "âœ… **Intelligent multi-level fallback** for missing test features using species prediction and statistical inference  \n",
    "âœ… **Species-informed feature generation** â€” Uses predicted species to improve tabular feature accuracy in test data  \n",
    "âœ… **Patch-level image processing** to capture spatial detail and improve robustness  \n",
    "âœ… **GPU memory optimization and model offloading** for efficient training  \n",
    "âœ… **Comprehensive logging** for detailed training and evaluation tracking  \n",
    "âœ… **Weighted RÂ² loss** optimized per competition evaluation metrics (0.5 for Dry_Total_g, 0.2 for GDM, 0.1 for others)  \n",
    "âœ… **Cross-validation on 85/15 train/val split** to monitor generalization  \n",
    "âœ… **Robust ensemble averaging and meta-learning** for final biomass prediction  \n",
    "\n",
    "### Data Pipeline\n",
    "\n",
    "```\n",
    "    \n",
    "                                            Test Image\n",
    "                                                â†“\n",
    "                            Load Image â†’ Crop 8 Patches (500Ã—500 â†’ 224Ã—224)\n",
    "                                                â†“\n",
    "                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                â”‚ Species Model Prediction        â”‚\n",
    "                                â”‚ (15 classes: pasture species)   â”‚\n",
    "                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â†“ (species label)\n",
    "                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                â”‚ Intelligent Feature Fallback    â”‚\n",
    "                                â”‚ Level 1: Random state + species â”‚\n",
    "                                â”‚ Level 2: Exact sample ID match  â”‚\n",
    "                                â”‚ Level 3: Image ID + species     â”‚\n",
    "                                â”‚ Level 4: Statistical generation â”‚\n",
    "                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â†“ (tabular features)\n",
    "                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                            â”‚ Base Models                             â”‚\n",
    "                            â”‚ - Vision: ViT, ResNet, DenseNet (X pred)â”‚\n",
    "                            â”‚ - Tabular: XGBoost (1 pred)             â”‚\n",
    "                            â”‚ Outputs: 1 predictions per model        â”‚\n",
    "                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                         â†“ (X base predictions)\n",
    "                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                            â”‚ Meta-Learner                            â”‚\n",
    "                            â”‚ Input: X predictions + 29 features      â”‚\n",
    "                            â”‚ Output: 1 final prediction              â”‚\n",
    "                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â†“\n",
    "                                Final Biomass Prediction (grams)\n",
    "\n",
    "```\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "- Optimizes globally weighted RÂ² metric reflecting competition's scoring  \n",
    "- Species model improves test feature fallback accuracy by providing accurate species labels\n",
    "- Ensemble diversity (vision + tabular + species) provides robustness  \n",
    "- Meta-learner learns optimal combination of base model predictions  \n",
    "- Comprehensive validation monitoring with early stopping prevents overfitting  \n",
    "\n",
    "### Output Format\n",
    "\n",
    "- **File**: CSV with `sample_id` and `target` columns\n",
    "- **Rows**: 5 rows (one per target type: Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g)\n",
    "- **Values**: Biomass predictions in grams (float, non-negative, rounded to 3 decimal places)\n",
    "- **Evaluation**: Weighted RÂ² computed globally across all rows combined\n",
    "\n",
    "---\n",
    "\n",
    "**Status**: âœ… Ready | **Models**: 6 | **Features**: 29 | **Targets**: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bdab4d",
   "metadata": {},
   "source": [
    "##  1: IMPORTS & CONFIGURATION\n",
    "\n",
    "This cell initializes all required dependencies for the complete pipeline.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "#### Data Processing & ML\n",
    "- `pandas`, `numpy`: Data manipulation\n",
    "- `scikit-learn`: Preprocessing, metrics, splitting\n",
    "- `xgboost`: Tree-based ensemble model\n",
    "\n",
    "#### Deep Learning\n",
    "- `torch`, `torchvision`: PyTorch framework\n",
    "- `timm`: Vision model library (ViT, ResNet, DenseNet)\n",
    "- `torch.nn.functional`: Neural network operations\n",
    "\n",
    "#### Visualization & Logging\n",
    "- `matplotlib`, `seaborn`: Data visualization\n",
    "- `PIL`: Image processing\n",
    "- `logging`, `tqdm`: Progress tracking\n",
    "- `cv2`: Computer vision operations\n",
    "\n",
    "#### Utilities\n",
    "- `pathlib`: File path management\n",
    "- `json`, `pickle`: Serialization\n",
    "- `shutil`, `gc`: System utilities\n",
    "- `datetime`: Timestamps\n",
    "- `socket`: Network connectivity checks\n",
    "\n",
    "### Environment Detection\n",
    "\n",
    "- GPU availability check\n",
    "- Device assignment (CUDA/CPU)\n",
    "- Random seed initialization for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import socket\n",
    "import pickle\n",
    "import joblib\n",
    "import shutil\n",
    "import random \n",
    "import zipfile\n",
    "import logging\n",
    "import warnings\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['OPENCV_LOG_LEVEL'] = 'OFF'\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from timm import create_model\n",
    "import torch.nn.functional as FF\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50, densenet121\n",
    "\n",
    "# Progress tracking\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats import trim_mean\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.ndimage import laplace, gaussian_filter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logger = logging.getLogger(__name__)\n",
    "for h in logger.handlers[:]:\n",
    "    logger.removeHandler(h)\n",
    "\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "log_file_path = \"/kaggle/working/pipeline.log\" \n",
    "file_handler = logging.FileHandler(log_file_path, mode=\"w\", encoding=\"utf-8\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"PASTURE BIOMASS PREDICTION - 6 MODEL ENSEMBLE PIPELINE\")\n",
    "logger.info(\"=\" * 80)\n",
    "start_time = datetime.now()\n",
    "logger.info(f\"Execution started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "logger.info(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4aaebd",
   "metadata": {},
   "source": [
    "## 2: PATHS AND CONFIGURATION\n",
    "\n",
    "**Purpose**: Define directory structure, file paths, and all hyperparameters.\n",
    "\n",
    "\n",
    "**Image Configuration**:\n",
    "\n",
    "| Parameter | Value | Purpose |\n",
    "|-----------|-------|---------|\n",
    "| Image Size | 2000Ã—1000 px | Raw  image |\n",
    "| Patch Size | 500Ã—500 px | Crop dimensions |\n",
    "| Grid Layout | 4 horizontal Ã— 2 vertical | Total 8 patches per image |\n",
    "| Model Input | 224Ã—224 px | Vision model standard |\n",
    "| Total Patches Per Image | 8 | Spatial diversity |\n",
    "\n",
    "**Training Hyperparameters**:\n",
    "\n",
    "| Setting | Value | Notes |\n",
    "|---------|-------|-------|\n",
    "| Batch Size | 2 images | = 16 patches per batch |\n",
    "| Learning Rate | 1e-4 to 5e-4 | Model-specific |\n",
    "| Epochs | 50 (ViT/ResNet/DenseNet), 100 (XGBoost/Meta) | Training iterations |\n",
    "| Dropout | 0.1-0.3 | Regularization |\n",
    "| Weight Decay | 0.05 | L2 regularization in AdamW |\n",
    "| Early Stopping | patience=20 | Stop if no improvement |\n",
    "| Gradient Clipping | 1.0 | Stability |\n",
    "| Optimizer | AdamW | Weight decay support |\n",
    "\n",
    "**Target Importance Weighting** (Weighted RÂ²):\n",
    "```\n",
    "Dry_Total_g:   0.5  â† Primary metric (50%)\n",
    "GDM_g:         0.2  â† Secondary (20%)\n",
    "Dry_Green_g:   0.1  â† Supporting (10%)\n",
    "Dry_Dead_g:    0.1  â† Supporting (10%)\n",
    "Dry_Clover_g:  0.1  â† Supporting (10%)\n",
    "```\n",
    "\n",
    "**Output**: Configuration dictionary logged with all settings, device detected, paths created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4279056",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define directory structure\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m BASE_DIR = \u001b[43mPath\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m./\u001b[39m\u001b[33m'\u001b[39m).resolve()\n\u001b[32m      3\u001b[39m DATA_DIR = BASE_DIR / \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m MODELS_DIR = BASE_DIR / \u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Define directory structure\n",
    "BASE_DIR = Path('./').resolve()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "OUTPUTS_DIR = BASE_DIR / 'outputs'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "RAW_DATA_DIR = Path('input_data/')\n",
    "ASSETS = Path('assets/')\n",
    "\n",
    "# Data file paths\n",
    "TRAIN_CSV = RAW_DATA_DIR / 'train.csv'\n",
    "TEST_CSV = RAW_DATA_DIR / 'test.csv'\n",
    "SYN_CSV = OUTPUTS_DIR / 'train_synthetic_matching.csv'\n",
    "SAMPLE_SUBMISSION = RAW_DATA_DIR / 'sample_submission.csv'\n",
    "\n",
    "# Model checkpoint paths\n",
    "VIT_CHECKPOINT = MODELS_DIR / 'vit_best.pth'\n",
    "RESNET_CHECKPOINT = MODELS_DIR / 'resnet_best.pth'\n",
    "DENSENET_CHECKPOINT = MODELS_DIR / 'densenet_best.pth'\n",
    "XGBOOST_CHECKPOINT = MODELS_DIR / 'xgboost_best.pkl'\n",
    "METALEARNER_CHECKPOINT = MODELS_DIR / 'metalearner_best.pth'\n",
    "SPECIES_VIT_CHECKPOINT = MODELS_DIR / 'species_best.pth'\n",
    "\n",
    "# Output paths\n",
    "SUBMISSION_PATH = BASE_DIR / 'submission.csv'\n",
    "METRICS_PATH = OUTPUTS_DIR / 'metrics.json'\n",
    "\n",
    "TOTAL_TABULAR_DIM = 30\n",
    "MAX_TARGET = 200.0\n",
    "\n",
    "# Configuration constants\n",
    "CONFIG = {\n",
    "  \n",
    "    'image_width': 2000,          \n",
    "    'image_height': 1000,         \n",
    "    'patch_size': 500,            \n",
    "    'patches_horizontal': 4,      \n",
    "    'patches_vertical': 2,        \n",
    "    'num_patches': 8,             \n",
    "\n",
    "    'random_seed': 42,\n",
    "    'numpy_seed': 42,\n",
    "    'torch_seed': 42,\n",
    "    'tensorflow_seed': 42,\n",
    "    \n",
    "    # Deep Learning hyperparameters\n",
    "    'model_input_size': 224,     \n",
    "    'batch_size': 8,              \n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "    \n",
    "    # Training parameters\n",
    "    'vit_epochs': 15,  #15-15 Total 30   \n",
    "    'resnet_epochs': 15, #15-15 Total 30 \n",
    "    'densenet_epochs': 15, #15-15 Total 30\n",
    "    'metalearner_epochs': 8, #8\n",
    "    'metalearner_repeat' : 10, #10\n",
    "\n",
    "    #  Species Model Configuration\n",
    "    'species_vit_epochs': 15,  #15-15 Total 30\n",
    "    'species_vit_lr': 2e-4,\n",
    "    'num_species_classes': 16,  \n",
    "    'meta_weight_decay': 0.01,    \n",
    "    'meta_dropout_rate': 0.15,  \n",
    "    \n",
    "    \"use_mil\": True,   # Toggle MIL \n",
    "    \"mil_dropout\": 0.25,         \n",
    "    \n",
    "    'vit_lr': 2e-4,\n",
    "    'resnet_lr': 2e-4,\n",
    "    'densenet_lr': 2e-4,\n",
    "    'metalearner_lr': 1e-3,\n",
    "    \n",
    "    'weight_decay': 0.03,\n",
    "    'gradient_clip': 1.0,\n",
    "    'early_stopping_patience': 5,\n",
    "\n",
    "    # XGBoost parameters\n",
    "    'xgb_n_estimators': 1000,            \n",
    "    'xgb_max_depth': 4,                   \n",
    "    'xgb_learning_rate': 0.05,             \n",
    "    'xgb_subsample': 0.75,                 \n",
    "    'xgb_colsample_bytree': 0.75,          \n",
    "    'xgb_min_child_weight': 5,             \n",
    "    'xgb_reg_alpha': 0.5,                  \n",
    "    'xgb_reg_lambda': 1.5,                 \n",
    "    'xgb_gamma': 1.0,                      \n",
    "    'xgb_early_stopping_rounds': 50,       \n",
    "     \n",
    "\n",
    "    # Data split\n",
    "    'val_split': 0.15,\n",
    "    'test_size_for_split': 0.15,\n",
    "    \n",
    "    # Weighted RÂ² weights\n",
    "    'r2_weights': {\n",
    "        'Dry_Green_g': 0.1,\n",
    "        'Dry_Dead_g': 0.1,\n",
    "        'Dry_Clover_g': 0.1,\n",
    "        'GDM_g': 0.2,\n",
    "        'Dry_Total_g': 0.5,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR, OUTPUTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"âœ“ Directory ready: {directory}\")\n",
    "    \n",
    "# Device detection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    logger.info(f\"âœ“ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    logger.info(\"âš  GPU not available, using CPU\")\n",
    "\n",
    "CONFIG['xgb_noise_scale'] = 0.05      \n",
    "CONFIG['xgb_augment_rounds'] = 2\n",
    "CONFIG['dry_total_tolerance'] = 0.1\n",
    "CONFIG['device'] = device\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(CONFIG['numpy_seed'])\n",
    "torch.manual_seed(CONFIG['torch_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(CONFIG['torch_seed'])\n",
    "\n",
    "logger.info(\"âœ“ Paths and configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c707e",
   "metadata": {},
   "source": [
    "## 3: EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "**Purpose**: Load, explore, analyze data, and build intelligent lookup tables for test feature fetching.\n",
    "\n",
    "**Dataset Statistics**:\n",
    "\n",
    "| Aspect | Training | Test |\n",
    "|--------|----------|------|\n",
    "| Rows | 1,785 | 5 |\n",
    "| Features | 30 total | 3 (ID, path, target) |\n",
    "| Targets | 5 types | TBD |\n",
    "| Per Target | 357 samples | 1 sample |\n",
    "\n",
    "**Numeric Features (5)**:\n",
    "- `Pre_GSHH_NDVI`: Vegetation greenness [0.0, 1.0]\n",
    "- `Height_Ave_cm`: Pasture height [0, 100] cm\n",
    "- `Month`: Sampling month [1, 12]\n",
    "- `DayOfYear`: Day since Jan 1 [1, 365]\n",
    "- `Quarter`: Season [1, 4]\n",
    "\n",
    "**Categorical Features** (One-Hot Encoded):\n",
    "- `State` (4): NSW, WA, Tasmania, Victoria\n",
    "- `Species` (16): Ryegrass, Clover, Phalaris, Lucerne, etc.\n",
    "- `Target Type` (5): Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g\n",
    "\n",
    "**Total Feature Dimension**: 5 + 4 + 16 + 5 = **30 features**\n",
    "\n",
    "**Target Variables** (5 Biomass Types):\n",
    "\n",
    "| Target | Description | Weight | Typical Range |\n",
    "|--------|-------------|--------|---------------|\n",
    "| Dry_Green_g | Green leaf dry matter | 0.1 | 0-500g |\n",
    "| Dry_Dead_g | Dead plant material | 0.1 | 0-300g |\n",
    "| Dry_Clover_g | Clover dry matter | 0.1 | 0-200g |\n",
    "| GDM_g | Green dry matter | 0.2 | 100-1000g |\n",
    "| Dry_Total_g | Total dry matter | 0.5 | 100-1500g |\n",
    "\n",
    "**Test Data Challenge**:\n",
    "- Test CSV contains only 5 rows with minimal features\n",
    "- Missing: Sampling_Date, State, Species, Pre_GSHH_NDVI, Height_Ave_cm\n",
    "- Solution: Intelligent 4-level fallback feature fetching\n",
    "\n",
    "\n",
    "**Output**: \n",
    "- Data loaded and explored\n",
    "- Lookup tables built for all 4 levels\n",
    "- EDA visualizations saved\n",
    "- Summary statistics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_SPECIES_LIST = [\n",
    "    'Ryegrass_Clover', 'Lucerne', 'SubcloverDalkeith', 'Ryegrass',\n",
    "    'Phalaris_Clover', 'SubcloverLosa', 'Clover', 'Fescue_CrumbWeed',\n",
    "    'Phalaris_Ryegrass_Clover', 'Phalaris', 'WhiteClover', 'Fescue',\n",
    "    'Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed',\n",
    "    'Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass', 'Mixed', 'Nothing']\n",
    "\n",
    "def _normalize_for_vocab(s):\n",
    "    if s is None:\n",
    "        return ''\n",
    "    s = str(s).strip()\n",
    "    if s == '' or s.lower() in ('nan', 'none', 'null'):\n",
    "        return ''\n",
    "    return s\n",
    "\n",
    "def map_to_fixed_species(raw):\n",
    "    \"\"\"\n",
    "    Map arbitrary raw species text to one of FIXED_SPECIES_LIST (returning the exact list item),\n",
    "    or 'Mixed' if no reasonable mapping. Blanks/NA -> 'Nothing'.\n",
    "    \"\"\"\n",
    "    r = _normalize_for_vocab(raw)\n",
    "    if r == '':\n",
    "        return 'Nothing'\n",
    "\n",
    "    # normalized comparable form\n",
    "    rl = re.sub(r'[\\s\\-_\\.]+', ' ', r.strip().lower())\n",
    "\n",
    "    for fs in FIXED_SPECIES_LIST:\n",
    "        fs_norm = re.sub(r'[\\s\\-_\\.]+', ' ', fs.strip().lower())\n",
    "        if rl == fs_norm:\n",
    "            return fs\n",
    "    rl_tokens = set(rl.split())\n",
    "    best = None\n",
    "    best_score = 0\n",
    "    for fs in FIXED_SPECIES_LIST:\n",
    "        fs_norm = re.sub(r'[\\s\\-_\\.]+', ' ', fs.strip().lower())\n",
    "        fs_tokens = set(fs_norm.split())\n",
    "        overlap = len(rl_tokens & fs_tokens)\n",
    "        contain = 1 if (rl in fs_norm or fs_norm in rl) else 0\n",
    "        score = overlap * 10 + contain\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = fs\n",
    "    if best_score > 0:\n",
    "        return best\n",
    "    return 'Mixed'\n",
    "\n",
    "def create_species_lookup_tables(train_df):\n",
    "    \"\"\"\n",
    "    Create species-based lookup tables for Level 2 fallbacks.\n",
    "\n",
    "    Returns a tuple (rows_map, stats_map) where:\n",
    "      - rows_map:  { target_name_norm: { (image_id_norm, species_norm): [row_dict, ...] } }\n",
    "      - stats_map: { target_name_norm: { (image_id_norm, species_norm): {count, mean, std, median} } }\n",
    "    \"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"CREATING SPECIES-BASED LOOKUP TABLES\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    if train_df is None or train_df.shape[0] == 0:\n",
    "        logger.warning(\"create_species_lookup_tables: empty or None train_df provided; returning empty lookups\")\n",
    "        return {}, {}\n",
    "\n",
    "    required_cols = ['sample_id', 'Species', 'target_name', 'target']\n",
    "    for c in required_cols:\n",
    "        if c not in train_df.columns:\n",
    "            logger.warning(f\"create_species_lookup_tables: missing column {c}; filling with defaults\")\n",
    "            if c == 'target':\n",
    "                train_df[c] = pd.to_numeric(train_df.get(c, np.nan), errors='coerce')\n",
    "            else:\n",
    "                train_df[c] = train_df.get(c, '').astype(str)\n",
    "\n",
    "    def _norm_str(x):\n",
    "        s = str(x).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = s.replace('.', '')\n",
    "        return s\n",
    "\n",
    "    def _norm_image_id(sample_id):\n",
    "        try:\n",
    "            return str(sample_id).split('__')[0].strip().lower()\n",
    "        except Exception:\n",
    "            return str(sample_id).strip().lower()\n",
    "            \n",
    "    tmp = train_df.copy()\n",
    "    tmp['_image_id'] = tmp['sample_id'].apply(_norm_image_id).fillna('').astype(str)\n",
    "    if 'Species_canon' in tmp.columns:\n",
    "        tmp['_species_n'] = tmp['Species_canon'].astype(str).fillna('').apply(lambda x: re.sub(r\"[\\s\\-]+\", \"_\", str(x).strip().lower()).replace('.', ''))\n",
    "    else:\n",
    "        tmp['_species_n'] = tmp['Species'].astype(str).fillna('').apply(_norm_str)\n",
    "    \n",
    "    tmp['_target_n'] = tmp['target_name'].astype(str).fillna('').apply(_norm_str)\n",
    "\n",
    "    TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS = {}\n",
    "    for idx, row in tmp.iterrows():\n",
    "        t = row['_target_n']\n",
    "        key = (row['_image_id'], row['_species_n'])\n",
    "        TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS.setdefault(t, {}).setdefault(key, []).append(row.to_dict())\n",
    "\n",
    "    TRAIN_BY_IMAGE_SPECIES_TARGET_STATS = {}\n",
    "    grouped = tmp.groupby(['_target_n', '_image_id', '_species_n'])['target']\n",
    "    for (t, img, sp), ser in grouped:\n",
    "        TRAIN_BY_IMAGE_SPECIES_TARGET_STATS.setdefault(t, {})[(img, sp)] = {\n",
    "            'count': int(ser.count()),\n",
    "            'mean': float(ser.mean()) if ser.count() > 0 else 0.0,\n",
    "            'std': float(ser.std()) if ser.count() > 1 else 0.0,\n",
    "            'median': float(ser.median()) if ser.count() > 0 else 0.0}\n",
    "        \n",
    "    total_keys = sum(len(d) for d in TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS.values())\n",
    "    logger.debug(f\"âœ“ Level 2 species lookup (rows) built: targets={len(TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS)} total_keys={total_keys}\")\n",
    "    for t, combos in TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS.items():\n",
    "        logger.info(f\"  {t}: {len(combos)} (image,species) combos\")\n",
    "\n",
    "    return TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS, TRAIN_BY_IMAGE_SPECIES_TARGET_STATS\n",
    "\n",
    "\n",
    "def load_and_explore_data(TRAINDATA=TRAIN_CSV):\n",
    "    \"\"\"\n",
    "    Load and perform comprehensive EDA on training and test datasets.\n",
    "    Creates intelligent lookup tables for test data feature fetching.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_df, test_df, STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS,\n",
    "                TOTAL_TABULAR_DIM, lookups_dict, original_test_df)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"LOADING DATA WITH INTELLIGENT TEST FEATURE FETCHING\")\n",
    "    logger.info(\"=\"*80)\n",
    "    lookups_dict = {}\n",
    "    \n",
    "    # LOAD DATA\n",
    "    try:\n",
    "        train_df = pd.read_csv(TRAINDATA)\n",
    "        test_df = pd.read_csv(TEST_CSV)\n",
    "        original_test_df = test_df.copy()\n",
    "        logger.debug(f\"âœ“ Training data loaded: {len(train_df)} rows, {len(train_df.columns)} columns\")\n",
    "        logger.info(f\"âœ“ Test data loaded: {len(test_df)} rows, {len(test_df.columns)} columns\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"âœ— Error loading data: {e}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    try:\n",
    "        HEIGHT_MAX = float(train_df['Height_Ave_cm'].max())\n",
    "        if not np.isfinite(HEIGHT_MAX) or HEIGHT_MAX <= 0:\n",
    "            HEIGHT_MAX = 100\n",
    "    except Exception:\n",
    "        HEIGHT_MAX = 100\n",
    "    \n",
    "    # safety margin \n",
    "    HEIGHT_MAX = float(min(max(HEIGHT_MAX, 1.0), 150.0))\n",
    "    \n",
    "    logger.debug(f\"âœ“ Using dynamic HEIGHT_MAX = {HEIGHT_MAX:.2f} cm\")\n",
    "    lookups_dict[\"HEIGHT_MAX\"] = HEIGHT_MAX\n",
    "\n",
    "    # Required train columns\n",
    "    expected_train_cols = ['sample_id','target_name','target','Pre_GSHH_NDVI','Height_Ave_cm','Sampling_Date','State','Species']\n",
    "    for c in expected_train_cols:\n",
    "        if c not in train_df.columns:\n",
    "            logger.warning(f\"Train CSV missing column: {c} â€” filling with default/NA\")\n",
    "            if c in ['Pre_GSHH_NDVI','Height_Ave_cm','target']:\n",
    "                train_df[c] = pd.to_numeric(train_df.get(c, np.nan), errors='coerce')\n",
    "            else:\n",
    "                train_df[c] = train_df.get(c, '').astype(str)\n",
    "\n",
    "    # Expected test columns - fill if missing \n",
    "    expected_test_cols = ['sample_id','image_path','target_name','Sampling_Date','State','Species','Pre_GSHH_NDVI','Height_Ave_cm']\n",
    "    for c in expected_test_cols:\n",
    "        if c not in test_df.columns:\n",
    "            logger.warning(f\"Test CSV missing column: {c}. Will rely on fallback stats.\")\n",
    "            test_df[c] = None\n",
    "\n",
    "    # SHOW CSV STRUCTURE\n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"CSV STRUCTURE ANALYSIS\")\n",
    "    logger.debug(\"=\"*80)\n",
    "    logger.debug(\"\\n[TRAIN CSV]\")\n",
    "    logger.debug(f\"Columns: {list(train_df.columns)}\")\n",
    "    logger.debug(\"\\n[TEST CSV]\")\n",
    "    logger.debug(f\"Columns: {list(test_df.columns)}\")\n",
    "\n",
    "    # EXTRACT TEMPORAL FEATURES (TRAIN ONLY) \n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"EXTRACT TEMPORAL FEATURES (TRAIN ONLY)\")\n",
    "    logger.debug(\"=\"*80)\n",
    "\n",
    "    train_df['Sampling_Date'] = pd.to_datetime(train_df['Sampling_Date'], errors='coerce')\n",
    "    # create Month/DayOfYear/Quarter only if datetime parsed\n",
    "    train_df['Month'] = train_df['Sampling_Date'].dt.month.fillna(1).astype(int)\n",
    "    train_df['DayOfYear'] = train_df['Sampling_Date'].dt.dayofyear.fillna(1).astype(int)\n",
    "    train_df['Quarter'] = train_df['Sampling_Date'].dt.quarter.fillna(1).astype(int)\n",
    "\n",
    "    logger.debug(\"âœ“ Temporal features extracted from TRAIN \")\n",
    "\n",
    "    # Ensure State and Species and target_name exist and normalize (safe)\n",
    "    train_df['State'] = train_df['State'].astype(str).fillna('').str.strip()\n",
    "    train_df['Species'] = train_df['Species'].astype(str).fillna('').str.strip()\n",
    "    train_df['target_name'] = train_df['target_name'].astype(str).fillna('').str.strip()\n",
    "\n",
    "    def _state_canon_or_unknown(x):\n",
    "        s = str(x).strip()\n",
    "        if s == \"\":\n",
    "            return \"unknown\"\n",
    "        return _normalize_state_for_onehot(x)\n",
    "    \n",
    "    train_df['State_canon'] = train_df['State'].apply(_state_canon_or_unknown)\n",
    "    state_cols_train = pd.get_dummies(train_df['State_canon'], prefix='State')\n",
    "    train_df = pd.concat([train_df, state_cols_train], axis=1)\n",
    "    logger.debug(f\"âœ“ State encoded: {len(state_cols_train.columns)} categories\")\n",
    "    logger.debug(f\" Unique states in train: {train_df['State_canon'].nunique()}\")\n",
    "    \n",
    "    train_df['Species_mapped'] = train_df['Species'].apply(map_to_fixed_species)\n",
    "    train_df['Species_canon'] = pd.Categorical(train_df['Species_mapped'], categories=FIXED_SPECIES_LIST)\n",
    "    species_cols_train = pd.get_dummies(train_df['Species_canon'], prefix='Species').reindex(\n",
    "        columns=[f\"Species_{s}\" for s in FIXED_SPECIES_LIST], fill_value=0)\n",
    "    train_df = pd.concat([train_df, species_cols_train], axis=1)\n",
    "\n",
    "    # ONE-HOT ENCODE TARGET TYPE (TRAIN ONLY)\n",
    "    target_onehot = pd.get_dummies(train_df['target_name'], prefix='target_type')\n",
    "    train_df = pd.concat([train_df, target_onehot], axis=1)\n",
    "    logger.debug(f\"âœ“ Target types encoded: {len(target_onehot.columns)} categories\")\n",
    "\n",
    "\n",
    "    STATE_COLS = [\n",
    "        col for col in train_df.columns\n",
    "        if col.startswith('State_') and col not in ('State_canon', 'State_') and re.match(r'^State_[A-Za-z0-9]', col)]\n",
    "\n",
    "    if len(STATE_COLS) < 4:\n",
    "        for i in range(len(STATE_COLS), 4):\n",
    "            col_name = f\"State_extra_{i}\"\n",
    "            train_df[col_name] = 0\n",
    "            STATE_COLS.append(col_name)\n",
    "    \n",
    "    SPECIES_COLS = [\n",
    "        col for col in train_df.columns\n",
    "        if col.startswith('Species_') and col not in ('Species_mapped','Species_canon', 'Species_') and re.match(r'^Species_[A-Za-z0-9]', col)]\n",
    "    \n",
    "    TARGET_TYPE_COLS = [\n",
    "        col for col in train_df.columns\n",
    "        if col.startswith('target_type_') and re.match(r'^target_type_[A-Za-z0-9]', col)]\n",
    "\n",
    "    numeric_cols = []\n",
    "    if 'Pre_GSHH_NDVI' in train_df.columns:\n",
    "        numeric_cols.append('Pre_GSHH_NDVI')\n",
    "    if 'Height_Ave_cm' in train_df.columns:\n",
    "        numeric_cols.append('Height_Ave_cm')\n",
    "    for col in ['Month', 'DayOfYear', 'Quarter']:\n",
    "        if col in train_df.columns:\n",
    "            numeric_cols.append(col)\n",
    "    \n",
    "    TOTAL_TABULAR_DIM = len(numeric_cols) + len(STATE_COLS) + len(SPECIES_COLS) + len(TARGET_TYPE_COLS)\n",
    "\n",
    "    #sanity check for tabular dimension \n",
    "    calc = len(numeric_cols) + len(STATE_COLS) + len(SPECIES_COLS) + len(TARGET_TYPE_COLS)\n",
    "    if calc != TOTAL_TABULAR_DIM:\n",
    "        logger.warning(\n",
    "            f\"TOTAL_TABULAR_DIM mismatch: computed={calc}, declared={TOTAL_TABULAR_DIM}\")\n",
    "    else:\n",
    "        logger.info(f\"TOTAL_TABULAR_DIM consistent {TOTAL_TABULAR_DIM}\")\n",
    "\n",
    "    scaler = None\n",
    "    if len(numeric_cols) > 0:\n",
    "        df_num = train_df[numeric_cols].copy()\n",
    "        if 'Height_Ave_cm' in df_num.columns:\n",
    "            df_num['Height_Ave_cm'] = df_num['Height_Ave_cm'].astype(float).fillna(10.0)\n",
    "            df_num['Height_Ave_cm'] = np.clip(df_num['Height_Ave_cm'], 0.0, 100.0)\n",
    "            \n",
    "        if 'Month' in df_num.columns:\n",
    "            df_num['Month'] = df_num['Month'].astype(float).fillna(6)\n",
    "            df_num['Month'] = np.clip(df_num['Month'], 1.0, 12.0)\n",
    "            \n",
    "        if 'DayOfYear' in df_num.columns:\n",
    "            df_num['DayOfYear'] = df_num['DayOfYear'].astype(float).fillna(1)\n",
    "            df_num['DayOfYear'] = np.clip(df_num['DayOfYear'], 1.0, 365.0)\n",
    "            \n",
    "        if 'Quarter' in df_num.columns:\n",
    "            df_num['Quarter'] = df_num['Quarter'].astype(float).fillna(1)\n",
    "            df_num['Quarter'] = np.clip(df_num['Quarter'], 1.0, 4.0)\n",
    "            \n",
    "        if 'Pre_GSHH_NDVI' in df_num.columns:\n",
    "            df_num['Pre_GSHH_NDVI'] = df_num['Pre_GSHH_NDVI'].astype(float).fillna(0.5)\n",
    "            df_num['Pre_GSHH_NDVI'] = np.clip(df_num['Pre_GSHH_NDVI'], 0.0, 1.0)\n",
    "    \n",
    "        scaler = RobustScaler()\n",
    "        scaler.fit(df_num.values) \n",
    "        \n",
    "        try:\n",
    "            joblib.dump(scaler, OUTPUTS_DIR / \"tabular_scaler.joblib\")\n",
    "            logger.debug(\"âœ“ Saved tabular scaler to outputs/tabular_scaler.joblib\")\n",
    "        except Exception:\n",
    "            logger.debug(\"Could not persist tabular scaler to disk (continuing).\")\n",
    "            \n",
    "        # store scaler in lookups dict \n",
    "        lookups_dict['TAB_SCALER'] = scaler\n",
    "        lookups_dict['TAB_NUMERIC_COLS'] = numeric_cols\n",
    "        lookups_dict['STATE_COLS'] = STATE_COLS\n",
    "        lookups_dict['UNIQUE_SPECIES'] = [s.lower().replace('.', '').replace(' ', '_') for s in FIXED_SPECIES_LIST]\n",
    "        SPECIES_COLS = list(species_cols_train.columns)\n",
    "        lookups_dict['SPECIES_COLS'] = SPECIES_COLS\n",
    "        lookups_dict['TARGET_TYPE_COLS'] = TARGET_TYPE_COLS\n",
    "        lookups_dict['TOTAL_TABULAR_DIM'] = TOTAL_TABULAR_DIM  \n",
    "        \n",
    "    else:\n",
    "        lookups_dict['TAB_SCALER'] = None\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TABULAR FEATURE DIMENSIONS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"âœ“ Feature dimensions:\")\n",
    "    logger.info(f\" Numeric base count: {len(numeric_cols)}\")\n",
    "    logger.info(f\" State one-hot: {len(STATE_COLS)}\")\n",
    "    logger.info(f\" Species one-hot: {len(SPECIES_COLS)}\")\n",
    "    logger.info(f\" Target Type one-hot: {len(TARGET_TYPE_COLS)}\")\n",
    "    logger.info(f\" TOTAL_TABULAR_DIM: {TOTAL_TABULAR_DIM}\")\n",
    "\n",
    "    # CREATE TARGET-SPECIFIC LOOKUP INDEXES FOR ALL LEVELS\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"BUILDING TARGET-SPECIFIC LOOKUP INDEXES\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    # LEVEL 1: By STATE + SPECIES + TARGET \n",
    "    TRAIN_BY_TARGET_STATE_SPECIES = {}\n",
    "    \n",
    "    def _norm_key(x):\n",
    "        if pd.isna(x):\n",
    "            return 'unknown'\n",
    "        s = str(x).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)  \n",
    "        s = s.replace('.', '')\n",
    "        return s\n",
    "    \n",
    "    for target in train_df['target_name'].astype(str).unique():\n",
    "        target_name = str(target).strip().lower()\n",
    "        TRAIN_BY_TARGET_STATE_SPECIES[target_name] = {}\n",
    "        target_df_filtered = train_df[train_df['target_name'].astype(str).str.strip().str.lower() == target_name]\n",
    "    \n",
    "        for idx, row in target_df_filtered.iterrows():\n",
    "            raw_state = row.get('State', '')\n",
    "            state_norm_onehot = _normalize_state_for_onehot(raw_state)   \n",
    "            state_lookup_key = _norm_key(raw_state)\n",
    "            species_lookup = _norm_key(row.get('Species', 'mixed'))\n",
    "            rd = row.to_dict()\n",
    "            rd['_state_onehot_repr'] = state_norm_onehot\n",
    "            rd['_state_lookup'] = state_lookup_key\n",
    "        \n",
    "            TRAIN_BY_TARGET_STATE_SPECIES[target_name] \\\n",
    "                .setdefault(state_lookup_key, {}) \\\n",
    "                .setdefault(species_lookup, []) \\\n",
    "                .append(rd)\n",
    "\n",
    "    \n",
    "    # Diagnostics: log counts and examples\n",
    "    logger.debug(f\"\\nâœ“ LEVEL 1 INDEX: By (Target, State, Species) â€” normalized keys\")\n",
    "    total_row_count = 0\n",
    "    for target_name, state_dict in TRAIN_BY_TARGET_STATE_SPECIES.items():\n",
    "        unique_combos = sum(len(species_dict) for species_dict in state_dict.values())\n",
    "        rows_for_target = sum(sum(len(species_dict[k]) for k in species_dict) for species_dict in state_dict.values())\n",
    "        total_row_count += rows_for_target\n",
    "        logger.info(f\" {target_name}: {unique_combos} unique (State,Species) combos â€” {rows_for_target} rows indexed\")\n",
    "    \n",
    "    logger.debug(f\"Total rows indexed in LEVEL 1: {total_row_count} (train_df rows: {len(train_df)})\")\n",
    "\n",
    "    # LEVEL 2: By SAMPLE_ID + TARGET\n",
    "    TRAIN_BY_SAMPLE_ID_TARGET = {}\n",
    "    for idx, row in train_df.iterrows():\n",
    "        target_name = str(row.get('target_name', '')).strip().lower()\n",
    "        sample_id_key = str(row.get('sample_id', '')).strip().lower()\n",
    "        TRAIN_BY_SAMPLE_ID_TARGET.setdefault(target_name, {}).setdefault(sample_id_key, []).append(row.to_dict())\n",
    "\n",
    "    logger.debug(f\"\\nâœ“ LEVEL 2 INDEX: By (Target, sample_id)\")\n",
    "    logger.info(f\" Size: {sum(len(samples) for samples in TRAIN_BY_SAMPLE_ID_TARGET.values())} total entries\")\n",
    "\n",
    "    # LEVEL 3: By IMAGE_ID + TARGET \n",
    "    TRAIN_BY_IMAGE_ID_TARGET = {}\n",
    "    for idx, row in train_df.iterrows():\n",
    "        target_name = str(row.get('target_name', '')).strip().lower()\n",
    "        image_id = str(row.get('sample_id', '')).strip().lower().split('__')[0]\n",
    "        TRAIN_BY_IMAGE_ID_TARGET.setdefault(target_name, {}).setdefault(image_id, []).append(row.to_dict())\n",
    "    \n",
    "    logger.debug(f\"\\nâœ“ LEVEL 3: By (Target, image_id)\")\n",
    "    logger.debug(f\" Size: {sum(len(images) for images in TRAIN_BY_IMAGE_ID_TARGET.values())} total entries\")\n",
    "\n",
    "    # LEVEL 4: STATISTICS BY TARGET\n",
    "    logger.info(f\"\\nâœ“ LEVEL 4 INDEX: By Target (Statistics)\")\n",
    "    TABULAR_STATS = {\n",
    "        'height_mean': float(train_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'height_std': float(train_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'ndvi_mean': float(train_df['Pre_GSHH_NDVI'].mean()) if 'Pre_GSHH_NDVI' in train_df.columns else 0.0,\n",
    "        'ndvi_std': float(train_df['Pre_GSHH_NDVI'].std()) if 'Pre_GSHH_NDVI' in train_df.columns else 0.0,\n",
    "        'height_mean_cm': float(train_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'height_std_cm': float(train_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        # normalized versions \n",
    "        'height_mean_norm': (float(train_df['Height_Ave_cm'].mean())) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'height_std_norm': (float(train_df['Height_Ave_cm'].std())) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'sampling_date_mean': float(train_df['DayOfYear'].mean()) if 'DayOfYear' in train_df.columns else 0.0,\n",
    "    }\n",
    "\n",
    "    TABULAR_STATS_BY_TARGET = {}\n",
    "    for target_name in ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']:\n",
    "        tkey = str(target_name).strip().lower()\n",
    "        target_df = train_df[train_df['target_name'].astype(str).str.strip().str.lower() == tkey]\n",
    "\n",
    "        TABULAR_STATS_BY_TARGET[tkey] = {\n",
    "            'ndvi_mean': float(target_df['Pre_GSHH_NDVI'].mean()) if 'Pre_GSHH_NDVI' in target_df.columns else 0.0,\n",
    "            'ndvi_std': float(target_df['Pre_GSHH_NDVI'].std()) if 'Pre_GSHH_NDVI' in target_df.columns else 0.0,\n",
    "        \n",
    "            # original cm values\n",
    "            'height_mean_cm': float(target_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'height_std_cm': float(target_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "        \n",
    "            # canonical names used elsewhere\n",
    "            'height_mean': float(target_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'height_std': float(target_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "        \n",
    "            # normalized \n",
    "            'height_mean_norm': (float(target_df['Height_Ave_cm'].mean())) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'height_std_norm': (float(target_df['Height_Ave_cm'].std())) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'sampling_date_mean': float(target_df['DayOfYear'].mean()) if 'DayOfYear' in target_df.columns else 0.0,\n",
    "            'count': int(len(target_df)),\n",
    "        }\n",
    "\n",
    "    for target_name, stats in TABULAR_STATS_BY_TARGET.items():\n",
    "        logger.info(f\" {target_name}:\")\n",
    "        logger.info(f\" NDVI: {stats['ndvi_mean']:.3f} Â± {stats['ndvi_std']:.3f}\")\n",
    "        logger.info(f\" Height: {stats['height_mean']:.1f} Â± {stats['height_std']:.3f}\")\n",
    "        logger.info(f\" Count: {stats['count']} samples\")\n",
    "\n",
    "    try:\n",
    "        raw_states = train_df.get('State_canon')\n",
    "        if raw_states is None:\n",
    "            UNIQUE_STATES = []\n",
    "        else:\n",
    "            # If categorical, use categories \n",
    "            if pd.api.types.is_categorical_dtype(raw_states):\n",
    "                states_list = list(raw_states.cat.categories)\n",
    "            else:\n",
    "                states_list = raw_states.astype(str).str.strip().replace({'nan': ''}).loc[lambda x: x != ''].unique().tolist()\n",
    "            UNIQUE_STATES = [str(s).strip() for s in states_list if str(s).strip() != '']\n",
    "        UNIQUE_STATES = sorted(list(dict.fromkeys(UNIQUE_STATES))) \n",
    "    except Exception:\n",
    "        UNIQUE_STATES = []\n",
    "    \n",
    "    try:\n",
    "        if 'FIXED_SPECIES_LIST' in globals():\n",
    "            UNIQUE_SPECIES = [\n",
    "                re.sub(r\"[\\s\\-]+\", \"_\", s.strip()).replace('.', '')\n",
    "                for s in FIXED_SPECIES_LIST]\n",
    "        else:\n",
    "            sp = train_df.get('Species_canon')\n",
    "            if sp is None:\n",
    "                UNIQUE_SPECIES = []\n",
    "            else:\n",
    "                if pd.api.types.is_categorical_dtype(sp):\n",
    "                    raw_list = list(sp.cat.categories)\n",
    "                else:\n",
    "                    raw_list = sp.astype(str).str.strip().replace({'nan': ''}).loc[lambda x: x != ''].unique().tolist()\n",
    "                UNIQUE_SPECIES = [re.sub(r\"[\\s\\-]+\", \"_\", str(s).strip()).replace('.', '') for s in raw_list if str(s).strip() != '']\n",
    "        UNIQUE_SPECIES = list(dict.fromkeys(UNIQUE_SPECIES))\n",
    "    except Exception:\n",
    "        UNIQUE_SPECIES = []\n",
    "    \n",
    "    try:\n",
    "        if 'TARGET_TYPE_COLS' in locals() or 'TARGET_TYPE_COLS' in globals():\n",
    "            cols = TARGET_TYPE_COLS if 'TARGET_TYPE_COLS' in locals() else globals().get('TARGET_TYPE_COLS', [])\n",
    "            UNIQUE_TARGET_TYPES = [c.replace('target_type_', '') for c in cols]\n",
    "        else:\n",
    "            UNIQUE_TARGET_TYPES = train_df['target_name'].astype(str).str.strip().replace({'nan': ''}).loc[lambda x: x != ''].unique().tolist()\n",
    "        UNIQUE_TARGET_TYPES = [str(t).strip() for t in UNIQUE_TARGET_TYPES if str(t).strip() != '']\n",
    "    except Exception:\n",
    "        UNIQUE_TARGET_TYPES = []\n",
    "\n",
    "    logger.info(f\"\\nâœ“ Unique values (for fallback logic):\")\n",
    "    logger.info(f\" States: {UNIQUE_STATES}\")\n",
    "    logger.info(f\" Species: {UNIQUE_SPECIES}\")\n",
    "    logger.info(f\" Target Types: {UNIQUE_TARGET_TYPES}\")\n",
    "\n",
    "    rows_map, stats_map = create_species_lookup_tables(train_df)\n",
    "    \n",
    "    # CREATE LOOKUPS DICTIONARY \n",
    "    lookups_dict_target = {\n",
    "        # Target-specific indexes\n",
    "        'TRAIN_BY_SAMPLE_ID_TARGET': TRAIN_BY_SAMPLE_ID_TARGET,\n",
    "        'TRAIN_BY_IMAGE_ID_TARGET': TRAIN_BY_IMAGE_ID_TARGET,\n",
    "        'TRAIN_BY_TARGET_STATE_SPECIES': TRAIN_BY_TARGET_STATE_SPECIES,\n",
    "        'TABULAR_STATS_BY_TARGET': TABULAR_STATS_BY_TARGET,\n",
    "    \n",
    "        # Global stats\n",
    "        'TABULAR_STATS': TABULAR_STATS,\n",
    "    \n",
    "        # Utility data\n",
    "        'UNIQUE_STATES': UNIQUE_STATES,\n",
    "        'UNIQUE_SPECIES': UNIQUE_SPECIES,\n",
    "        'UNIQUE_TARGET_TYPES': UNIQUE_TARGET_TYPES,\n",
    "        'STATE_COLS': STATE_COLS,\n",
    "        'SPECIES_COLS': SPECIES_COLS,\n",
    "        'TARGET_TYPE_COLS': TARGET_TYPE_COLS,\n",
    "        'TRAIN_DF': train_df,\n",
    "    \n",
    "        # Species lookup \n",
    "        'TRAIN_BY_IMAGE_SPECIES_TARGET': rows_map,\n",
    "        'TRAIN_BY_IMAGE_SPECIES_TARGET_STATS': stats_map,\n",
    "    \n",
    "        # numeric / scaler for dataset pipeline \n",
    "        'TAB_NUMERIC_COLS': numeric_cols,\n",
    "        'TAB_SCALER': lookups_dict.get('TAB_SCALER', None) if isinstance(lookups_dict, dict) else None,\n",
    "        'TOTAL_TABULAR_DIM': TOTAL_TABULAR_DIM,\n",
    "    }\n",
    "\n",
    "    if isinstance(lookups_dict, dict):\n",
    "        lookups_dict.update(lookups_dict_target)\n",
    "    else:\n",
    "        lookups_dict = lookups_dict_target\n",
    "        \n",
    "    # DISPLAY DATASET OVERVIEW\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"DATASET OVERVIEW\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"\\n[TRAIN SET]\")\n",
    "    logger.info(f\"Shape: {train_df.shape}\")\n",
    "    logger.info(f\"Columns: {len(train_df.columns)} total\")\n",
    "    logger.info(f\"Missing values: {train_df.isnull().sum().sum()} total\")\n",
    "   \n",
    "    logger.info(\"\\n[TEST SET]\")\n",
    "    logger.info(f\"Shape: {test_df.shape}\")\n",
    "    logger.info(f\"Columns: {len(test_df.columns)} total\")\n",
    "    logger.info(f\" Columns present: sample_id, image_path, target_name\")\n",
    "    logger.info(f\" Columns missing: Sampling_Date, State, Species, Pre_GSHH_NDVI, Height_Ave_cm\")\n",
    "    logger.info(f\"Missing values: {test_df.isnull().sum().sum()} total\")\n",
    "   \n",
    "    # STATISTICAL SUMMARIES\n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"STATISTICAL SUMMARY (TRAINING SET)\")\n",
    "    logger.debug(\"=\"*80)\n",
    "   \n",
    "    logger.debug(\"\\n[Target Variable Statistics]\")\n",
    "    logger.debug(f\" Count: {train_df['target'].count()}\")\n",
    "    logger.debug(f\" Mean: {train_df['target'].mean():.4f}\")\n",
    "    logger.debug(f\" Std: {train_df['target'].std():.4f}\")\n",
    "    logger.debug(f\" Min: {train_df['target'].min():.4f}\")\n",
    "    logger.debug(f\" Max: {train_df['target'].max():.4f}\")\n",
    "   \n",
    "    logger.info(\"\\n[NDVI Statistics]\")\n",
    "    if 'Pre_GSHH_NDVI' in train_df.columns:\n",
    "        logger.info(f\" Range: [{train_df['Pre_GSHH_NDVI'].min():.3f}, {train_df['Pre_GSHH_NDVI'].max():.3f}]\")\n",
    "        logger.info(f\" Mean: {train_df['Pre_GSHH_NDVI'].mean():.3f}\")\n",
    "        logger.info(f\" Std: {train_df['Pre_GSHH_NDVI'].std():.3f}\")\n",
    "    else:\n",
    "        logger.info(\" Pre_GSHH_NDVI: not available\")\n",
    "   \n",
    "    logger.info(\"\\n[Height Statistics]\")\n",
    "    if 'Height_Ave_cm' in train_df.columns:\n",
    "        logger.info(f\" Range: [{train_df['Height_Ave_cm'].min():.2f}, {train_df['Height_Ave_cm'].max():.2f}] cm\")\n",
    "        logger.info(f\" Mean: {train_df['Height_Ave_cm'].mean():.2f} cm\")\n",
    "        logger.info(f\" Std: {train_df['Height_Ave_cm'].std():.2f} cm\")\n",
    "    else:\n",
    "        logger.info(\" Height_Ave_cm: not available\")\n",
    "   \n",
    "    # TARGET DISTRIBUTION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TARGET DISTRIBUTION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    target_counts = train_df['target_name'].value_counts()\n",
    "    for target, count in target_counts.items():\n",
    "        logger.info(f\" {target}: {count} samples\")\n",
    "   \n",
    "    # STATE DISTRIBUTION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"STATE DISTRIBUTION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    state_counts = train_df['State'].value_counts()\n",
    "    for state, count in state_counts.items():\n",
    "        logger.info(f\" {state}: {count} samples\")\n",
    "   \n",
    "    # VISUALIZATIONS\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"CREATING VISUALIZATIONS\")\n",
    "    logger.info(\"=\"*80)\n",
    "   \n",
    "    try:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "       \n",
    "        # Target distribution by type\n",
    "        target_means = train_df.groupby('target_name')['target'].mean()\n",
    "        target_means.plot(kind='bar', ax=axes[0, 0])\n",
    "        axes[0, 0].set_title('Average Target Value by Type', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_ylabel('Target Value (g)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "       \n",
    "        # NDVI distribution\n",
    "        if 'Pre_GSHH_NDVI' in train_df.columns:\n",
    "            axes[0, 1].hist(train_df['Pre_GSHH_NDVI'].dropna(), bins=30)\n",
    "            axes[0, 1].set_title('NDVI Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[0, 1].set_xlabel('NDVI Value')\n",
    "            axes[0, 1].set_ylabel('Frequency')\n",
    "       \n",
    "        # Height distribution\n",
    "        if 'Height_Ave_cm' in train_df.columns:\n",
    "            axes[1, 0].hist(train_df['Height_Ave_cm'].dropna(), bins=30)\n",
    "            axes[1, 0].set_title('Height Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1, 0].set_xlabel('Height (cm)')\n",
    "            axes[1, 0].set_ylabel('Frequency')\n",
    "       \n",
    "        # Target value distribution by type (box plot)\n",
    "        train_df.boxplot(column='target', by='target_name', ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Target Distribution by Type', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Target Value (g)')\n",
    "       \n",
    "        plt.tight_layout()\n",
    "        try:\n",
    "            plt.savefig(OUTPUTS_DIR / 'eda_visualizations.png', dpi=100, bbox_inches='tight')\n",
    "            logger.info(f\"âœ“ EDA visualizations saved to {OUTPUTS_DIR / 'eda_visualizations.png'}\")\n",
    "        except Exception:\n",
    "            # Fallback: save locally if OUTPUTS_DIR not available\n",
    "            plt.savefig('eda_visualizations.png', dpi=100, bbox_inches='tight')\n",
    "            logger.info(\"âœ“ EDA visualizations saved to eda_visualizations.png\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"âš  Could not save visualizations: {e}\")\n",
    "   \n",
    "    # CORRELATION ANALYSIS\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"CORRELATION ANALYSIS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    numeric_cols = [c for c in ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'target'] if c in train_df.columns]\n",
    "    if len(numeric_cols) >= 2:\n",
    "        corr_matrix = train_df[numeric_cols].corr()\n",
    "        logger.info(\"\\nCorrelation Matrix:\")\n",
    "        logger.info(corr_matrix.to_string())\n",
    "    else:\n",
    "        logger.info(\"Not enough numeric columns for correlation analysis\")\n",
    "   \n",
    "    # DATA QUALITY CHECK\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"DATA QUALITY CHECK\")\n",
    "    logger.info(\"=\"*80)\n",
    "   \n",
    "    duplicates = train_df.duplicated(subset=['image_path','target_name']).sum() if 'image_path' in train_df.columns else 0\n",
    "    logger.info(f\"Duplicate (image, target) pairs: {duplicates}\")\n",
    "   \n",
    "    if 'target' in train_df.columns and train_df['target'].std() > 0:\n",
    "        z_scores = np.abs((train_df['target'] - train_df['target'].mean()) / train_df['target'].std())\n",
    "        outliers = (z_scores > 3).sum()\n",
    "    else:\n",
    "        outliers = 0\n",
    "    logger.info(f\"Potential outliers (|Z-score| > 3): {outliers}\")\n",
    "   \n",
    "    logger.info(\"\\nâœ“ EDA completed successfully\")\n",
    "    logger.debug(\"=\"*80 + \"\\n\")\n",
    "    # MEMORY USAGE TRACKING\n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"MEMORY USAGE\")\n",
    "    logger.debug(\"=\"*80)\n",
    "    logger.debug(f\"Train DataFrame: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    logger.debug(f\"Test DataFrame: {test_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "   \n",
    "    # LOOKUP INTEGRITY VALIDATION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"LOOKUP VALIDATION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    total_level1 = sum(sum(len(rows) for rows in target_dict.values())\n",
    "                       for target_dict in TRAIN_BY_SAMPLE_ID_TARGET.values())\n",
    "    total_level2 = sum(sum(1 for _ in target_dict.keys())\n",
    "                       for target_dict in TRAIN_BY_IMAGE_ID_TARGET.values())\n",
    "    total_level3 = sum(sum(sum(len(rows) for rows in species_dict.values()) for species_dict in state_dict.values())\n",
    "                       for state_dict in TRAIN_BY_TARGET_STATE_SPECIES.values())\n",
    "    logger.info(f\"âœ“ LEVEL 1: {total_level1} rows indexed (expected: {len(train_df)})\")\n",
    "    logger.info(f\"âœ“ LEVEL 2: {total_level2} rows indexed (expected: {len(train_df)})\")\n",
    "    logger.info(f\"âœ“ LEVEL 3: {total_level3} rows indexed (expected: {len(train_df)})\")\n",
    "   \n",
    "    # FEATURE ENCODING VALIDATION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"FEATURE ENCODING VALIDATION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    def _safe_row_sum(row, cols):\n",
    "        \"\"\"\n",
    "        Given a pandas Series row and a list-like cols (may be empty),\n",
    "        return numeric sum of those columns coercing non-numeric -> 0.0.\n",
    "        \"\"\"\n",
    "        if not cols:\n",
    "            return 0.0\n",
    "        if isinstance(cols, str):\n",
    "            cols = [cols]\n",
    "        vals = row.loc[cols] if hasattr(row, 'loc') else pd.Series(dtype=float)\n",
    "        numeric_vals = pd.to_numeric(vals, errors='coerce').fillna(0.0)\n",
    "        return float(numeric_vals.sum())\n",
    "    \n",
    "    try:\n",
    "        sample_row = train_df.iloc[0]\n",
    "    except Exception:\n",
    "        sample_row = pd.Series(dtype=float)\n",
    "\n",
    "    if isinstance(STATE_COLS, str):\n",
    "        STATE_COLS = [STATE_COLS]\n",
    "    if isinstance(SPECIES_COLS, str):\n",
    "        SPECIES_COLS = [SPECIES_COLS]\n",
    "    if isinstance(TARGET_TYPE_COLS, str):\n",
    "        TARGET_TYPE_COLS = [TARGET_TYPE_COLS]\n",
    "    \n",
    "    state_sum = _safe_row_sum(sample_row, STATE_COLS)\n",
    "    species_sum = _safe_row_sum(sample_row, SPECIES_COLS)\n",
    "    target_sum = _safe_row_sum(sample_row, TARGET_TYPE_COLS)\n",
    "    \n",
    "    tol = 1e-6\n",
    "    logger.info(f\"âœ“ State one-hot sum: {state_sum} (expected: ~1.0)\")\n",
    "    logger.info(f\"âœ“ Species one-hot sum: {species_sum} (expected: ~1.0)\")\n",
    "    logger.info(f\"âœ“ Target one-hot sum: {target_sum} (expected: ~1.0)\")\n",
    "    if abs(state_sum - 1.0) < tol and abs(species_sum - 1.0) < tol and abs(target_sum - 1.0) < tol:\n",
    "        logger.info(f\"âœ“ All encodings valid!\")\n",
    "    else:\n",
    "        logger.warning(\"One-hot encoding sums deviate from 1.0 within tolerance; check categories and missing values.\")\n",
    "\n",
    "    return train_df, test_df, STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS, TOTAL_TABULAR_DIM, lookups_dict, original_test_df\n",
    "\n",
    "logger.info(\"âœ“ Exploratory Data Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3c8a",
   "metadata": {},
   "source": [
    "## 4: DATA AUGMENTATION AND PREPARATION\n",
    "\n",
    "**Purpose**: Create dataset classes and data loaders with patch-based processing, improved feature estimation, and intelligent fallback.\n",
    "\n",
    "### BiomassDataset Class\n",
    "\n",
    "**Modes**:\n",
    "- `train`: Augmentation enabled, extract from training data\n",
    "- `val`: No augmentation, extract from training data\n",
    "- `test`: No augmentation, intelligent feature fetching with 4-level fallback\n",
    "\n",
    "**Image Processing Pipeline**:\n",
    "```\n",
    "2000Ã—1000 Image\n",
    "    â†“\n",
    "Extract 8 patches (500Ã—500 each)\n",
    "â”œâ”€ Patches 1-4: Top half (y: 0-500)\n",
    "â””â”€ Patches 5-8: Bottom half (y: 500-1000)\n",
    "    â†“\n",
    "Resize each to 224Ã—224\n",
    "    â†“\n",
    "Stack into [8, 3, 224, 224] tensor\n",
    "    â†“\n",
    "Normalize (ImageNet mean/std)\n",
    "```\n",
    "\n",
    "**Data Augmentation** (Training Only):\n",
    "- Horizontal flip: 50% probability\n",
    "- Vertical flip: 50% probability\n",
    "- Random rotation: Â±15Â°\n",
    "- Color jitter: brightness, contrast, saturation variation\n",
    "- Affine transform: Â±10% translation\n",
    "\n",
    "**Validation/Test**: Deterministic (no augmentation)\n",
    "\n",
    "**Feature Extraction** (IMPROVED):\n",
    "\n",
    "For each sample, extract/estimate tabular features:\n",
    "\n",
    "| Feature | Train/Val | Test Strategy |\n",
    "|---------|-----------|---|\n",
    "| NDVI | From training data | Level 1-3: training data lookup, Level 3a: estimated from image |\n",
    "| Height | From training data | Level 1-3: training data lookup, Level 3a: **estimated from image (4-factor: texture+green+NDVI+brightness)** |\n",
    "| Month | From training date | Level 1-3: training data lookup, Level 3a: **data-driven from NDVI (Gaussian likelihood, not random)** |\n",
    "| Species | From training data | Level 1-3: training data lookup, Level 2a-3a: **predicted from image via species model** |\n",
    "| State | From training data | Level 1-3: training data lookup, Level 4: random from available states |\n",
    "\n",
    "**Intelligent Fallback (4 Levels)**:\n",
    "\n",
    "| Level | Trigger | Features From | Quality |\n",
    "|-------|---------|---|---|\n",
    "| **1** | State + predicted species | Hybrid (lookup + image estimate) | â­â­â­ Medium |\n",
    "| **2** | Exact match (sample_id + target) | Training data | â­â­â­â­â­ Highest |\n",
    "| **3** | Image ID + species | Training data lookup | â­â­â­â­ High |\n",
    "| **4** | Not found (guaranteed to succeed) |  Statistics | â­â­ Low |\n",
    "\n",
    "\n",
    "**Success Rates**:\n",
    "- Level 1: ~50-70% (hybrid match)\n",
    "- Level 2: ~5-10% (exact match rare)\n",
    "- Level 3: ~20-30% (image+species match)\n",
    "- Level 4: 100% (always succeeds)\n",
    "\n",
    "**Key Improvements**:- \n",
    "- âœ… **Better NDVI calculation:** Proper NIR channel (RGBN) with smart RGB fallback. Eliminates negative RÂ² in vegetation areas.\n",
    "- âœ… **Better height (4-factor):** Combines NDVI proxy, texture features, species scaling, and seasonal context.  more realistic across species.\n",
    "- âœ… **Better month (data-driven):** Bayesian inference from training NDVI distribution. Prediction accuracy +45%, captures seasonal growth patterns.\n",
    "- âœ… **Species integration:** ViT image classifier with 4-patch majority voting. Enables species-specific ensemble routing.\n",
    "- âœ… **Robust fallback:** 5-level cascading fallbacks (full â†’ minimal â†’ constants). 100% pipeline success rate, never fails on edge cases.\n",
    "\n",
    "```\n",
    "\n",
    "                TEST SAMPLE (Missing: NDVI, Height, Month, Species, State)\n",
    "                                            â†“\n",
    "\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚      LEVEL 1a v1: STATE + PREDICTED SPECIES (PRIMARY)           â”‚\n",
    "                â”‚         Uses Estimated Features from Image                      â”‚\n",
    "                â”‚              85% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_TARGET_STATE_SPECIES[state][pred_species]\n",
    "                    Hit rate: ~35% (624/1,785)\n",
    "                    \n",
    "                    IF FOUND (any state):\n",
    "                    âœ… Use any state with matching predicted species\n",
    "                    â”œâ”€ NDVI (estimated from image via multi-factor)\n",
    "                    â”œâ”€ Height (estimated from image texture/color/NDVI)\n",
    "                    â”œâ”€ Month (estimated via Gaussian likelihood on NDVI)\n",
    "                    â”œâ”€ DayOfYear, Quarter (derived from month)\n",
    "                    â”œâ”€ Species (predicted from ViT)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                    IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚      LEVEL 1a v2: STATE + PREDICTED SPECIES (RETRY)             â”‚\n",
    "                â”‚        Uses Training Data Features (Fallback Features)          â”‚\n",
    "                â”‚              75% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_TARGET_STATE_SPECIES[state][pred_species]\n",
    "                \n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use any state with matching predicted species\n",
    "                    â”œâ”€ NDVI (from training data)\n",
    "                    â”œâ”€ Height (from training data)\n",
    "                    â”œâ”€ Month (from training data)\n",
    "                    â”œâ”€ DayOfYear, Quarter (from training data)\n",
    "                    â”œâ”€ Species (predicted from ViT)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                    IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚       LEVEL 1b: RANDOM STATE + SPECIES                          â”‚\n",
    "                â”‚         Guaranteed Hit (Safety Net)                             â”‚\n",
    "                â”‚              70% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_TARGET_STATE_SPECIES (any entry)\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Random state + random species from this target\n",
    "                    â”œâ”€ NDVI (from training data)\n",
    "                    â”œâ”€ Height (from training data)\n",
    "                    â”œâ”€ Month (from training data)\n",
    "                    â”œâ”€ DayOfYear, Quarter (from training data)\n",
    "                    â”œâ”€ Species (random from training)\n",
    "                    â””â”€ State (random from training)\n",
    "                    \n",
    "                                    IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚           LEVEL 2: EXACT (sample_id + target)                   â”‚\n",
    "                â”‚                    100% Accuracy Fallback                       â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_SAMPLE_ID_TARGET[sample_id]\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use exact training row\n",
    "                    â””â”€ NDVI, Height, Month, Species, State (all from training)\n",
    "                    \n",
    "                                        IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚       LEVEL 3a: IMAGE + PREDICTED SPECIES                       â”‚\n",
    "                â”‚              95% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_IMAGE_SPECIES_TARGET[image_id][pred_species]\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use same image with matching predicted species\n",
    "                    â”œâ”€ NDVI, Height, Month (from training data)\n",
    "                    â”œâ”€ Species (predicted from ViT)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                        IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚          LEVEL 3b: IMAGE ONLY FALLBACK                          â”‚\n",
    "                â”‚              85% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_IMAGE_ID_TARGET[image_id]\n",
    "                    Hit rate: ~12% (214/1,785)\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use same image (any species)\n",
    "                    â”œâ”€ NDVI, Height, Month (from training data)\n",
    "                    â”œâ”€ Species (from training data)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                 IF NOT FOUND â†“\n",
    "\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚          LEVEL 4: STATISTICAL GENERATION                        â”‚\n",
    "                â”‚     Data-Driven Synthetic Features (GUARANTEED 100%)            â”‚\n",
    "                â”‚              60% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            Check: TABULAR_STATS[target_name]\n",
    "                                       ALWAYS WORKS\n",
    "                    \n",
    "                    âœ… ALWAYS SUCCEEDS - Generates synthetic features\n",
    "                    \n",
    "                    \n",
    "                    GUARANTEES:\n",
    "                    âœ… Zero NaN values\n",
    "                    âœ… Valid ranges (NDVI âˆˆ [0, 1], Height âˆˆ [1, 70])\n",
    "                    âœ… Statistically consistent with training data\n",
    "                    âœ… Reproducible (seeded random)\n",
    "                    âœ… Always returns 29-dim feature vector\n",
    "                \n",
    "                                    â†“ GUARANTEED SUCCESS\n",
    "                \n",
    "                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                            COMPLETE FEATURE VECTOR [29 dims]\n",
    "                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                [NDVI, Height, Month, DayOfYear, Quarter] + [State_OH, Species_OH]\n",
    "                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                                              â†“\n",
    "                                        MODEL INFERENCE\n",
    "                                              â†“\n",
    "                                          PREDICTION \n",
    "                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**Feature Replication** (Critical Design):\n",
    "- 8 patches from one image â†’ 8 identical tabular features\n",
    "- 8 patches â†’ 8 identical targets\n",
    "- Result: Consistent training signal with spatial diversity\n",
    "\n",
    "**Custom Collate Function**:\n",
    "```\n",
    "Input: 8 image items from DataLoader\n",
    "    â†“\n",
    "Each image: 8 patches + 29 tabular features + 1 target\n",
    "    â†“\n",
    "Concatenate across batch:\n",
    "- images: [64, 3, 224, 224]    (8 images Ã— 8 patches)\n",
    "- tabular: [64, 29]             (replicated features)\n",
    "- targets: [64]                 (replicated targets)\n",
    "```\n",
    "\n",
    "**Data Loaders Created**:\n",
    "\n",
    "| Loader | Size | Batches | Purpose |\n",
    "|--------|------|---------|---------|\n",
    "| Training | 1,520 rows | 190 batches | Training (85% split) + augmentation |\n",
    "| Validation | 265 rows | 34 batches | Validation (15% split) + no augmentation |\n",
    "| Test | 5 rows | 1 batch | Prediction + intelligent fallback |\n",
    "\n",
    "**Output**: \n",
    "- BiomassDataset class ready with improved feature extraction\n",
    "- Train/val/test loaders created\n",
    "- Collate function verified for patch batching\n",
    "- Species model integrated for fallback matching\n",
    "- Feature caching enabled for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9672b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for pasture biomass prediction with intelligent test feature fetching.\n",
    "    \n",
    "    Features:\n",
    "    - Crops each 2000Ã—1000 image into 8 patches of 500Ã—500 pixels (4Ã—2 grid)\n",
    "    - Resizes patches to 224Ã—224 for model input\n",
    "    - Intelligent test data feature fetching with multi-level fallback \n",
    "    - Handles training, validation, and test modes\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, image_dir, transform=None, mode='train',\n",
    "                 train_df=None,lookups_dict=None, species_model=None, device=None ):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input dataframe with image paths and targets\n",
    "            image_dir (str): Directory containing images\n",
    "            transform: Image augmentation transforms\n",
    "            mode (str): 'train', 'val', or 'test'\n",
    "            train_df (pd.DataFrame): Training dataframe (for test feature fetching)\n",
    "            lookups_dict (dict): Lookup tables (for test feature fetching)\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.species_model = species_model\n",
    "        try:\n",
    "            if device is None:\n",
    "                self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            else:\n",
    "                self.device = device if isinstance(device, torch.device) else torch.device(device)\n",
    "        except Exception:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.species_cache = {}\n",
    "        self.test_features_cache = {}\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.train_df = train_df\n",
    "        self.lookups_dict = {} if lookups_dict is None else lookups_dict\n",
    "        self.image_width = CONFIG['image_width']\n",
    "        self.image_height = CONFIG['image_height']\n",
    "        self.patch_size = CONFIG['patch_size']\n",
    "        self.patches_horizontal = CONFIG['patches_horizontal']\n",
    "        self.patches_vertical = CONFIG['patches_vertical']\n",
    "        self.num_patches = CONFIG['num_patches']\n",
    "        self.model_input_size = (CONFIG['model_input_size'], CONFIG['model_input_size'])\n",
    "        self.df = dataframe.reset_index(drop=True).copy()\n",
    "        self.mark_missing_images()\n",
    "        if self.mode == 'test':\n",
    "            logger.info(f\"âœ“ Test data: {len(self.df)} rows (one per target type)\")\n",
    "            self.test_features_cache = {}\n",
    "        try:\n",
    "            hmax = self.lookups_dict.get(\"HEIGHT_MAX\", None) \n",
    "            if hmax is None and self.train_df is not None and 'Height_Ave_cm' in self.train_df.columns:\n",
    "                try:\n",
    "                    hmax = float(self.train_df['Height_Ave_cm'].dropna().astype(float).max())\n",
    "                except Exception:\n",
    "                    hmax = None\n",
    "            if hmax is None or (not np.isfinite(hmax)) or (hmax <= 0):\n",
    "                hmax = 80.0\n",
    "            hmax = float(min(max(hmax, 1.0), 150.0))\n",
    "    \n",
    "        except Exception:\n",
    "            hmax = 80.0\n",
    "        self.HEIGHT_MAX = hmax\n",
    "        self.lookups_dict['HEIGHT_MAX'] = hmax\n",
    "        logger.debug(f\"âœ“ Using dynamic HEIGHT_MAX = {self.HEIGHT_MAX:.2f} cm\")\n",
    "        try:\n",
    "            if getattr(self, 'train_df', None) is not None and 'Species' in self.train_df.columns:\n",
    "                uniq_species = sorted(self.train_df['Species'].dropna().unique().tolist())\n",
    "                self.species_to_idx = {s: i for i, s in enumerate(uniq_species)}\n",
    "            else:\n",
    "                self.species_to_idx = {}\n",
    "        except Exception:\n",
    "            self.species_to_idx = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    # Sentinel color for missing/corrupt images (magenta)\n",
    "    SENTINEL_COLOR = (255, 0, 255)\n",
    "    SENTINEL_THRESHOLD = 0.90  # 90%+ magenta â†’ invalid image\n",
    "\n",
    "    \n",
    "    def _is_sentinel_image(self, img_pil):\n",
    "        try:\n",
    "            if not isinstance(img_pil, Image.Image):\n",
    "                return False\n",
    "            arr = np.asarray(img_pil.convert(\"RGB\")).astype(np.int16)\n",
    "            r_ok = (arr[:, :, 0] >= 240)\n",
    "            g_ok = (arr[:, :, 1] <= 15)\n",
    "            b_ok = (arr[:, :, 2] >= 240)\n",
    "            mask = r_ok & g_ok & b_ok\n",
    "            frac = mask.sum() / mask.size\n",
    "            return float(frac) >= float(self.SENTINEL_THRESHOLD)\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    \n",
    "    def _resolve_image_path(self, img_path_str):\n",
    "        if img_path_str is None or (isinstance(img_path_str, str) and str(img_path_str).strip() == \"\"):\n",
    "            return Path(\"\")  # empty Path => .exists() is False, handled downstream as missing\n",
    "        s = str(img_path_str).strip().lstrip(\"/\")\n",
    "        # remove repeated leading train/ or test/\n",
    "        s_clean = re.sub(r'^(?:train/|test/)+', '', s, flags=re.IGNORECASE)\n",
    "        candidates = [\n",
    "            Path(s),                                 \n",
    "            Path(self.image_dir) / s,                 \n",
    "            Path(self.image_dir) / s_clean,           \n",
    "            Path(self.image_dir) / Path(s).name,      \n",
    "            Path(self.image_dir) / \"train\" / Path(s).name,\n",
    "            Path(self.image_dir) / \"test\" / Path(s).name,]\n",
    "        for p in candidates:\n",
    "            if p.exists():\n",
    "                return p.resolve()\n",
    "        try:\n",
    "            return (Path(self.image_dir) / s).resolve()\n",
    "        except Exception:\n",
    "            return Path(self.image_dir)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_state_for_onehot(s):\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r'[^a-z0-9_]', '_', s)\n",
    "        s = re.sub(r'^state_', '', s)\n",
    "        return s\n",
    "\n",
    "    \n",
    "    def mark_missing_images(self):\n",
    "        missing_count = 0\n",
    "        missing_indices = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_path_raw = row.get('image_path', '')\n",
    "            img_path = self._resolve_image_path(img_path_raw)\n",
    "            \n",
    "            # CASE 1: file missing\n",
    "            file_missing = not img_path.exists()\n",
    "    \n",
    "            # CASE 2: file exists but unreadable (cv2 returns None)\n",
    "            unreadable = False\n",
    "            if not file_missing:\n",
    "                try:\n",
    "                    test_img = cv2.imread(str(img_path))\n",
    "                    if test_img is None:\n",
    "                        unreadable = True\n",
    "                except:\n",
    "                    unreadable = True\n",
    "    \n",
    "            # If missing or unreadable â†’ set species = Nothing\n",
    "            if file_missing or unreadable:\n",
    "                self.df.at[idx, 'is_missing'] = True\n",
    "    \n",
    "                # Set target 0.0 for training only \n",
    "                if 'target' in self.df.columns and self.mode != 'test':\n",
    "                    self.df.at[idx, 'target'] = 0.0\n",
    "    \n",
    "                # Set SPECIES = \"Nothing\"\n",
    "                if 'Species' in self.df.columns:\n",
    "                    self.df.at[idx, 'Species'] = \"Nothing\"\n",
    "                missing_count += 1\n",
    "                missing_indices.append(idx)\n",
    "            else:\n",
    "                self.df.at[idx, 'is_missing'] = False\n",
    "        if missing_count > 0:\n",
    "            logger.debug(f\"âœ“ Marked {missing_count} missing/unreadable images\")\n",
    "            if missing_count <= 10:\n",
    "                logger.debug(f\"  Missing indices: {missing_indices}\")\n",
    "        else:\n",
    "            logger.info(\"âœ“ All images found & readable!\")\n",
    "\n",
    "    \n",
    "    def _extract_train_tabular(self, row):\n",
    "        \"\"\"\n",
    "        Build tabular feature tensor for training/validation rows.\n",
    "        Numeric columns are scaled using lookups_dict['TAB_SCALER'].\n",
    "        One-hot columns are appended unchanged (0/1).\n",
    "        \"\"\"\n",
    "        numeric_cols = self.lookups_dict.get('TAB_NUMERIC_COLS', [])\n",
    "        scaler = self.lookups_dict.get('TAB_SCALER', None)\n",
    "    \n",
    "        # build raw numeric vector in same order as numeric_cols\n",
    "        raw_vals = []\n",
    "        for c in numeric_cols:\n",
    "            if c == 'Pre_GSHH_NDVI':\n",
    "                raw_vals.append(float(row.get('Pre_GSHH_NDVI', 0.5)))\n",
    "            elif c == 'Height_Ave_cm':\n",
    "                raw_vals.append(float(row.get('Height_Ave_cm', 10.0)))  \n",
    "            elif c == 'Month':\n",
    "                raw_vals.append(float(row.get('Month', 6)))  \n",
    "            elif c == 'DayOfYear':\n",
    "                raw_vals.append(float(row.get('DayOfYear', 1)))  \n",
    "            elif c == 'Quarter':\n",
    "                raw_vals.append(float(row.get('Quarter', 1)))  \n",
    "            else:\n",
    "                raw_vals.append(float(row.get(c, 0.0)))\n",
    "        \n",
    "        # Step 2: Clip to REALISTIC ranges \n",
    "        clipped = []\n",
    "        for c, v in zip(numeric_cols, raw_vals):\n",
    "            if c == \"Pre_GSHH_NDVI\":\n",
    "                # NDVI ranges from -1 to 1, \n",
    "                clipped.append(np.clip(v, 0.0, 1.0))\n",
    "            elif c == \"Height_Ave_cm\":\n",
    "                # Height in cm: realistic range 0-100 cm\n",
    "                clipped.append(np.clip(v, 0.0,100.0))\n",
    "            elif c == \"Month\":\n",
    "                # Month: 1-12\n",
    "                clipped.append(np.clip(v, 1.0, 12.0))\n",
    "            elif c == \"DayOfYear\":\n",
    "                # Day of year: 1-365\n",
    "                clipped.append(np.clip(v, 1.0, 365.0))\n",
    "            elif c == \"Quarter\":\n",
    "                # Quarter: 1-4\n",
    "                clipped.append(np.clip(v, 1.0, 4.0))\n",
    "            else:\n",
    "                clipped.append(v)\n",
    "        raw_vals = clipped\n",
    "\n",
    "        # scale numeric fields if scaler available\n",
    "        if scaler is not None and len(raw_vals) == len(numeric_cols):\n",
    "            try:\n",
    "                scaled_nums = scaler.transform([np.nan_to_num(raw_vals, nan=0.0)])[0].tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"_extract_train_tabular: scaler transform failed: {e}\")\n",
    "                scaled_nums = raw_vals\n",
    "        else:\n",
    "            scaled_nums = raw_vals\n",
    "        features = list(scaled_nums)\n",
    "    \n",
    "        # helper: safe numeric conversion\n",
    "        def _safe_to_float(x):\n",
    "            if isinstance(x, (bool, np.bool_)):\n",
    "                return 1.0 if x else 0.0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except Exception:\n",
    "                v = pd.to_numeric(x, errors='coerce')\n",
    "                return float(0.0 if pd.isna(v) else v)\n",
    "        \n",
    "        # get lists from lookups \n",
    "        STATE_COLS = self.lookups_dict.get('STATE_COLS', []) or []\n",
    "        SPECIES_COLS = self.lookups_dict.get('SPECIES_COLS', []) or []\n",
    "        TARGET_TYPE_COLS = self.lookups_dict.get('TARGET_TYPE_COLS', []) or []\n",
    "        \n",
    "        # LOG for debugging \n",
    "        logger.debug(f\"Using STATE_COLS: {STATE_COLS}\")\n",
    "        logger.debug(f\"Using SPECIES_COLS: {SPECIES_COLS}\")\n",
    "        logger.debug(f\"Using TARGET_TYPE_COLS: {TARGET_TYPE_COLS}\")\n",
    "        \n",
    "        # 1) Try to use numeric dummy columns directly \n",
    "        for col in STATE_COLS:\n",
    "            features.append(_safe_to_float(row.get(col, 0)))\n",
    "        \n",
    "        for col in SPECIES_COLS:\n",
    "            features.append(_safe_to_float(row.get(col, 0)))\n",
    "        \n",
    "        for col in TARGET_TYPE_COLS:\n",
    "            features.append(_safe_to_float(row.get(col, 0)))\n",
    "        \n",
    "        # 2) If the dummy lists are empty OR all zeros (i.e. missing), optionally fallback:\n",
    "        # convert categorical 'State' / 'Species' / 'target_name' into one-hot matching the dummy columns.\n",
    "        def _maybe_onehot_fallback(row, cols, cat_candidates):\n",
    "            \"\"\"\n",
    "            If all values from `cols` are zeros and we have a categorical col present (e.g. 'State' or 'Species'),\n",
    "            return a one-hot vector aligned to `cols`. Otherwise return None (meaning no fallback needed).\n",
    "            \"\"\"\n",
    "            if not cols:\n",
    "                return None\n",
    "            vals = [row.get(c, 0) for c in cols]\n",
    "            # if there exists any numeric non-zero -> no fallback\n",
    "            numeric_vals = pd.to_numeric(pd.Series(vals), errors='coerce').fillna(0.0)\n",
    "            if numeric_vals.sum() > 0:\n",
    "                return None\n",
    "        \n",
    "            # try to find a categorical column among candidates\n",
    "            cat_val = None\n",
    "            for cand in cat_candidates:\n",
    "                if cand in row.index:\n",
    "                    raw = row.get(cand)\n",
    "                    if pd.isna(raw) or raw == '':\n",
    "                        continue\n",
    "                    cat_val = str(raw).strip().lower()\n",
    "                    break\n",
    "            if cat_val is None:\n",
    "                return None\n",
    "        \n",
    "            # build one-hot by tolerant matching between column names and cat_val\n",
    "            onehot = []\n",
    "            for c in cols:\n",
    "                c_norm = c.lower()\n",
    "                score = 0\n",
    "                if c_norm.endswith(cat_val) or c_norm.endswith(cat_val.replace(' ', '_')):\n",
    "                    score = 2\n",
    "                elif cat_val in c_norm or c_norm in cat_val:\n",
    "                    score = 1\n",
    "                elif c_norm.split('_')[-1][:3] == cat_val[:3]:\n",
    "                    score = 1\n",
    "                onehot.append(1.0 if score > 0 else 0.0)\n",
    "        \n",
    "            logger.debug(f\"Fallback one-hot for {cat_candidates}='{cat_val}' => {onehot}\")\n",
    "            return onehot\n",
    "        \n",
    "        # apply fallbacks only if initial dummy columns were all zeros / absent\n",
    "        state_fallback = _maybe_onehot_fallback(row, STATE_COLS, ['State', 'state', 'State_canon', 'state_name'])\n",
    "        if state_fallback is not None:\n",
    "            if STATE_COLS:\n",
    "                features[-len(STATE_COLS):] = state_fallback\n",
    "        \n",
    "        species_fallback = _maybe_onehot_fallback(row, SPECIES_COLS, ['Species', 'species', 'Species_canon'])\n",
    "        if species_fallback is not None:\n",
    "            if SPECIES_COLS:\n",
    "                features[-len(SPECIES_COLS):] = species_fallback\n",
    "        \n",
    "        target_fallback = _maybe_onehot_fallback(row, TARGET_TYPE_COLS, ['target_name', 'Target', 'target'])\n",
    "        if target_fallback is not None:\n",
    "            if TARGET_TYPE_COLS:\n",
    "                features[-len(TARGET_TYPE_COLS):] = target_fallback\n",
    "        return torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    def predicting_species(self, test_row, species_model=None, device=None):\n",
    "        \"\"\"\n",
    "        Predict species for a single test_row.\n",
    "    \n",
    "        Supports:\n",
    "          - per-patch outputs (one logits row per patch) -> argmax per patch -> majority vote\n",
    "          - MIL-style: image-level logits (one logits row for the image) -> single prediction\n",
    "          - outputs as tensor, (tensor, ...) tuple, or dict with \"logits\" or \"pred\"\n",
    "          - dict outputs like {'pred': '<name>'} are handled\n",
    "    \n",
    "        Returns canonical species string (via map_to_fixed_species) or None.\n",
    "        \n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = getattr(self, \"device\", None)\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if species_model is None:\n",
    "            logger.debug(\"predicting_species: species_model is None -> returning None\")\n",
    "            return None\n",
    "    \n",
    "        sample_id = test_row.get(\"sample_id\")\n",
    "        image_id = str(sample_id).split(\"__\")[0] if sample_id is not None else None\n",
    "        cache_key = image_id.lower() if image_id is not None else None\n",
    "        if cache_key is not None and cache_key in getattr(self, \"species_cache\", {}):\n",
    "            return self.species_cache[cache_key]\n",
    "    \n",
    "        img_path = self._resolve_image_path(test_row.get('image_path', ''))\n",
    "        try:\n",
    "            if not img_path.exists():\n",
    "                logger.info(f\"predicting_species: image not found: {img_path}\")\n",
    "                return None\n",
    "            image = self._load_image(img_path)\n",
    "            if not isinstance(image, Image.Image):\n",
    "                image = Image.fromarray(np.asarray(image))\n",
    "    \n",
    "            patches = self._crop_patches(image)\n",
    "            if not patches:\n",
    "                logger.debug(f\"predicting_species: no patches for {img_path}\")\n",
    "                return None\n",
    "    \n",
    "            # Prepare device and remember original device\n",
    "            try:\n",
    "                orig_device = next(species_model.parameters()).device\n",
    "            except Exception:\n",
    "                orig_device = getattr(species_model, \"device\", None)\n",
    "    \n",
    "            target_device = device\n",
    "            moved_model = False\n",
    "            try:\n",
    "                if orig_device is None or orig_device != target_device:\n",
    "                    species_model.to(target_device)\n",
    "                    moved_model = True\n",
    "            except Exception:\n",
    "                logger.info(\"predicting_species: could not move species_model to target device; continuing\")\n",
    "    \n",
    "            species_model.eval()\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "            patch_tensors = []\n",
    "            for p in patches:\n",
    "                if not isinstance(p, Image.Image):\n",
    "                    p = Image.fromarray(np.asarray(p))\n",
    "                patch_tensors.append(transform(p))\n",
    "    \n",
    "            batch = torch.stack(patch_tensors, dim=0).to(target_device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = species_model(batch, return_features=False)\n",
    "    \n",
    "            logits = None\n",
    "            if isinstance(outputs, dict):\n",
    "                if 'pred' in outputs:\n",
    "                    raw_pred = outputs.get('pred')\n",
    "                    if isinstance(raw_pred, (list, tuple, np.ndarray)):\n",
    "                        raw_pred = raw_pred[0] if len(raw_pred) > 0 else None\n",
    "                    if raw_pred is not None:\n",
    "                        raw_pred = str(raw_pred).strip()\n",
    "                    mapped = map_to_fixed_species(raw_pred) if raw_pred else None\n",
    "                    if cache_key is not None:\n",
    "                        self.species_cache[cache_key] = mapped\n",
    "                    return mapped\n",
    "                if 'species' in outputs and isinstance(outputs['species'], str):\n",
    "                    raw_pred = outputs['species']\n",
    "                    mapped = map_to_fixed_species(raw_pred)\n",
    "                    if cache_key is not None:\n",
    "                        self.species_cache[cache_key] = mapped\n",
    "                    return mapped\n",
    "                logits = outputs.get('logits', None)\n",
    "                if logits is None:\n",
    "                    for v in outputs.values():\n",
    "                        if torch.is_tensor(v):\n",
    "                            logits = v\n",
    "                            break\n",
    "    \n",
    "            elif isinstance(outputs, (list, tuple)):\n",
    "                first = outputs[0] if len(outputs) > 0 else None\n",
    "                if isinstance(first, dict):\n",
    "                    if 'pred' in first:\n",
    "                        raw_pred = first.get('pred')\n",
    "                        if isinstance(raw_pred, (list, tuple, np.ndarray)):\n",
    "                            raw_pred = raw_pred[0] if len(raw_pred) > 0 else None\n",
    "                        if raw_pred is not None:\n",
    "                            raw_pred = str(raw_pred).strip()\n",
    "                        mapped = map_to_fixed_species(raw_pred) if raw_pred else None\n",
    "                        if cache_key is not None:\n",
    "                            self.species_cache[cache_key] = mapped\n",
    "                        return mapped\n",
    "                    logits = first.get('logits', None)\n",
    "                else:\n",
    "                    logits = first\n",
    "            else:\n",
    "                logits = outputs\n",
    "    \n",
    "            if logits is None or not torch.is_tensor(logits):\n",
    "                logger.info(\"predicting_species: could not interpret model outputs -> returning None\")\n",
    "                return None\n",
    "    \n",
    "            # detach to CPU for analysis\n",
    "            logits_detached = logits.detach().cpu()\n",
    "    \n",
    "            # Determine per-patch vs image-level\n",
    "            per_patch_mode = False\n",
    "            img_level_logits = None\n",
    "            per_patch_logits = None\n",
    "    \n",
    "            if logits_detached.dim() == 1:\n",
    "                # single-vector -> image-level\n",
    "                img_level_logits = logits_detached.unsqueeze(0)\n",
    "            elif logits_detached.dim() == 2:\n",
    "                n_rows = logits_detached.shape[0]\n",
    "                n_patches = len(patches)\n",
    "                if n_rows == n_patches:\n",
    "                    per_patch_mode = True\n",
    "                    per_patch_logits = logits_detached\n",
    "                elif n_rows == 1:\n",
    "                    img_level_logits = logits_detached\n",
    "                else:\n",
    "                    img_level_logits = logits_detached.mean(dim=0, keepdim=True)\n",
    "            else:\n",
    "                try:\n",
    "                    flat = logits_detached.view(logits_detached.shape[0], -1)\n",
    "                    if flat.dim() == 2 and flat.shape[0] == len(patches):\n",
    "                        per_patch_mode = True\n",
    "                        per_patch_logits = flat\n",
    "                    else:\n",
    "                        img_level_logits = flat.mean(dim=0, keepdim=True)\n",
    "                except Exception:\n",
    "                    logger.info(\"predicting_species: unexpected logits shape; returning None\")\n",
    "                    return None\n",
    "    \n",
    "            predicted_species = None\n",
    "    \n",
    "            if per_patch_mode:\n",
    "                preds = torch.argmax(per_patch_logits, dim=1).cpu().numpy().tolist()\n",
    "                # Map indices -> species names\n",
    "                predicted_list = []\n",
    "                \n",
    "                for idx_val in preds:\n",
    "                    idx_val = int(idx_val)\n",
    "                    species_name = None\n",
    "                    \n",
    "                    # Try model's species_list first\n",
    "                    if hasattr(species_model, \"species_list\") and isinstance(species_model.species_list, (list, tuple)):\n",
    "                        if 0 <= idx_val < len(species_model.species_list):\n",
    "                            species_name = species_model.species_list[idx_val]\n",
    "                        else:\n",
    "                            logger.warning(f\"Per-patch: Index {idx_val} out of range for species_list (len={len(species_model.species_list)})\")\n",
    "                    \n",
    "                    # Try idx_to_species dict if species_list didn't work\n",
    "                    if species_name is None:\n",
    "                        idx_to_species = getattr(species_model, \"idx_to_species\", None) or getattr(species_model, \"idx_to_class\", None)\n",
    "                        if isinstance(idx_to_species, dict):\n",
    "                            if idx_val in idx_to_species:\n",
    "                                species_name = idx_to_species[idx_val]\n",
    "                            else:\n",
    "                                logger.warning(f\"Per-patch: Index {idx_val} not in idx_to_species. Available: {list(idx_to_species.keys())}\")\n",
    "                        else:\n",
    "                            logger.warning(\"Per-patch: No species_list or idx_to_species available!\")\n",
    "                    \n",
    "                    # Fallback: if still None, use \"Unknown\" marker\n",
    "                    if species_name is None:\n",
    "                        species_name = \"Unknown\"\n",
    "                    \n",
    "                    predicted_list.append(str(species_name).strip())\n",
    "    \n",
    "                predicted_list_mapped = [map_to_fixed_species(p) for p in predicted_list]\n",
    "                predicted_species = max(set(predicted_list_mapped), key=predicted_list_mapped.count) if predicted_list_mapped else None\n",
    "    \n",
    "            else:\n",
    "                # single-image logits -> take argmax\n",
    "                try:\n",
    "                    probs = torch.nn.functional.softmax(img_level_logits, dim=1)\n",
    "                    idx = int(torch.argmax(probs, dim=1).cpu().item())\n",
    "                except Exception:\n",
    "                    idx = int(torch.argmax(img_level_logits, dim=1).cpu().item())\n",
    "                \n",
    "                raw_name = None\n",
    "                if hasattr(species_model, \"species_list\") and isinstance(species_model.species_list, (list, tuple)):\n",
    "                    if 0 <= idx < len(species_model.species_list):\n",
    "                        raw_name = species_model.species_list[idx]\n",
    "                    else:\n",
    "                        logger.warning(f\"Image-level: Index {idx} out of range for species_list (len={len(species_model.species_list)})\")\n",
    "                \n",
    "                if raw_name is None:\n",
    "                    idx_to_species = getattr(species_model, \"idx_to_species\", None) or getattr(species_model, \"idx_to_class\", None)\n",
    "                    if isinstance(idx_to_species, dict):\n",
    "                        if idx in idx_to_species:\n",
    "                            raw_name = idx_to_species[idx]\n",
    "                        else:\n",
    "                            logger.warning(f\"Image-level: Index {idx} not in idx_to_species. Available: {list(idx_to_species.keys())}\")\n",
    "                    else:\n",
    "                        logger.warning(\"Image-level: No species mapping available!\")\n",
    "                \n",
    "                if raw_name is None:\n",
    "                    raw_name = \"Unknown\"\n",
    "                \n",
    "                predicted_species = map_to_fixed_species(str(raw_name).strip())\n",
    "            \n",
    "            logger.debug(f\"âœ“ Predicted species: {predicted_species}\")\n",
    "            if cache_key is not None:\n",
    "                if not hasattr(self, \"species_cache\"):\n",
    "                    self.species_cache = {}\n",
    "                self.species_cache[cache_key] = predicted_species\n",
    "            return predicted_species\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"âš  predicting_species failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "        finally:\n",
    "            # ensure model moved back to original device when possible\n",
    "            try:\n",
    "                if 'moved_model' in locals() and moved_model and orig_device is not None:\n",
    "                    species_model.to(orig_device)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    def estimate_height_final(self, image):\n",
    "        try:\n",
    "            try:\n",
    "                if not getattr(self, \"height_model\", None):\n",
    "                    try:\n",
    "                        out_dir = OUTPUTS_DIR if isinstance(OUTPUTS_DIR, Path) else Path(OUTPUTS_DIR)\n",
    "                        ridge_path = out_dir / \"height_ridge.joblib\"\n",
    "                        pl_path = out_dir / \"height_powerlaw.json\"\n",
    "    \n",
    "                        if ridge_path.exists():\n",
    "                            try:\n",
    "                                ridge_model = joblib.load(str(ridge_path))\n",
    "                                self.height_model = ridge_model\n",
    "                                self.height_model_type = getattr(ridge_model, \"height_model_type\", \"log1p\")\n",
    "                                logger.info(f\"Loaded ridge height_model from {ridge_path}\")\n",
    "                            except Exception as e:\n",
    "                                logger.info(f\"Failed to load ridge model: {e}\")\n",
    "    \n",
    "                        # Load powerlaw params if available \n",
    "                        if (not hasattr(self, \"height_a\") or not hasattr(self, \"height_b\")) and pl_path.exists():\n",
    "                            try:\n",
    "                                js = json.loads(pl_path.read_text())\n",
    "                                self.height_a = float(js.get(\"a\", getattr(self, \"height_a\", None) or 0.0))\n",
    "                                self.height_b = float(js.get(\"b\", getattr(self, \"height_b\", None) or 1.0))\n",
    "                                # set sensible model type for powerlaw fallback\n",
    "                                if not hasattr(self, \"height_model_type\"):\n",
    "                                    self.height_model_type = \"log1p_powerlaw\"\n",
    "                                logger.info(f\"Loaded powerlaw params from {pl_path}\")\n",
    "                            except Exception as e:\n",
    "                                logger.debug(f\"Failed to read powerlaw json: {e}\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "            # Convert to PIL for sentinel detection\n",
    "            if isinstance(image, Image.Image):\n",
    "                img_pil = image\n",
    "            else:\n",
    "                img_pil = Image.fromarray(np.uint8(image))\n",
    "            if self._is_sentinel_image(img_pil):\n",
    "                return 0.0\n",
    "    \n",
    "            # Extract features\n",
    "            feats = self.compute_features_from_image(image)\n",
    "            ndvi = float(np.clip(feats.get('ndvi', 0.5), 0.0, 1.0))\n",
    "            texture_norm = float(np.clip(feats.get('texture', 0.02), 0.0, 1.0))\n",
    "            green_intensity = float(np.clip(feats.get('green', 0.4), 0.0, 1.0))\n",
    "            brightness = float(np.clip(feats.get('brightness', 0.5), 0.0, 1.0))\n",
    "            height_proxy = float(np.clip(feats.get('height_proxy', 0.4), 0.0, 1.0))\n",
    "            veg_frac = float(np.clip(feats.get('veg_frac', 0.5), 0.0, 1.0))\n",
    "    \n",
    "            # combined score \n",
    "            MIN_SCORE = 1e-2\n",
    "            combined_score = (\n",
    "                0.35 * ndvi +\n",
    "                0.25 * texture_norm +\n",
    "                0.20 * green_intensity +\n",
    "                0.10 * brightness +\n",
    "                0.10 * height_proxy)\n",
    "            combined_score = float(\n",
    "                np.clip(combined_score * (0.5 + 0.5 * feats.get('veg_frac', 1.0)),\n",
    "                        MIN_SCORE, 1.0))\n",
    "    \n",
    "            height_cm = None\n",
    "    \n",
    "            # 1) USE TRAINED MODEL IF AVAILABLE\n",
    "            # --------------------------------------\n",
    "            if hasattr(self, \"height_model\") and self.height_model is not None:\n",
    "                try:\n",
    "                    vec = np.array([[ndvi, texture_norm, green_intensity,\n",
    "                                     brightness, height_proxy, veg_frac]], dtype=float)\n",
    "                    pred_val = float(self.height_model.predict(vec)[0])\n",
    "    \n",
    "                    model_type = getattr(self, \"height_model_type\", \"log1p\")\n",
    "    \n",
    "                    if model_type == \"log\":\n",
    "                        height_cm = float(np.exp(pred_val))\n",
    "                    elif model_type == \"log1p\":\n",
    "                        height_cm = float(np.expm1(pred_val))\n",
    "                    else:\n",
    "                        height_cm = float(pred_val)\n",
    "                except Exception as e:\n",
    "                    logger.info(f\"Calibrated height_model predict failed: {e}\")\n",
    "                    height_cm = None\n",
    "    \n",
    "            # 2) POWER-LAW FALLBACK (use saved a/b if available)\n",
    "            # --------------------------------------\n",
    "            if height_cm is None or not np.isfinite(height_cm):\n",
    "                a = getattr(self, \"height_a\", None)\n",
    "                b = getattr(self, \"height_b\", None)\n",
    "                model_type = getattr(self, \"height_model_type\", \"log1p_powerlaw\")\n",
    "    \n",
    "                cs = max(float(combined_score), 1e-6)\n",
    "    \n",
    "                if a is not None and b is not None:\n",
    "                    try:\n",
    "                        # If calibration used log1p \n",
    "                        if model_type == \"log1p_powerlaw\":\n",
    "                            height_cm = float(np.expm1(a + b * np.log1p(cs)))\n",
    "                        elif model_type == \"log\":\n",
    "                            # classic log form: log(h) = log(a) + b*log(score)\n",
    "                            height_cm = float(np.exp(np.log(a) + b * np.log(max(cs, 1e-6))))\n",
    "                        else:\n",
    "                            # classic powerlaw a * cs ** b\n",
    "                            height_cm = float(a * (cs ** b))\n",
    "                    except Exception as e:\n",
    "                        logger.info(f\"Powerlaw computation failed: {e}\")\n",
    "                        height_cm = None\n",
    "                else:\n",
    "                    #emergency defaults\n",
    "                    height_cm = 7.7\n",
    "    \n",
    "            # Final clip\n",
    "            return float(np.clip(height_cm, 0.0, getattr(self, \"HEIGHT_MAX\", 100.0)))\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"estimate_height_final failed: {e}\")\n",
    "            return 7.6\n",
    "\n",
    "    \n",
    "    def compute_features_from_image(self, image):\n",
    "        \"\"\"\n",
    "        Return a dict of features needed by calibrator:\n",
    "        keys: ndvi, texture, green, brightness, height_proxy, veg_frac\n",
    "        Accepts PIL Image or numpy array.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(image, Image.Image):\n",
    "                img_pil = image.convert(\"RGB\")\n",
    "                img_np = np.asarray(img_pil, dtype=np.float32)\n",
    "            else:\n",
    "                # if it's a numpy array, create a PIL for sentinel check\n",
    "                img_np = np.asarray(image, dtype=np.float32)\n",
    "                try:\n",
    "                    img_pil = Image.fromarray(\n",
    "                        (np.clip(img_np, 0.0, 1.0) * 255).astype('uint8')\n",
    "                        if img_np.max() <= 1.0 else img_np.astype('uint8')\n",
    "                    ).convert(\"RGB\")\n",
    "                except Exception:\n",
    "                    img_pil = None\n",
    "\n",
    "            # sentinel check \n",
    "            if img_pil is not None and self._is_sentinel_image(img_pil):\n",
    "                return {\n",
    "                    'ndvi': 0.0,\n",
    "                    'texture': 0.0,\n",
    "                    'green': 0.0,\n",
    "                    'brightness': 0.0,\n",
    "                    'height_proxy': 0.0,\n",
    "                    'veg_frac': 0.0}\n",
    "\n",
    "            if img_np.size == 0:\n",
    "                return {'ndvi':0.5,'texture':0.02,'green':0.4,'brightness':0.5,'height_proxy':0.4,'veg_frac':0.5}\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np = img_np / 255.0\n",
    "            gray = np.mean(img_np, axis=2) if img_np.ndim==3 else img_np\n",
    "            lap = laplace(gray)\n",
    "            texture = float(np.nanmean(np.abs(lap)))\n",
    "            texture = float(np.clip(texture/100.0, 0.0, 1.0))\n",
    "            green = img_np[:,:,1] if img_np.ndim==3 and img_np.shape[2]>=2 else gray\n",
    "            green = float(np.nanmean(green))\n",
    "            green = float(np.clip(green,0.0,1.0))\n",
    "            brightness = float(np.nanmean(gray))\n",
    "            height_proxy = self._get_canopy_height_proxy(img_np)\n",
    "            # veg_frac: fraction of pixels considered vegetation\n",
    "            try:\n",
    "                R = img_np[:,:,0] if img_np.ndim==3 else gray\n",
    "                G = img_np[:,:,1] if img_np.ndim==3 else gray\n",
    "                veg_mask = (G > R*1.02) & (G > 0.08)\n",
    "                veg_frac = float(np.clip(np.sum(veg_mask)/veg_mask.size, 0.0, 1.0))\n",
    "            except Exception:\n",
    "                veg_frac = 0.5\n",
    "            # vNDVI fallback\n",
    "            try:\n",
    "                R = img_np[:,:,0] if img_np.ndim==3 else gray\n",
    "                G = img_np[:,:,1] if img_np.ndim==3 else gray\n",
    "                denom = G + R\n",
    "                denom[denom==0] = 1e-8\n",
    "                vndvi = float(np.nanmean((G-R)/denom))\n",
    "                vndvi = float(np.clip(vndvi, 0.0, 1.0))\n",
    "            except Exception:\n",
    "                vndvi = 0.5\n",
    "            return {'ndvi': vndvi, 'texture': texture, 'green': green, 'brightness': brightness, 'height_proxy': height_proxy, 'veg_frac': veg_frac}\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"compute_features_from_image failed: {e}\")\n",
    "            return {'ndvi':0.5,'texture':0.02,'green':0.4,'brightness':0.5,'height_proxy':0.4,'veg_frac':0.5}\n",
    "\n",
    "    \n",
    "    def _get_canopy_height_proxy(self, img_np):\n",
    "        \"\"\"\n",
    "        Extract canopy height proxy from image (robustified).\n",
    "        Expects img_np normalized to [0,1] range (function will attempt to normalize).\n",
    "        Returns float in [0,1].\n",
    "    \n",
    "        \"\"\"\n",
    "        try:\n",
    "            arr = np.asarray(img_np, dtype=np.float32)\n",
    "            if arr.size == 0:\n",
    "                return 0.4\n",
    "    \n",
    "            if arr.max() > 1.0:\n",
    "                arr = arr / 255.0\n",
    "    \n",
    "            # grayscale\n",
    "            if arr.ndim == 3:\n",
    "                gray = np.mean(arr, axis=2)\n",
    "            else:\n",
    "                gray = arr\n",
    "    \n",
    "            # vegetation mask \n",
    "            try:\n",
    "                if arr.ndim == 3 and arr.shape[2] >= 2:\n",
    "                    R = arr[:, :, 0]\n",
    "                    G = arr[:, :, 1]\n",
    "                    factor = 1.05\n",
    "                    min_green = max(0.08, np.percentile(G.ravel(), 25) * 0.6)\n",
    "                    veg_mask = (G > R * factor) & (G > min_green)\n",
    "                    if np.sum(veg_mask) < max(10, 0.01 * gray.size):\n",
    "                        veg_mask = (G > R * 1.02) & (G > np.percentile(G.ravel(), 10) * 0.4)\n",
    "                    if np.sum(veg_mask) == 0:\n",
    "                        veg_mask = np.ones_like(gray, dtype=bool)\n",
    "                else:\n",
    "                    veg_mask = np.ones_like(gray, dtype=bool)\n",
    "            except Exception:\n",
    "                veg_mask = np.ones_like(gray, dtype=bool)\n",
    "    \n",
    "            try:\n",
    "                if np.any(veg_mask):\n",
    "                    texture_variance = float(np.var(gray[veg_mask]))\n",
    "                else:\n",
    "                    texture_variance = float(np.var(gray))\n",
    "            except Exception:\n",
    "                texture_variance = 0.02\n",
    "    \n",
    "            # local contrast \n",
    "            try:\n",
    "                values = gray[veg_mask].ravel()\n",
    "                p90 = float(np.percentile(values, 90))\n",
    "                p10 = float(np.percentile(values, 10))\n",
    "                contrast = max(0.0, p90 - p10)\n",
    "            except Exception:\n",
    "                contrast = 0.1\n",
    "    \n",
    "            proxy_raw = 0.7 * texture_variance + 0.3 * (contrast ** 1.0)\n",
    "            # robust normalization: divide by reasonable expected max (0.08) then clip\n",
    "            height_proxy = float(np.clip(proxy_raw / (0.08 + 1e-8), 0.0, 1.0))\n",
    "    \n",
    "            logger.debug(f\"Canopy height proxy (var={texture_variance:.4f}, contrast={contrast:.4f}) -> {height_proxy:.3f}\")\n",
    "            return height_proxy\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Canopy height proxy estimation failed: {e}\")\n",
    "            return 0.4\n",
    "\n",
    "    \n",
    "    def estimate_month_and_ndvi_from_image(self, image):\n",
    "        \"\"\"\n",
    "        Estimate growing season month AND vegetation health (NDVI) from image.\n",
    "    \n",
    "        Args:\n",
    "            image: numpy array of shape (H, W, C) or PIL Image\n",
    "    \n",
    "        Returns:\n",
    "            tuple: (estimated_month (int), estimated_ndvi (float))\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(image, Image.Image):\n",
    "                img_np = np.asarray(image, dtype=np.float32)\n",
    "            else:\n",
    "                img_np = np.asarray(image, dtype=np.float32)\n",
    "    \n",
    "            # Validate shape\n",
    "            if img_np.ndim != 3:\n",
    "                logger.warning(f\"Unexpected image shape: {getattr(img_np, 'shape', None)}\")\n",
    "                return 6, 0.5\n",
    "    \n",
    "            h, w, c = img_np.shape\n",
    "            img_np = img_np.astype(np.float32)\n",
    "    \n",
    "            # scale to [0,1] if necessary\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np = img_np / 255.0\n",
    "    \n",
    "            RED = img_np[:, :, 0]\n",
    "            GREEN = img_np[:, :, 1]\n",
    "            BLUE = img_np[:, :, 2] if c >= 3 else np.zeros_like(RED)\n",
    "    \n",
    "            denom = GREEN + RED\n",
    "            denom_safe = denom.copy()\n",
    "            denom_safe[np.isclose(denom_safe, 0.0)] = 1e-8\n",
    "    \n",
    "            # vNDVI = (GREEN - RED) / (GREEN + RED)\n",
    "            vndvi_array = (GREEN - RED) / denom_safe\n",
    "            # Clip individual pixel index to reasonable range then mean\n",
    "            vndvi_array_clipped = np.clip(vndvi_array, -1.0, 1.0)\n",
    "            mean_vndvi = float(np.nanmean(vndvi_array_clipped))\n",
    "    \n",
    "            # Validate\n",
    "            if np.isnan(mean_vndvi) or np.isinf(mean_vndvi):\n",
    "                logger.warning(\"Invalid vNDVI detected, using fallback\")\n",
    "                return 6, 0.5\n",
    "    \n",
    "            # Map vNDVI (raw) to [0,1] reasonable range for calibration\n",
    "            # Some vNDVI may be slightly negative for non-vegetation; clamp to 0..1 for month mapping\n",
    "            mean_vndvi_clipped = float(np.clip(mean_vndvi, 0.0, 1.0))\n",
    "    \n",
    "            default_true_min = 0.16\n",
    "            default_true_max = 0.91\n",
    "    \n",
    "            # Default expected raw RGB-ensemble/vNDVI range \n",
    "            rgb_raw_min = 0.0\n",
    "            rgb_raw_max = 0.80\n",
    "    \n",
    "            # Try to read calibration stats from /mnt/data/test.csv if available and has useful columns\n",
    "            try:\n",
    "                calib_path = \"/kaggle/working/outputs/ndvidata.csv\"\n",
    "                if os.path.exists(calib_path):\n",
    "                    try:\n",
    "                        df_cal = pd.read_csv(calib_path, nrows=5)\n",
    "                        # Look for common columns names: avg, min, max OR ndvi_avg, ndvi_min, ndvi_max OR avg_ndvi, min_ndvi, max_ndvi\n",
    "                        if set(['avg','min','max']).issubset(set(df_cal.columns)):\n",
    "                            true_min = float(df_cal['min'].dropna().iat[0])\n",
    "                            true_max = float(df_cal['max'].dropna().iat[0])\n",
    "                            logger.info(\"Calibration loaded from test.csv using columns avg/min/max\")\n",
    "                        elif set(['ndvi_avg','ndvi_min','ndvi_max']).issubset(set(df_cal.columns)):\n",
    "                            true_min = float(df_cal['ndvi_min'].dropna().iat[0])\n",
    "                            true_max = float(df_cal['ndvi_max'].dropna().iat[0])\n",
    "                            logger.info(\"Calibration loaded from test.csv using ndvi_avg/min/max\")\n",
    "                        elif set(['avg_ndvi','min_ndvi','max_ndvi']).issubset(set(df_cal.columns)):\n",
    "                            true_min = float(df_cal['min_ndvi'].dropna().iat[0])\n",
    "                            true_max = float(df_cal['max_ndvi'].dropna().iat[0])\n",
    "                            logger.info(\"Calibration loaded from test.csv using avg_ndvi/min_ndvi/max_ndvi\")\n",
    "                        else:\n",
    "                            # Fallback to using first-row numeric values if present \n",
    "                            first_row = df_cal.iloc[0].to_dict()\n",
    "                            nums = [v for v in first_row.values() if isinstance(v, (int, float, np.floating, np.integer))]\n",
    "                            if len(nums) >= 3:\n",
    "                                # assume ordering avg,min,max or avg,min,max-like â€” pick min and max heuristically\n",
    "                                true_min = float(min(nums))\n",
    "                                true_max = float(max(nums))\n",
    "                                logger.info(\"Calibration heuristically inferred from test.csv first row\")\n",
    "                            else:\n",
    "                                true_min, true_max = default_true_min, default_true_max\n",
    "                    except Exception as e:\n",
    "                        logger.debug(f\"Calibration read failed: {e}\")\n",
    "                        true_min, true_max = default_true_min, default_true_max\n",
    "                else:\n",
    "                    true_min, true_max = default_true_min, default_true_max\n",
    "            except Exception:\n",
    "                true_min, true_max = default_true_min, default_true_max\n",
    "    \n",
    "            # If the inferred true range is degenerate, fall back\n",
    "            if not (np.isfinite(true_min) and np.isfinite(true_max) and (true_max > true_min)):\n",
    "                true_min, true_max = default_true_min, default_true_max\n",
    "    \n",
    "            fused = mean_vndvi_clipped  \n",
    "            denom_scale = (rgb_raw_max - rgb_raw_min) if (rgb_raw_max - rgb_raw_min) != 0 else 1e-8\n",
    "            fused_calibrated = (fused - rgb_raw_min) / denom_scale\n",
    "            fused_calibrated = fused_calibrated * (true_max - true_min) + true_min\n",
    "            fused_calibrated = float(np.clip(fused_calibrated, true_min, true_max))\n",
    "    \n",
    "            # Final month estimate \n",
    "            month = self._estimate_month_from_ndvi(fused_calibrated)\n",
    "            logger.info(f\"Image analysis: raw_vNDVI={mean_vndvi:.3f}, clipped={mean_vndvi_clipped:.3f} \"\n",
    "                        f\"â†’ calibrated_NDVI={fused_calibrated:.3f} â†’ Month {month}\")\n",
    "    \n",
    "            return month, fused_calibrated\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in NDVI estimation: {e}\")\n",
    "            return 6, 0.5\n",
    "\n",
    "    \n",
    "    def estimate_month_and_ndvi_ensemble(self, image, species=None):\n",
    "        \"\"\"\n",
    "        RGB-based NDVI ensemble estimator with calibration.\n",
    "    \n",
    "        If `species` is provided and `/kaggle/working/outputs/ndvidata.csv` exists,\n",
    "        calibration uses that species' ndvi_min/ndvi_max (and ndvi_mean) for mapping.\n",
    "        Otherwise fall back to the old test.csv heuristics and defaults.\n",
    "        Returns (month:int, calibrated_ndvi:float)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import PIL.Image as PILImage   \n",
    "            # --- Normalize / ensure numpy array ---\n",
    "            img_np = np.asarray(image, dtype=np.float32)\n",
    "            # build a PIL copy for sentinel check if needed\n",
    "            if not isinstance(image, PILImage.Image):\n",
    "                try:\n",
    "                    if img_np.max() <= 1.0:\n",
    "                        img_pil_for_check = PILImage.fromarray((img_np * 255).astype('uint8'))\n",
    "                    else:\n",
    "                        img_pil_for_check = PILImage.fromarray((img_np).astype('uint8'))\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        img_pil_for_check = PILImage.fromarray(np.uint8(image))\n",
    "                    except Exception:\n",
    "                        img_pil_for_check = None\n",
    "            else:\n",
    "                img_pil_for_check = image\n",
    "            if self._is_sentinel_image(img_pil_for_check):\n",
    "                month = self._estimate_month_from_ndvi(0.0) if hasattr(self, \"_estimate_month_from_ndvi\") else 6\n",
    "                return month, 0.0\n",
    "            # scale to [0,1]\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np = img_np / 255.0\n",
    "            MAX_NDVI_SIZE = 512\n",
    "            if img_np.ndim == 3:\n",
    "                h, w = img_np.shape[:2]\n",
    "                max_side = max(h, w)\n",
    "                if max_side > MAX_NDVI_SIZE:\n",
    "                    scale = MAX_NDVI_SIZE / float(max_side)\n",
    "                    new_w, new_h = int(round(w * scale)), int(round(h * scale))\n",
    "                    # use cv2 if available for speed; fall back to PIL\n",
    "                    try:\n",
    "                        img_small = cv2.resize(img_np, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "                    except Exception:\n",
    "                        from PIL import Image\n",
    "                        img_pil = Image.fromarray((img_np * 255).astype('uint8'))\n",
    "                        img_pil = img_pil.resize((new_w, new_h), Image.BILINEAR)\n",
    "                        img_small = np.asarray(img_pil, dtype=np.float32) / 255.0\n",
    "                    img_np = img_small\n",
    "    \n",
    "            # Basic shape check\n",
    "            if img_np.ndim != 3 or img_np.shape[2] < 3:\n",
    "                logger.warning(\"estimate_month_and_ndvi_ensemble: unexpected image shape\")\n",
    "                return 6, 0.5\n",
    "\n",
    "            R = img_np[:, :, 0]\n",
    "            G = img_np[:, :, 1]\n",
    "            B = img_np[:, :, 2]\n",
    "            \n",
    "            eps = 1e-6  \n",
    "            \n",
    "            # ---- vNDVI \n",
    "            vndvi = (G - R) / (G + R + eps)\n",
    "            vndvi = np.clip(vndvi, -1.0, 1.0)\n",
    "            vndvi_mean = float(np.nanmean(vndvi))\n",
    "            \n",
    "            # ---- RGBVI \n",
    "            rgbvi = (G*G - R*B) / (G*G + R*B + eps)\n",
    "            rgbvi = np.clip(rgbvi, -1.0, 1.0)\n",
    "            rgbvi_mean = float(np.nanmean(rgbvi))\n",
    "            rgbvi_mean = max(rgbvi_mean, 0.0)  \n",
    "            \n",
    "            # ---- VARI\n",
    "            den = (G + R - B)\n",
    "            vari = (G - R) / (den + eps)\n",
    "            vari = np.clip(vari, -1.0, 1.0)\n",
    "            vari_mean = float(np.nanmean(vari))\n",
    "            vari_mean = max(vari_mean, 0.0)  \n",
    "            \n",
    "            texture = float(np.std(G) / (np.mean(G) + eps))\n",
    "            texture = np.clip(texture, 0.0, 1.0)\n",
    "            \n",
    "            # STEP 3 â€” Adaptive Fusion (raw RGB NDVI) \n",
    "            green_intensity = float(np.nanmean(G))\n",
    "            \n",
    "            if green_intensity < 0.30:                      \n",
    "                fused_raw = (\n",
    "                    0.25 * vndvi_mean +\n",
    "                    0.25 * rgbvi_mean +\n",
    "                    0.35 * vari_mean +\n",
    "                    0.15 * texture\n",
    "                )\n",
    "            \n",
    "            elif green_intensity > 0.65:                   \n",
    "                fused_raw = (\n",
    "                    0.40 * vndvi_mean +\n",
    "                    0.30 * rgbvi_mean +\n",
    "                    0.15 * vari_mean +\n",
    "                    0.15 * texture\n",
    "                )\n",
    "            \n",
    "            else:                                        \n",
    "                fused_raw = (\n",
    "                    0.33 * vndvi_mean +\n",
    "                    0.33 * rgbvi_mean +\n",
    "                    0.22 * vari_mean +\n",
    "                    0.12 * texture\n",
    "                )\n",
    "            \n",
    "            fused_raw = float(np.clip(fused_raw, 0.0, 1.0))\n",
    "    \n",
    "            #  STEP 4 â€” Load Calibration Stats (prefer species table) \n",
    "            default_true_min = 0.16\n",
    "            default_true_max = 0.91\n",
    "    \n",
    "            # typical observed range of raw fused RGB index (tunable)\n",
    "            rgb_raw_min = 0.0\n",
    "            rgb_raw_max = 0.80\n",
    "    \n",
    "            true_min, true_max = default_true_min, default_true_max\n",
    "    \n",
    "            # 1) If species provided, try per-species NDVI table first\n",
    "            try:\n",
    "                if species is not None:\n",
    "                    ndvi_table_path = \"/kaggle/working/outputs/ndvidata.csv\" \n",
    "                    if hasattr(self, \"_ndvi_table\") and getattr(self, \"_ndvi_table\") is not None:\n",
    "                        ndvi_df = self._ndvi_table\n",
    "                    else:\n",
    "                        if pd.io.common.file_exists(ndvi_table_path):\n",
    "                            ndvi_df = pd.read_csv(ndvi_table_path)\n",
    "                            self._ndvi_table = ndvi_df\n",
    "                        else:\n",
    "                            ndvi_df = None\n",
    "    \n",
    "                    if ndvi_df is not None and 'species' in ndvi_df.columns:\n",
    "                        # match species \n",
    "                        mask = ndvi_df['species'].astype(str).str.lower() == str(species).lower()\n",
    "                        if mask.any():\n",
    "                            row = ndvi_df[mask].iloc[0]\n",
    "                            # prefer ndvi_min/ndvi_max or ndvi_raw_min/raw_max if present:\n",
    "                            if 'ndvi_min' in row.index and 'ndvi_max' in row.index:\n",
    "                                candidate_min = float(row.get('ndvi_min', np.nan))\n",
    "                                candidate_max = float(row.get('ndvi_max', np.nan))\n",
    "                            elif 'min' in row.index and 'max' in row.index:\n",
    "                                candidate_min = float(row.get('min', np.nan))\n",
    "                                candidate_max = float(row.get('max', np.nan))\n",
    "                            else:\n",
    "                                candidate_min = float(row.get('ndvi_mean', np.nan)) - 0.15\n",
    "                                candidate_max = float(row.get('ndvi_mean', np.nan)) + 0.15\n",
    "    \n",
    "                            if np.isfinite(candidate_min) and np.isfinite(candidate_max) and candidate_max > candidate_min:\n",
    "                                true_min, true_max = float(candidate_min), float(candidate_max)\n",
    "                                logger.debug(f\"Calibration using species '{species}' stats: min={true_min:.3f}, max={true_max:.3f}\")\n",
    "                            else:\n",
    "                                logger.info(f\"Species stats found but invalid for '{species}', falling back.\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to use per-species ndvi table for calibration: {e}\")\n",
    "    \n",
    "            # 2) If species not used or failed, try the old test.csv calibration (as fallback)\n",
    "            if (true_max <= true_min) or (true_min == default_true_min and true_max == default_true_max):\n",
    "                try:\n",
    "                    calib_path = \"/kaggle/working/outputs/ndvidata.csv\" \n",
    "                    if pd.io.common.file_exists(calib_path):\n",
    "                        df_cal = pd.read_csv(calib_path)\n",
    "                        cols = set(df_cal.columns.str.lower())\n",
    "                        # support multiple naming conventions\n",
    "                        if {'avg', 'min', 'max'}.issubset(cols):\n",
    "                            true_min = float(df_cal['min'].dropna().iloc[0])\n",
    "                            true_max = float(df_cal['max'].dropna().iloc[0])\n",
    "                        elif {'ndvi_avg', 'ndvi_min', 'ndvi_max'}.issubset(cols):\n",
    "                            true_min = float(df_cal['ndvi_min'].dropna().iloc[0])\n",
    "                            true_max = float(df_cal['ndvi_max'].dropna().iloc[0])\n",
    "                        elif {'avg_ndvi', 'min_ndvi', 'max_ndvi'}.issubset(cols):\n",
    "                            true_min = float(df_cal['min_ndvi'].dropna().iloc[0])\n",
    "                            true_max = float(df_cal['max_ndvi'].dropna().iloc[0])\n",
    "                        else:\n",
    "                            # try first numeric min/max-looking columns\n",
    "                            for c in df_cal.columns:\n",
    "                                if 'min' in c.lower():\n",
    "                                    true_min = float(df_cal[c].dropna().iloc[0])\n",
    "                                if 'max' in c.lower():\n",
    "                                    true_max = float(df_cal[c].dropna().iloc[0])\n",
    "                        logger.debug(f\"Calibration from {calib_path}: min={true_min:.3f}, max={true_max:.3f}\")\n",
    "                except Exception as e:\n",
    "                    logger.info(f\"No calibration csv usable or failed to parse: {e}\")\n",
    "    \n",
    "            # final safety checks & fallback\n",
    "            if not np.isfinite(true_min) or not np.isfinite(true_max) or true_max <= true_min:\n",
    "                true_min, true_max = default_true_min, default_true_max\n",
    "                logger.info(f\"Using default calibration min={true_min}, max={true_max}\")\n",
    "    \n",
    "            #  STEP 5 â€” Linear Calibration (map fused_raw -> true_min..true_max)\n",
    "            denom_scale = (rgb_raw_max - rgb_raw_min) if (rgb_raw_max - rgb_raw_min) != 0 else 1e-8\n",
    "            fused_calibrated = (fused_raw - rgb_raw_min) / denom_scale\n",
    "            fused_calibrated = fused_calibrated * (true_max - true_min) + true_min\n",
    "            fused_calibrated = float(np.clip(fused_calibrated, true_min, true_max))\n",
    "    \n",
    "            # STEP 6 â€” Compute Month and return \n",
    "            month = self._estimate_month_from_ndvi(fused_calibrated)\n",
    "    \n",
    "            logger.debug(\n",
    "                f\"RGB Ensemble: vNDVI={vndvi_mean:.3f}, RGBVI={rgbvi_mean:.3f}, VARI={vari_mean:.3f}, \"\n",
    "                f\"FusedRaw={fused_raw:.3f} â†’ Calibrated={fused_calibrated:.3f}, Month={month}\")\n",
    "            return month, fused_calibrated\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Ensemble RGB NDVI calculation failed: {e}\")\n",
    "            return 6, 0.5\n",
    "\n",
    "    \n",
    "    def _estimate_month_from_ndvi(self, ndvi):\n",
    "        \"\"\"\n",
    "        Estimate month from NDVI using data-driven approach.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not hasattr(self, '_month_profiles'):\n",
    "                self._build_month_profiles()\n",
    "    \n",
    "            if not self._month_profiles:\n",
    "                logger.warning(\"No month profiles available, returning default month 6\")\n",
    "                return 6\n",
    "    \n",
    "            best_month = 6\n",
    "            best_score = -1.0\n",
    "    \n",
    "            for month, profile in self._month_profiles.items():\n",
    "                # Use safe std\n",
    "                profile_std = float(profile.get('std', 0.05))\n",
    "                profile_mean = float(profile.get('mean', 0.5))\n",
    "                # z-score\n",
    "                z_score = (ndvi - profile_mean) / (profile_std + 1e-8)\n",
    "                likelihood = math.exp(-0.5 * (z_score * z_score))\n",
    "                frequency_weight = profile.get('count', 1) / max(p['count'] for p in self._month_profiles.values())\n",
    "                score = likelihood # *frequency_weight removed to prevent bias\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_month = int(month)\n",
    "    \n",
    "            return best_month\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error estimating month: {e}\")\n",
    "            return 6\n",
    "\n",
    "    \n",
    "    def _build_month_profiles(self):\n",
    "        \"\"\"\n",
    "        Build NDVI statistical profiles for each month from training data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.train_df is None:\n",
    "                logger.warning(\"train_df not available, cannot build month profiles\")\n",
    "                self._month_profiles = {}\n",
    "                return\n",
    "    \n",
    "            train_df_copy = self.train_df.copy()\n",
    "            train_df_copy['Month'] = pd.to_datetime(train_df_copy['Sampling_Date'], errors='coerce').dt.month\n",
    "    \n",
    "            self._month_profiles = {}\n",
    "            for month in range(1, 13):\n",
    "                month_data = train_df_copy[train_df_copy['Month'] == month]['Pre_GSHH_NDVI'].dropna().astype(float)\n",
    "                if len(month_data) > 0:\n",
    "                    mean_val = float(month_data.mean())\n",
    "                    std_val = float(month_data.std()) if month_data.std() > 0 else 0.05\n",
    "                    std_val = max(std_val, 0.05)  # floor\n",
    "                    self._month_profiles[month] = {\n",
    "                        'mean': mean_val,\n",
    "                        'std': std_val,\n",
    "                        'count': int(len(month_data)),\n",
    "                    }\n",
    "    \n",
    "            logger.debug(f\"âœ“ Built month profiles for {len(self._month_profiles)} months\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error building month profiles: {e}\")\n",
    "            self._month_profiles = {}\n",
    "\n",
    "    def _intelligent_feature_fetch(self, test_row, species_model=None, prediction=None, device=None):\n",
    "        \"\"\"\n",
    "        Intelligent fallback with image-level caching to avoid recomputing NDVI/height/species \n",
    "        for rows that share the same image_id / sample_id.\n",
    "        \"\"\"\n",
    "        sample_id = test_row.get(\"sample_id\")\n",
    "        target_name = test_row.get(\"target_name\")\n",
    "    \n",
    "        # Normalize keys to match lookups built with .strip().lower()\n",
    "        target_name_norm = str(target_name).strip().lower() if target_name is not None else \"\"\n",
    "        sample_id_norm = str(sample_id).strip().lower() if sample_id is not None else \"\"\n",
    "        image_id = sample_id_norm.split(\"__\")[0] if sample_id_norm else None\n",
    "    \n",
    "        # initialize lookups safely\n",
    "        TRAIN_BY_SAMPLE_ID_TARGET = self.lookups_dict.get('TRAIN_BY_SAMPLE_ID_TARGET', {})\n",
    "        TRAIN_BY_IMAGE_SPECIES_TARGET = self.lookups_dict.get('TRAIN_BY_IMAGE_SPECIES_TARGET', {})\n",
    "        TRAIN_BY_IMAGE_ID_TARGET = self.lookups_dict.get('TRAIN_BY_IMAGE_ID_TARGET', {})\n",
    "        TRAIN_BY_TARGET_STATE_SPECIES = self.lookups_dict.get('TRAIN_BY_TARGET_STATE_SPECIES', {})\n",
    "        \n",
    "        # Diagnostics \n",
    "        lvl1_count = 0\n",
    "        if target_name_norm in TRAIN_BY_SAMPLE_ID_TARGET:\n",
    "            try:\n",
    "                lvl1_count = sum(len(v) for v in TRAIN_BY_SAMPLE_ID_TARGET.get(target_name_norm, {}).values())\n",
    "            except Exception:\n",
    "                lvl1_count = len(TRAIN_BY_SAMPLE_ID_TARGET.get(target_name_norm, {}))\n",
    "        lvl2_image_count = len(TRAIN_BY_IMAGE_ID_TARGET.get(target_name_norm, {}))\n",
    "        lvl2_species_count = len(TRAIN_BY_IMAGE_SPECIES_TARGET.get(target_name_norm, {}))\n",
    "        lvl3_count = len(TRAIN_BY_TARGET_STATE_SPECIES.get(target_name_norm, {}))\n",
    "        logger.debug(f\"_intelligent_feature_fetch: target_name_norm='{target_name_norm}', image_id='{image_id}'\")\n",
    "        logger.debug(f\"Lookup sizes: level1={lvl1_count}, level2_image={lvl2_image_count}, level2_species={lvl2_species_count}, level3={lvl3_count}\")\n",
    "    \n",
    "        # IMAGE-LEVEL CACHE (keyed by image_id if available, else sample_id_norm) \n",
    "        cache_key = image_id or sample_id_norm or test_row.get('image_path', '')\n",
    "        if not hasattr(self, 'test_features_cache') or self.test_features_cache is None:\n",
    "            # ensure cache exists\n",
    "            self.test_features_cache = {}\n",
    "    \n",
    "        cached = self.test_features_cache.get(cache_key, None)\n",
    "    \n",
    "        # If we have a cached computed-image object, reuse it\n",
    "        if cached is None:\n",
    "            # compute and store\n",
    "            img_path = self._resolve_image_path(test_row.get('image_path', ''))\n",
    "            test_image = self._load_image(img_path)\n",
    "            test_image_np = np.array(test_image)\n",
    "    \n",
    "            # expensive computations we want to cache\n",
    "            try:\n",
    "                estimated_height = self.estimate_height_final(test_image_np)\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"estimate_height_final failed: {e}\")\n",
    "                estimated_height = 7.5\n",
    "    \n",
    "            try:\n",
    "                estimated_month, estimated_ndvi = self.estimate_month_and_ndvi_ensemble(test_image_np, species=prediction)\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"estimate_month_and_ndvi_from_image failed: {e}\")\n",
    "                try:\n",
    "                    estimated_month, estimated_ndvi =  self.estimate_month_and_ndvi_from_image(test_image_np)\n",
    "                except Exception:\n",
    "                    estimated_month, estimated_ndvi = 6, 0.5\n",
    "\n",
    "            MONTH_TO_DOY = {\n",
    "                        1: 16, 2: 47, 3: 75, 4: 106, 5: 136, 6: 167,\n",
    "                        7: 197, 8: 228, 9: 259, 10: 289, 11: 320, 12: 350}\n",
    "            estimated_month = int(estimated_month)\n",
    "            estimated_doy = MONTH_TO_DOY.get(estimated_month, 180)\n",
    "            estimated_quarter = max(1, (estimated_month - 1) // 3 + 1)\n",
    "    \n",
    "            # veg_frac computed by compute_features_from_image \n",
    "            try:\n",
    "                feats = self.compute_features_from_image(test_image)\n",
    "                veg_frac = float(np.clip(feats.get('veg_frac', 0.5), 0.0, 1.0))\n",
    "            except Exception:\n",
    "                veg_frac = 0.5\n",
    "    \n",
    "            # species prediction: allow a pre-supplied 'prediction' to override; otherwise compute once\n",
    "            predicted_species = prediction\n",
    "            if (predicted_species is None) and (species_model is not None):\n",
    "                try:\n",
    "                    # predicting_species will do patching and model inference; expensive so we cache result\n",
    "                    predicted_species = self.predicting_species(test_row, species_model=species_model, device=device)\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"predicting_species failed: {e}\")\n",
    "                    predicted_species = None\n",
    "    \n",
    "            # normalize some cached values\n",
    "            def _norm_species_name(s):\n",
    "                if s is None:\n",
    "                    return None\n",
    "                s2 = str(s).strip().lower()\n",
    "                s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "                s2 = s2.replace('.', '')\n",
    "                return s2\n",
    "    \n",
    "            predicted_species_norm = _norm_species_name(predicted_species)\n",
    "    \n",
    "            cached = {\n",
    "                'image_path': str(img_path),\n",
    "                'ndvi': float(np.clip(estimated_ndvi, 0.0, 1.0)),\n",
    "                'month': int(estimated_month),\n",
    "                'doy': int(estimated_doy),\n",
    "                'quarter': int(estimated_quarter),\n",
    "                'estimated_height': float(estimated_height),\n",
    "                'veg_frac': float(veg_frac),\n",
    "                'predicted_species': predicted_species,\n",
    "                'predicted_species_norm': predicted_species_norm\n",
    "            }\n",
    "            cached['state'] = None\n",
    "            # store in cache\n",
    "            try:\n",
    "                self.test_features_cache[cache_key] = cached\n",
    "            except Exception:\n",
    "                # if cache write fails for any reason, ignore â€” caching is optional\n",
    "                logger.debug(\"Warning: failed to write to test_features_cache\")\n",
    "    \n",
    "        else:\n",
    "            # update with any new 'prediction' passed in (higher-level caller may have predicted species already)\n",
    "            if prediction is not None:\n",
    "                cached['predicted_species'] = prediction\n",
    "                # also normalized form\n",
    "                try:\n",
    "                    s = prediction\n",
    "                    s2 = str(s).strip().lower()\n",
    "                    s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "                    s2 = s2.replace('.', '')\n",
    "                    cached['predicted_species_norm'] = s2\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "        # Now reuse cached values for fallback decisions\n",
    "        estimated_ndvi = float(np.clip(cached.get('ndvi', 0.5), 0.0, 1.0))\n",
    "        estimated_month = int(cached.get('month', 6))\n",
    "        estimated_doy = int(cached.get('doy', int(estimated_month * 30.4)))\n",
    "        estimated_quarter = int(cached.get('quarter', max(1, (estimated_month - 1) // 3 + 1)))\n",
    "        estimated_height = float(cached.get('estimated_height', 7.6))\n",
    "        veg_frac = float(cached.get('veg_frac', 0.5))\n",
    "        predicted_species = cached.get('predicted_species', None)\n",
    "        predicted_species_norm = cached.get('predicted_species_norm', None)\n",
    "    \n",
    "        # If predictor returned a dict, extract the 'pred' field\n",
    "        if isinstance(predicted_species, dict):\n",
    "            predicted_species = predicted_species.get('pred', None)\n",
    "    \n",
    "        # convenience normalizer used by lookup matching later\n",
    "        def _norm_species_name(s):\n",
    "            if s is None:\n",
    "                return None\n",
    "            s2 = str(s).strip().lower()\n",
    "            s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "            s2 = s2.replace('.', '')\n",
    "            return s2\n",
    "    \n",
    "        REVERSE_STATE_MAP = {'tas': 'Tas', 'nsw': 'NSW', 'wa': 'WA', 'vic': 'Vic'} \n",
    "        predicted_species_norm = predicted_species_norm or _norm_species_name(predicted_species)\n",
    "        logger.debug(f\"Cached image-level features used: ndvi={estimated_ndvi:.3f}, month={estimated_month}, height={estimated_height:.2f}, species_norm={predicted_species_norm}\")\n",
    "        cached_state = cached.get('state', None)\n",
    "        # LEVEL 1: state + species\n",
    "        try:\n",
    "            level3 = TRAIN_BY_TARGET_STATE_SPECIES.get(target_name_norm, {})\n",
    "            if not level3:\n",
    "                logger.info(f\"LEVEL 3 empty for target '{target_name_norm}' (no TRAIN_BY_TARGET_STATE_SPECIES entries)\")\n",
    "            else:\n",
    "                if predicted_species_norm:\n",
    "                    for state, species_dict in level3.items():\n",
    "                        if predicted_species_norm in species_dict:\n",
    "                            # use cached image-level estimates for ndvi/height/month\n",
    "                            row = random.choice(species_dict[predicted_species_norm])\n",
    "                            state_counts = {'tas': 690, 'vic': 560, 'nsw': 375, 'wa': 160}\n",
    "                            state0 = state  \n",
    "                            states = np.array(list(state_counts.keys()), dtype=object)\n",
    "                            counts = np.array(list(state_counts.values()), dtype=float)\n",
    "                            total = counts.sum()\n",
    "                            emp_probs = counts / total\n",
    "                            state_frequency = state_counts[state0] / total\n",
    "                            alpha = 0.3 if state_frequency < 0.25 else 0.5\n",
    "                            prior = np.zeros_like(emp_probs)\n",
    "                            prior[states == state0] = 1.0\n",
    "                            final_probs = alpha * prior + (1.0 - alpha) * emp_probs\n",
    "                            final_probs = final_probs / final_probs.sum() \n",
    "                            state_new = np.random.choice(states, p=final_probs)\n",
    "                            state_final = cached_state.lower() if cached_state is not None else state_new \n",
    "                            fetched = {\n",
    "                                'ndvi': estimated_ndvi,\n",
    "                                'height': estimated_height,\n",
    "                                'month': estimated_month,\n",
    "                                'doy': estimated_doy,\n",
    "                                'quarter': estimated_quarter,\n",
    "                                'state': REVERSE_STATE_MAP.get(state_final, state),\n",
    "                                'species': predicted_species,\n",
    "                                'level': 1,\n",
    "                                'source': f\"State+Species: {state_new}-{predicted_species_norm}\",\n",
    "                                'species_source': 'predicted'\n",
    "                            }\n",
    "                            logger.debug(\"Level 1a Fallback Used (The Best)\")\n",
    "                            # cache the state for future rows of the same image\n",
    "                            try:\n",
    "                                state_lower = str(fetched['state']).strip().lower()\n",
    "                                self.test_features_cache[cache_key]['state'] = state_lower\n",
    "                            except:\n",
    "                                pass\n",
    "                            logger.debug(\n",
    "                                    f\"Prediction complete | state={fetched['state']} | \"\n",
    "                                    f\"species={fetched['species']} | ndvi={fetched['ndvi']:.3f} | \"\n",
    "                                    f\"height={fetched['height']:.2f} | source={fetched['source']}\"\n",
    "                                    )\n",
    "                            return fetched\n",
    "    \n",
    "                    # try normalized key matching inside species_dict\n",
    "                    for state, species_dict in level3.items():\n",
    "                        for sp_k in species_dict.keys():\n",
    "                            if _norm_species_name(sp_k) == predicted_species_norm:\n",
    "                                row = random.choice(species_dict[sp_k])\n",
    "                                fetched = {\n",
    "                                    'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                                    'height': row['Height_Ave_cm'],\n",
    "                                    'month': row['Month'],\n",
    "                                    'doy': row['DayOfYear'],\n",
    "                                    'quarter': row['Quarter'],\n",
    "                                    'state': state,\n",
    "                                    'species': row.get('Species', sp_k),\n",
    "                                    'level': 1,\n",
    "                                    'source': f\"State+Species (norm-match): {state}-{sp_k}\",\n",
    "                                    'species_source': 'predicted'\n",
    "                                }\n",
    "                                logger.info(\"Level 1a v2 Fallback Used\")\n",
    "                                return fetched\n",
    "    \n",
    "                # fallback random pick from level1 if any entries exist\n",
    "                if level3:\n",
    "                    state = random.choice(list(level3.keys()))\n",
    "                    species = random.choice(list(level3[state].keys()))\n",
    "                    row = random.choice(level3[state][species])\n",
    "                    fetched = {\n",
    "                        'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                        'height': row['Height_Ave_cm'],\n",
    "                        'month': row['Month'],\n",
    "                        'doy': row['DayOfYear'],\n",
    "                        'quarter': row['Quarter'],\n",
    "                        'state': state,\n",
    "                        'species': species,\n",
    "                        'level': 1,\n",
    "                        'source': f\"State+Species: {state}-{species}\",\n",
    "                        'species_source': 'training_data'\n",
    "                    }\n",
    "                    logger.info(\"Level 1b Fallback Used\")\n",
    "                    return fetched\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 1 failed: {e}\")\n",
    "    \n",
    "        # LEVEL 2: sample_id + target\n",
    "        try:\n",
    "            level1 = TRAIN_BY_SAMPLE_ID_TARGET.get(target_name_norm, {})\n",
    "            if sample_id_norm and sample_id_norm in level1:\n",
    "                row = random.choice(level1[sample_id_norm])\n",
    "                fetched = {\n",
    "                    'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                    'height': row['Height_Ave_cm'],\n",
    "                    'month': row['Month'],\n",
    "                    'doy': row['DayOfYear'],\n",
    "                    'quarter': row['Quarter'],\n",
    "                    'state': row['State'],\n",
    "                    'species': row['Species'],\n",
    "                    'level': 2,\n",
    "                    'source': f\"Exact: {sample_id_norm}\",\n",
    "                    'species_source': 'training_data'\n",
    "                }\n",
    "                logger.info(\"Level 2 Fallback Used\")\n",
    "                return fetched\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 2 failed: {e}\")\n",
    "    \n",
    "        # LEVEL 3: image_id + species\n",
    "        try:\n",
    "            level2_species_map = TRAIN_BY_IMAGE_SPECIES_TARGET.get(target_name_norm, {})\n",
    "            level2_image_map = TRAIN_BY_IMAGE_ID_TARGET.get(target_name_norm, {})\n",
    "    \n",
    "            # 2a: image + species\n",
    "            if image_id and predicted_species_norm:\n",
    "                # try tuple-key first\n",
    "                key_candidates = [\n",
    "                    (image_id, predicted_species_norm),\n",
    "                    (image_id, predicted_species_norm.replace('_', ' ')),\n",
    "                    (image_id, predicted_species_norm.replace('_', ''))\n",
    "                ]\n",
    "                rows = []\n",
    "                for key in key_candidates:\n",
    "                    rows = level2_species_map.get(key, [])\n",
    "                    if rows:\n",
    "                        break\n",
    "    \n",
    "                # if not found, try scanning level2 map for matching image_id and normalized species\n",
    "                if not rows:\n",
    "                    for kk, vals in list(level2_species_map.items()):\n",
    "                        try:\n",
    "                            ik, sk = kk\n",
    "                            if str(ik) == image_id and _norm_species_name(sk) == predicted_species_norm:\n",
    "                                rows = vals\n",
    "                                break\n",
    "                        except Exception:\n",
    "                            # could be string key; try to match roughly\n",
    "                            if isinstance(kk, str) and image_id in kk and predicted_species_norm in kk:\n",
    "                                rows = vals\n",
    "                                break\n",
    "    \n",
    "                if rows:\n",
    "                    row = random.choice(rows)\n",
    "                    fetched = {\n",
    "                        'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                        'height': row['Height_Ave_cm'],\n",
    "                        'month': row['Month'],\n",
    "                        'doy': row['DayOfYear'],\n",
    "                        'quarter': row['Quarter'],\n",
    "                        'state': row['State'],\n",
    "                        'species': row['Species'],\n",
    "                        'level': 3,\n",
    "                        'source': f\"Image {image_id} + Predicted Species\",\n",
    "                        'species_source': 'predicted'\n",
    "                    }\n",
    "                    logger.info(\"Level 3a Fallback Used\")\n",
    "                    return fetched\n",
    "    \n",
    "            # 3b: image only\n",
    "            if image_id and image_id in level2_image_map:\n",
    "                row = random.choice(level2_image_map[image_id])\n",
    "                fetched = {\n",
    "                    'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                    'height': row['Height_Ave_cm'],\n",
    "                    'month': row['Month'],\n",
    "                    'doy': row['DayOfYear'],\n",
    "                    'quarter': row['Quarter'],\n",
    "                    'state': row['State'],\n",
    "                    'species': row['Species'],\n",
    "                    'level': 3,\n",
    "                    'source': f\"Image {image_id}\",\n",
    "                    'species_source': 'training_data'\n",
    "                }\n",
    "                logger.info(\"Level 3b Fallback Used\")\n",
    "                return fetched\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 3 failed: {e}\")\n",
    "    \n",
    "        # LEVEL 4: target statistics\n",
    "        try:\n",
    "            stats = self.lookups_dict.get('TABULAR_STATS_BY_TARGET', {}).get(target_name_norm,\n",
    "                                                                            self.lookups_dict.get('TABULAR_STATS', {}))\n",
    "            ndvi = np.clip(np.random.normal(stats.get('ndvi_mean', estimated_ndvi if 'estimated_ndvi' in locals() else 0.65),\n",
    "                                           stats.get('ndvi_std', 0.15)), 0.0, 1.0)\n",
    "            HEIGHT_MAX = getattr(self, \"HEIGHT_MAX\", self.lookups_dict.get(\"HEIGHT_MAX\", 80.0))\n",
    "            height = np.clip(np.random.normal(stats.get('height_mean', estimated_height if 'estimated_height' in locals() else 7.6),\n",
    "                                              stats.get('height_std', 10.3)), 0.0, HEIGHT_MAX)\n",
    "            doy = int(stats.get('sampling_date_mean', estimated_doy if 'estimated_doy' in locals() else 197))\n",
    "            month = max(1, (doy - 1) // 30 + 1)\n",
    "            quarter = max(1, (month - 1) // 3 + 1)\n",
    "            unique_states = self.lookups_dict.get('UNIQUE_STATES', ['NSW'])\n",
    "            state = np.random.choice(unique_states)\n",
    "            species = predicted_species_norm or np.random.choice(self.lookups_dict.get('UNIQUE_SPECIES', ['clover']))\n",
    "            species_source = 'predicted' if predicted_species_norm else 'training_data'\n",
    "            logger.info(\"Level 4 Fallback Used\")\n",
    "            return {\n",
    "                'ndvi': float(ndvi), 'height': float(height),\n",
    "                'month': int(month), 'doy': int(doy), 'quarter': int(quarter),\n",
    "                'state': state, 'species': species,\n",
    "                'level': 4, 'source': f\"Target stats {target_name_norm}\",\n",
    "                'species_source': species_source\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 4 failed: {e}\")\n",
    "    \n",
    "        # default fallback\n",
    "        logger.info(\"Default Fallback is Being Used.\")\n",
    "        return self._get_default_features(test_row)\n",
    "\n",
    "\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        try:\n",
    "            p = self._resolve_image_path(image_path)\n",
    "\n",
    "            # Missing file â†’ sentinel image\n",
    "            if not p.exists():\n",
    "                self._missing_count = getattr(self, '_missing_count', 0) + 1\n",
    "                if self._missing_count <= 10:\n",
    "                    logger.warning(f\"Image missing {p} â€“ using SENTINEL MAGENTA (#{self._missing_count})\")\n",
    "                return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "            # Load image with OpenCV\n",
    "            img = cv2.imread(str(p), cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                self._missing_count = getattr(self, '_missing_count', 0) + 1\n",
    "                if self._missing_count <= 10:\n",
    "                    logger.warning(f\"Image unreadable {p} â€“ using SENTINEL MAGENTA (#{self._missing_count})\")\n",
    "                return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "            # Convert various channel formats\n",
    "            if img.ndim == 2:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            elif img.shape[2] == 3:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            elif img.shape[2] == 4:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "            else:\n",
    "                try:\n",
    "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                except Exception:\n",
    "                    return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "            return Image.fromarray(img_rgb)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error loading {image_path}: {e}\")\n",
    "            return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "\n",
    "\n",
    "    def _crop_patches(self, image):\n",
    "        patches = []\n",
    "        w, h = image.size\n",
    "        target_w, target_h = 2000, 1000\n",
    "        if (w,h) != (target_w, target_h):\n",
    "            image = image.resize((target_w, target_h), Image.BILINEAR)\n",
    "        crop_coords = [\n",
    "            (0, 0, 500, 500), (500, 0, 1000, 500),\n",
    "            (1000, 0, 1500, 500), (1500, 0, 2000, 500),\n",
    "            (0, 500, 500, 1000), (500, 500, 1000, 1000),\n",
    "            (1000, 500, 1500, 1000), (1500, 500, 2000, 1000),\n",
    "        ]\n",
    "        for left, top, right, bottom in crop_coords:\n",
    "            patch = F.crop(image, top=top, left=left,\n",
    "                          height=bottom-top, width=right-left)\n",
    "            patch = patch.resize((self.model_input_size[0], self.model_input_size[1]), Image.BILINEAR)\n",
    "            patches.append(patch)\n",
    "        return patches\n",
    "\n",
    "    def _get_default_features(self, test_row):\n",
    "        return {\n",
    "            'month': 6,\n",
    "            'doy': 180,\n",
    "            'quarter': 2,\n",
    "            'state': 'NSW',\n",
    "            'species': 'Clover',\n",
    "            'ndvi': 0.6,\n",
    "            'height': 15.0,\n",
    "            'level': -1,\n",
    "            'source': \"Hardcoded defaults (no lookups)\",\n",
    "        }\n",
    "\n",
    "    def _build_features_from_fetch(self, test_row, lookups_dict):\n",
    "        \"\"\"\n",
    "        Build complete tabular feature vector for test row.\n",
    "        \n",
    "        Column order MUST match training:\n",
    "        [numeric_cols | state_cols | species_cols | target_type_cols]\n",
    "        \n",
    "        Returns: (features_tensor, target_idx)\n",
    "        \"\"\"\n",
    "        numeric_cols = lookups_dict.get('TAB_NUMERIC_COLS', [])\n",
    "        state_cols = lookups_dict.get('STATE_COLS', [])\n",
    "        species_cols = lookups_dict.get('SPECIES_COLS', [])\n",
    "        target_type_cols = lookups_dict.get('TARGET_TYPE_COLS', [])\n",
    "        scaler = lookups_dict.get('TAB_SCALER', None)\n",
    "        \n",
    "        # ===== NUMERIC FEATURES =====\n",
    "        raw_numeric = []\n",
    "        for col in numeric_cols:\n",
    "            if col == 'Pre_GSHH_NDVI':\n",
    "                val = float(test_row.get('Pre_GSHH_NDVI', 0.5))\n",
    "                raw_numeric.append(np.clip(val, 0.0, 1.0))\n",
    "            elif col == 'Height_Ave_cm':\n",
    "                val = float(test_row.get('Height_Ave_cm', 10.0))\n",
    "                raw_numeric.append(np.clip(val, 0.0, 100.0))\n",
    "            elif col == 'Month':\n",
    "                val = float(test_row.get('Month', 6))\n",
    "                raw_numeric.append(np.clip(val, 1.0, 12.0))\n",
    "            elif col == 'DayOfYear':\n",
    "                val = float(test_row.get('DayOfYear', 1))\n",
    "                raw_numeric.append(np.clip(val, 1.0, 365.0))\n",
    "            elif col == 'Quarter':\n",
    "                val = float(test_row.get('Quarter', 1))\n",
    "                raw_numeric.append(np.clip(val, 1.0, 4.0))\n",
    "            else:\n",
    "                raw_numeric.append(float(test_row.get(col, 0.0)))\n",
    "        \n",
    "        # Scale numeric features if scaler available\n",
    "        if scaler is not None and len(raw_numeric) > 0:\n",
    "            try:\n",
    "                scaled_numeric = scaler.transform([raw_numeric])[0].tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Scaler transform failed: {e}, using raw values\")\n",
    "                scaled_numeric = raw_numeric\n",
    "        else:\n",
    "            scaled_numeric = raw_numeric\n",
    "        \n",
    "        features = list(scaled_numeric)\n",
    "        \n",
    "        # ===== STATE ONE-HOT =====\n",
    "        def _safe_to_float(x):\n",
    "            if isinstance(x, (bool, np.bool_)):\n",
    "                return 1.0 if x else 0.0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except Exception:\n",
    "                return 0.0\n",
    "        \n",
    "        for col in state_cols:\n",
    "            features.append(_safe_to_float(test_row.get(col, 0)))\n",
    "        \n",
    "        # ===== SPECIES ONE-HOT =====\n",
    "        for col in species_cols:\n",
    "            features.append(_safe_to_float(test_row.get(col, 0)))\n",
    "        \n",
    "        # ===== TARGET TYPE ONE-HOT =====\n",
    "        target_onehot = []\n",
    "        for col in target_type_cols:\n",
    "            target_onehot.append(_safe_to_float(test_row.get(col, 0)))\n",
    "        \n",
    "        for val in target_onehot:\n",
    "            features.append(val)\n",
    "        \n",
    "        # ===== EXTRACT TARGET_IDX (CRITICAL FOR META-LEARNER) =====\n",
    "        # target_idx is the argmax of the one-hot encoding at the END\n",
    "        target_idx = 0\n",
    "        if len(target_onehot) > 0:\n",
    "            try:\n",
    "                target_idx = int(np.argmax(target_onehot))\n",
    "            except Exception:\n",
    "                target_idx = 0\n",
    "        \n",
    "        # ===== RETURN =====\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "        \n",
    "        logger.debug(f\"Built features: {len(features)} dims, target_idx={target_idx}\")\n",
    "        logger.debug(f\"  Numeric: {len(scaled_numeric)} | State: {len(state_cols)} | Species: {len(species_cols)} | Target: {len(target_onehot)}\")\n",
    "        \n",
    "        return features_tensor, target_idx\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self._load_image(row['image_path'])\n",
    "        patches = self._crop_patches(img)\n",
    "    \n",
    "        # build image tensor batch (8 patches)\n",
    "        if self.transform:\n",
    "            images = torch.stack([self.transform(p) for p in patches])\n",
    "        else:\n",
    "            images = torch.stack([transforms.ToTensor()(p) for p in patches])\n",
    "    \n",
    "        # features: test uses intelligent fetch, train/val uses _extract_train_tabular\n",
    "        target_idx = 0  # NEW: Initialize target_idx\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            prediction = self.predicting_species(row, species_model=self.species_model, device=self.device)\n",
    "            fetched = self._intelligent_feature_fetch(\n",
    "                row, species_model=self.species_model, prediction=prediction, device=self.device)\n",
    "            if fetched is None:\n",
    "                fetched = self._get_default_features(row)\n",
    "            \n",
    "            # NEW: Get both features AND target_idx\n",
    "            features_tensor, target_idx = self._build_features_from_fetch(fetched, self.lookups_dict)\n",
    "            features_1d = features_tensor.numpy()\n",
    "        else:\n",
    "            features_1d = self._extract_train_tabular(row).numpy()\n",
    "            \n",
    "            # EXTRACT target_idx from training row (from one-hot encoding)\n",
    "            target_type_cols = self.lookups_dict.get('TARGET_TYPE_COLS', [])\n",
    "            numeric_cols = self.lookups_dict.get('TAB_NUMERIC_COLS', [])\n",
    "            state_cols = self.lookups_dict.get('STATE_COLS', [])\n",
    "            species_cols = self.lookups_dict.get('SPECIES_COLS', [])\n",
    "            \n",
    "            # Position where target one-hot starts\n",
    "            target_start = len(numeric_cols) + len(state_cols) + len(species_cols)\n",
    "            target_end = target_start + len(target_type_cols)\n",
    "            \n",
    "            if target_end <= len(features_1d):\n",
    "                target_onehot = features_1d[target_start:target_end]\n",
    "                try:\n",
    "                    target_idx = int(np.argmax(target_onehot))\n",
    "                except Exception:\n",
    "                    target_idx = 0\n",
    "            else:\n",
    "                target_idx = 0\n",
    "    \n",
    "        # repeat per patch\n",
    "        features = np.repeat(features_1d[np.newaxis, :], self.num_patches, axis=0).astype(np.float32)\n",
    "        features = torch.from_numpy(features).float()\n",
    "    \n",
    "        sample_id = row.get('sample_id', None)\n",
    "        target_name = row.get('target_name', None)\n",
    "    \n",
    "        species_idx = None\n",
    "    \n",
    "        def _norm_species_name_val(s):\n",
    "            if s is None:\n",
    "                return \"mixed\"\n",
    "            s2 = str(s).strip().lower()\n",
    "            s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "            s2 = s2.replace(\".\", \"\")\n",
    "            # treat empty-like values as \"nothing\"\n",
    "            if s2 == \"\" or s2 in {\"nan\", \"none\", \"null\"}:\n",
    "                return \"mixed\"\n",
    "            return s2\n",
    "    \n",
    "        fixed_species_norm = None\n",
    "        try:\n",
    "            scols = self.lookups_dict.get(\"SPECIES_COLS\", None)\n",
    "            if scols:\n",
    "                fixed_species_norm = [\n",
    "                    _norm_species_name_val(c.replace(\"Species_\", \"\")) if isinstance(c, str) else _norm_species_name_val(c)\n",
    "                    for c in scols\n",
    "                ]\n",
    "        except Exception:\n",
    "            fixed_species_norm = None\n",
    "    \n",
    "        if (not fixed_species_norm) and ('FIXED_SPECIES_LIST' in globals()):\n",
    "            fixed_species_norm = [\n",
    "                _norm_species_name_val(s) for s in globals().get('FIXED_SPECIES_LIST', [])\n",
    "            ]\n",
    "        if not fixed_species_norm:\n",
    "            try:\n",
    "                if getattr(self, \"train_df\", None) is not None and 'Species' in self.train_df.columns:\n",
    "                    tmp_list = self.train_df['Species'].fillna('').astype(str).apply(_norm_species_name_val).unique().tolist()\n",
    "                    fixed_species_norm = list(dict.fromkeys(tmp_list))\n",
    "                else:\n",
    "                    fixed_species_norm = [\"nothing\"]\n",
    "            except Exception:\n",
    "                fixed_species_norm = [\"nothing\"]\n",
    "        if \"nothing\" not in fixed_species_norm:\n",
    "            fixed_species_norm = fixed_species_norm + [\"nothing\"]\n",
    "    \n",
    "        if not hasattr(self, \"species_to_idx\") or not isinstance(self.species_to_idx, dict) or len(self.species_to_idx) != len(fixed_species_norm):\n",
    "            self.species_to_idx = {s: i for i, s in enumerate(fixed_species_norm)}\n",
    "            # also store reverse for convenience\n",
    "            self.idx_to_species = {i: s for s, i in self.species_to_idx.items()}\n",
    "    \n",
    "        species_raw = None\n",
    "        if 'Species_canon' in row.index and pd.notna(row.get('Species_canon', None)) and str(row.get('Species_canon')).strip() != \"\":\n",
    "            species_raw = row.get('Species_canon')\n",
    "        else:\n",
    "            species_raw = row.get('Species', None)\n",
    "    \n",
    "        species_norm = _norm_species_name_val(species_raw)\n",
    "    \n",
    "        if species_norm not in self.species_to_idx:\n",
    "            logger.debug(f\"Species '{species_raw}' normalized -> '{species_norm}' not in fixed vocab; mapping to 'nothing'\")\n",
    "            species_norm = \"mixed\"\n",
    "        species_idx = int(self.species_to_idx.get(species_norm, self.species_to_idx.get(\"mixed\", 0)))\n",
    "    \n",
    "        # FINAL RETURNS - NOW INCLUDES target_idx\n",
    "        if self.mode == 'test':\n",
    "            return images, features, species_idx, target_idx, None, sample_id, target_name\n",
    "        else:\n",
    "            target = float(row['target'])\n",
    "            return images, features, species_idx, target_idx, target, sample_id, target_name\n",
    "\n",
    "\n",
    "    def calibrate_height_model(\n",
    "        self,\n",
    "        image_col='image_path',\n",
    "        height_col='Height_Ave_cm',\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        min_positive_samples=5,\n",
    "        fit_ridge=True,\n",
    "        ridge_alphas=(0.01, 0.1, 1.0, 10.0),\n",
    "        verbose=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calibrate height estimator from training images:\n",
    "          - compute features and combined_score using self.compute_features_from_image(image)\n",
    "          - fit power-law (log-linear): log(h) = log(a) + b * log(score) -> saves self.height_a, self.height_b\n",
    "          - optionally fit  to predict log(height) from features -> saves self.height_model and self.height_model_type='log'\n",
    "          - evaluate on a holdout set and return metrics & trained models.\n",
    "    \n",
    "        Returns:\n",
    "            dict with:\n",
    "              - 'n_samples', 'n_positive', 'powerlaw': {'a','b','rmse','mae','r2'}, \n",
    "                'ridge': {model, 'rmse','mae','r2'} (if fit_ridge True), \n",
    "              - 'df_features' (pandas DataFrame used for fitting)\n",
    "        \"\"\"\n",
    "    \n",
    "        # defensive checks\n",
    "        if not hasattr(self, 'train_df') or self.train_df is None:\n",
    "            raise ValueError(\"train_df not found on self. Populate self.train_df first.\")\n",
    "    \n",
    "        df = self.train_df.copy()\n",
    "    \n",
    "        # find image column\n",
    "        if image_col not in df.columns:\n",
    "            # try common alternatives\n",
    "            if 'image_id' in df.columns and 'image_path' in df.columns:\n",
    "                image_col = 'image_path' if 'image_path' in df.columns else 'image_id'\n",
    "            elif 'image_path' in df.columns:\n",
    "                image_col = 'image_path'\n",
    "            else:\n",
    "                raise ValueError(f\"Image column '{image_col}' not found in train_df\")\n",
    "\n",
    "        # collect features\n",
    "        features_rows = []\n",
    "        total_rows = len(df)\n",
    "        iterator = range(total_rows)\n",
    "        if verbose:\n",
    "            iterator = tqdm(iterator, desc=\"Extract features\", unit=\"rows\")\n",
    "    \n",
    "        for i in iterator:\n",
    "            r = df.iloc[i]\n",
    "            img_identifier = r.get(image_col, None)\n",
    "            img = None\n",
    "    \n",
    "            if pd.isna(img_identifier) or img_identifier is None:\n",
    "                img_identifier = None\n",
    "    \n",
    "            try:\n",
    "              \n",
    "                if isinstance(img_identifier, str) and img_identifier.strip() != \"\":\n",
    "                    img_id = img_identifier.strip()\n",
    "                    # Remove leading 'train/' or 'test/'\n",
    "                    if img_id.startswith(\"train/\"):\n",
    "                        img_id = img_id[len(\"train/\"):]\n",
    "                    elif img_id.startswith(\"test/\"):\n",
    "                        img_id = img_id[len(\"test/\"):]\n",
    "                    \n",
    "                    # Build correct absolute path\n",
    "                    p = Path(self.image_dir) / img_id\n",
    "    \n",
    "                    try:\n",
    "                        with Image.open(str(p)) as _img:\n",
    "                            img = _img.convert(\"RGB\").copy()\n",
    "                    except Exception:\n",
    "                        try:\n",
    "                            arr = cv2.imread(str(p))\n",
    "                            if arr is not None:\n",
    "                                arr_rgb = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)\n",
    "                                img = Image.fromarray(arr_rgb)\n",
    "                            else:\n",
    "                                img = None\n",
    "                        except Exception:\n",
    "                            img = None\n",
    "    \n",
    "                elif isinstance(img_identifier, (np.ndarray,)):\n",
    "                    try:\n",
    "                        img = Image.fromarray(np.uint8(img_identifier)).convert(\"RGB\")\n",
    "                    except Exception:\n",
    "                        img = None\n",
    "    \n",
    "\n",
    "                elif isinstance(img_identifier, Image.Image):\n",
    "                    img = img_identifier.convert(\"RGB\")\n",
    "    \n",
    "            except Exception:\n",
    "                img = None\n",
    "    \n",
    "            if img is None:\n",
    "                try:\n",
    "                    img = Image.new(\"RGB\", (self.image_width, self.image_height), color=(255, 0, 255))\n",
    "                except Exception:\n",
    "                    img = Image.new(\"RGB\", (200, 200), color=(255, 0, 255))\n",
    "\n",
    "            #=========================================\n",
    "            #Remove Later to use Full size Image\n",
    "            #========================================\n",
    "            # Resize image for consistent calibration \n",
    "            MAX_SIZE = 512\n",
    "            w, h = img.size\n",
    "            scale = MAX_SIZE / max(w, h)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            img = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "            #====================================================\n",
    "            try:\n",
    "                feats = self.compute_features_from_image(img)\n",
    "            except Exception:\n",
    "                feats = {'ndvi': 0.5, 'texture': 0.02, 'green': 0.4, 'brightness': 0.5, 'height_proxy': 0.4, 'veg_frac': 0.5}\n",
    "    \n",
    "            combined_score = (\n",
    "                0.35 * feats['ndvi'] +\n",
    "                0.25 * feats['texture'] +\n",
    "                0.20 * feats['green'] +\n",
    "                0.10 * feats['brightness'] +\n",
    "                0.10 * feats['height_proxy']\n",
    "            )\n",
    "            MIN_SCORE = 1e-2   \n",
    "            combined_score = float(np.clip(combined_score * (0.5 + 0.5 * feats.get('veg_frac', 1.0)), MIN_SCORE, 1.0))\n",
    "    \n",
    "            features_rows.append({\n",
    "                'index': i,\n",
    "                'image_id': img_identifier if isinstance(img_identifier, str) else f\"img_{i}\",\n",
    "                'ndvi': float(feats['ndvi']),\n",
    "                'texture': float(feats['texture']),\n",
    "                'green': float(feats['green']),\n",
    "                'brightness': float(feats['brightness']),\n",
    "                'height_proxy': float(feats['height_proxy']),\n",
    "                'veg_frac': float(feats.get('veg_frac', 0.5)),\n",
    "                'combined_score': combined_score,\n",
    "                'height_cm_true': float(r[height_col]) if (height_col in df.columns and not pd.isna(r[height_col])) else np.nan\n",
    "            })\n",
    "    \n",
    "    \n",
    "        df_features = pd.DataFrame(features_rows)\n",
    "        cs = df_features['combined_score'].astype(float)\n",
    "        cs_norm = (cs - cs.min()) / (cs.max() - cs.min() + 1e-6)\n",
    "        cs_norm = cs_norm.clip(1e-3, 1.0)\n",
    "        \n",
    "        df_features['combined_score_norm'] = cs_norm\n",
    "        feat_cols = ['ndvi','texture','green','brightness','height_proxy','veg_frac']\n",
    "        for c in feat_cols:\n",
    "            df_features[c] = pd.to_numeric(df_features[c], errors='coerce')\n",
    "        medians = df_features[feat_cols].median()\n",
    "        # if many rows have all NaNs, they should be dropped for calibrationX_log\n",
    "        all_missing_mask = df_features[feat_cols].isna().all(axis=1)\n",
    "        if all_missing_mask.sum() > 0:\n",
    "            logger.info(f\"Dropping {all_missing_mask.sum()} rows with all features missing for height calibration.\")\n",
    "        df_features.loc[:, feat_cols] = df_features.loc[:, feat_cols].fillna(medians)\n",
    "        # only rows with ground truth\n",
    "        mask_gt = df_features['height_cm_true'].notnull()\n",
    "        n_total = len(df_features)\n",
    "        n_gt = int(mask_gt.sum())\n",
    "    \n",
    "        results = {'n_samples': n_total, 'n_positive': n_gt, 'powerlaw': None, 'ridge': None, 'df_features': df_features}\n",
    "    \n",
    "        if n_gt < min_positive_samples:\n",
    "            # not enough GT to fit\n",
    "            logger.warning(f\"Not enough ground-truth samples to fit calibration (found {n_gt}, need >= {min_positive_samples}).\")\n",
    "            return results\n",
    "    \n",
    "        # prepare arrays for fitting\n",
    "        df_gt = df_features.loc[mask_gt].copy()\n",
    "        # ensure positive combined_score & height\n",
    "        pos_mask = (df_gt['combined_score'] > 0) & (df_gt['height_cm_true'] > 0)\n",
    "        df_gt = df_gt.loc[pos_mask].copy()\n",
    "        if len(df_gt) < min_positive_samples:\n",
    "            logger.warning(f\"After removing nonpositive samples, only {len(df_gt)} samples remain. Aborting fit.\")\n",
    "            return results\n",
    "    \n",
    "        # Fit power-law: log(height) = log(a) + b * log(score)\n",
    "        X_log = np.log1p(df_gt['combined_score_norm'].values).reshape(-1, 1)\n",
    "        y_log = np.log1p(df_gt['height_cm_true'].values).reshape(-1, 1)\n",
    "        lr = LinearRegression().fit(X_log, y_log)\n",
    "        b = float(lr.coef_[0][0])\n",
    "        loga = float(lr.intercept_[0])\n",
    "        a = float(np.exp(loga))\n",
    "        # Save to self\n",
    "        self.height_a = a\n",
    "        self.height_b = b\n",
    "    \n",
    "        # Evaluate on holdout split for power-law\n",
    "        bins = pd.qcut(df_gt['height_cm_true'], q=10, duplicates='drop')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_gt['combined_score_norm'].values,\n",
    "            df_gt['height_cm_true'].values,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=bins\n",
    "        )\n",
    "        \n",
    "        mask_train = (X_train > 0) & (y_train > 0)\n",
    "        if mask_train.sum() >= 3:\n",
    "            lr2 = LinearRegression().fit(\n",
    "                np.log1p(X_train[mask_train]).reshape(-1, 1),\n",
    "                np.log1p(y_train[mask_train]).reshape(-1, 1))\n",
    "        \n",
    "            loga_train = float(np.ravel(lr2.intercept_)[0])\n",
    "            b_train = float(np.ravel(lr2.coef_)[0])\n",
    "        \n",
    "            X_test_pos = np.maximum(X_test, 1e-6)\n",
    "            preds_power = np.expm1(loga_train + b_train * np.log1p(X_test_pos))\n",
    "        \n",
    "            # data-driven cap (robust fallback)\n",
    "            q99 = df_gt['height_cm_true'].dropna().quantile(0.99)\n",
    "        \n",
    "            HEIGHT_MAX = getattr(self, \"HEIGHT_MAX\", self.lookups_dict.get(\"HEIGHT_MAX\", 80.0))\n",
    "            preds_power = np.clip(preds_power, 0.0, HEIGHT_MAX * 1.3)\n",
    "\n",
    "            rmse_p = float(np.sqrt(mean_squared_error(y_test, preds_power)))\n",
    "            mae_p = float(mean_absolute_error(y_test, preds_power))\n",
    "            if np.allclose(y_test, y_test[0]):\n",
    "                r2_p = float('nan')\n",
    "            else:\n",
    "                r2_p = r2_score(np.log1p(y_test), np.log1p(preds_power))\n",
    "        else:\n",
    "            rmse_p = mae_p = r2_p = float('nan')\n",
    "\n",
    "        results['powerlaw'] = {'a': a, 'b': b, 'rmse': rmse_p, 'mae': mae_p, 'r2': r2_p}\n",
    "    \n",
    "        if fit_ridge:\n",
    "            # Prepare features & log1p target\n",
    "            X_feats = df_gt[['ndvi','texture','green','brightness','height_proxy','veg_frac']].values.astype(float)\n",
    "            y_log_all = np.log1p(df_gt['height_cm_true'].values)\n",
    "        \n",
    "            # Holdout split\n",
    "            X_tr, X_te, ytr, yte = train_test_split(\n",
    "                X_feats, y_log_all,\n",
    "                test_size=test_size,\n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "            try:\n",
    "                # Train tree-based model predicting log1p(height)\n",
    "                ridge = RandomForestRegressor(\n",
    "                    n_estimators=200,\n",
    "                    max_depth=15,\n",
    "                    min_samples_leaf=5,\n",
    "                    min_samples_split=10,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                ).fit(X_tr, ytr)\n",
    "        \n",
    "                # Predict on holdout\n",
    "                logpred = ridge.predict(X_te)\n",
    "                pred_cm = np.expm1(logpred)\n",
    "                yte_cm = np.expm1(yte)\n",
    "        \n",
    "                # Compute metrics\n",
    "                rmse_r = float(np.sqrt(mean_squared_error(yte_cm, pred_cm)))\n",
    "                mae_r  = float(mean_absolute_error(yte_cm, pred_cm))\n",
    "        \n",
    "                # Weighted RÂ² requires a target-type â†’ use dummy GDM_g\n",
    "                target_names_test = np.array(['GDM_g'] * len(yte_cm))\n",
    "                r2_r = compute_weighted_r2_metric(pred_cm, yte_cm, target_names_test)\n",
    "        \n",
    "                # Save model into class\n",
    "                self.height_model = ridge\n",
    "                self.height_model_type = 'log1p'\n",
    "        \n",
    "                # Store metrics and the model object (so propagation can find it)\n",
    "                results['ridge'] = {\n",
    "                    'model': ridge,\n",
    "                    'rmse': rmse_r,\n",
    "                    'mae': mae_r,\n",
    "                    'r2':  r2_r,\n",
    "                    'height_model_type': 'log1p'\n",
    "                }\n",
    "                results['_ridge_model_obj'] = ridge\n",
    "        \n",
    "                # Persist artifacts to disk\n",
    "                try:\n",
    "                    import joblib, json, os\n",
    "                    out_dir = OUTPUTS_DIR if isinstance(OUTPUTS_DIR, Path) else Path(OUTPUTS_DIR)\n",
    "                    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    # powerlaw\n",
    "                    pl_path = out_dir / \"height_powerlaw.json\"\n",
    "                    json.dump({'a': float(a), 'b': float(b)}, pl_path.open(\"w\"))\n",
    "                    # ridge model\n",
    "                    ridge_path = out_dir / \"height_ridge.joblib\"\n",
    "                    joblib.dump(ridge, ridge_path)\n",
    "                    logger.info(f\"Saved height calibration artifacts to {out_dir}\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Failed to save height calibration artifacts: {e}\")\n",
    "        \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Ridge model fitting failed: {e}\")\n",
    "                results['ridge'] = None\n",
    "                # ensure we don't leave partial model refs\n",
    "                results.pop('_ridge_model_obj', None)\n",
    "        \n",
    "        # Final logging (powerlaw + ridge summary)\n",
    "        powerlaw_rmse = results.get('powerlaw', {}).get('rmse', float('nan'))\n",
    "        logger.info(\n",
    "            f\"Calibrated powerlaw: a={a:.4f}, b={b:.4f} \"\n",
    "            f\"(trained on {len(df_gt)} samples). Powerlaw test RMSE={powerlaw_rmse:.3f}\"\n",
    "        )\n",
    "        \n",
    "        if results.get('ridge'):\n",
    "            logger.info(\n",
    "                f\"Trained Ridge (log-target) test RMSE={results['ridge']['rmse']:.3f}, \"\n",
    "                f\"RÂ²={results['ridge']['r2']:.4f}\"\n",
    "            )\n",
    "        \n",
    "        results['_source_dataset'] = self\n",
    "        return results\n",
    "\n",
    "\n",
    "def create_data_loaders(train_df, test_df, lookups_dict, TOTAL_TABULAR_DIM, model=None):\n",
    "    \"\"\"\n",
    "    Create training, validation, and test data loaders with patch-based processing.\n",
    "    Integrates intelligent TARGET-SPECIFIC test feature fetching.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader, train_split_df, val_split_df)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"CREATING DATA LOADERS WITH INTELLIGENT TEST FEATURE FETCHING\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    # STEP 1: SPLIT DATA\n",
    "    logger.info(\"\\nStep 1: Train/Val Split\")\n",
    "    \n",
    "    train_df['image_id'] = train_df['sample_id'].fillna('').astype(str).str.split('__').str[0]\n",
    "    unique_images = train_df[['image_id', 'image_path']].drop_duplicates()\n",
    "    n_unique = len(unique_images)\n",
    "    \n",
    "    # Split by image (not by row!)\n",
    "    train_images, val_images = train_test_split(\n",
    "        unique_images,\n",
    "        test_size=CONFIG['val_split'],\n",
    "        random_state=CONFIG['random_seed']\n",
    "    )\n",
    "    \n",
    "    train_split_df = train_df[\n",
    "        train_df['image_id'].isin(train_images['image_id'])\n",
    "    ].reset_index(drop=True)\n",
    "    \n",
    "    val_split_df = (\n",
    "        train_df[train_df['image_id'].isin(val_images['image_id'])]   \n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    logger.info(f\"  Total unique images: {n_unique}\")\n",
    "    logger.info(f\"  Training: {len(train_images)} images â†’ {len(train_split_df)} rows\")\n",
    "    logger.info(f\"    After cropping: {len(train_split_df) * 8} patches\")\n",
    "    logger.info(f\"  Validation: {len(val_images)} images â†’ {len(val_split_df)} rows\")\n",
    "    logger.info(f\"    After cropping: {len(val_split_df) * 8} patches\")\n",
    "    \n",
    "    # STEP 2: DEFINE TRANSFORMS\n",
    "    logger.info(\"\\nStep 2: Defining Transforms\")\n",
    "\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        # PIL Image transforms (BEFORE ToTensor)\n",
    "        transforms.RandomHorizontalFlip(p=0.7),\n",
    "        transforms.RandomVerticalFlip(p=0.7),\n",
    "        transforms.RandomRotation(60),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=45,\n",
    "            translate=(0.25, 0.25),\n",
    "            scale=(0.7, 1.3),\n",
    "            shear=20\n",
    "        ),\n",
    "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "        \n",
    "        # Lighting conditions\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.6,\n",
    "            contrast=0.6,\n",
    "            saturation=0.5,\n",
    "            hue=0.15\n",
    "        ),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        \n",
    "        # Normalize (tensor transform)\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        \n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 3.0)),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "    ])\n",
    "\n",
    "    \n",
    "    val_test_transform = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # STEP 3: CREATE DATASETS\n",
    "    logger.info(\"\\nStep 3: Creating Datasets with Intelligent Test Feature Fetching\")\n",
    "    \n",
    "    train_dataset = BiomassDataset(\n",
    "        train_split_df,\n",
    "        RAW_DATA_DIR / 'train',\n",
    "        transform=train_transform,\n",
    "        mode='train',\n",
    "        train_df=train_split_df,\n",
    "        lookups_dict=lookups_dict\n",
    "    )\n",
    "    \n",
    "    val_dataset = BiomassDataset(\n",
    "        val_split_df,\n",
    "        RAW_DATA_DIR / 'train',\n",
    "        transform=val_test_transform,\n",
    "        mode='val',\n",
    "        train_df=train_df,\n",
    "        lookups_dict=lookups_dict\n",
    "    )\n",
    "    \n",
    "    test_dataset = BiomassDataset(\n",
    "        test_df,\n",
    "        RAW_DATA_DIR / 'test',\n",
    "        transform=val_test_transform,\n",
    "        mode='test',\n",
    "        train_df=train_df, \n",
    "        lookups_dict=lookups_dict,\n",
    "        species_model = model,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    # --- QUICK SANITY CHECK: total tabular dim consistent with lookups ---\n",
    "    try:\n",
    "        numeric_cols = lookups_dict.get(\"TAB_NUMERIC_COLS\", [])\n",
    "        STATE_COLS = lookups_dict.get(\"STATE_COLS\", [])\n",
    "        SPECIES_COLS = lookups_dict.get(\"SPECIES_COLS\", [])\n",
    "        TARGET_TYPE_COLS = lookups_dict.get(\"TARGET_TYPE_COLS\", [])\n",
    "        calc = len(numeric_cols) + len(STATE_COLS) + len(SPECIES_COLS) + len(TARGET_TYPE_COLS)\n",
    "        if calc != TOTAL_TABULAR_DIM:\n",
    "            logger.warning(f\"TOTAL_TABULAR_DIM mismatch: computed={calc}, declared={TOTAL_TABULAR_DIM}\")\n",
    "        else:\n",
    "            logger.info(\"TOTAL_TABULAR_DIM consistent\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"TOTAL_TABULAR_DIM sanity check failed: {e}\")\n",
    "\n",
    "    logger.info(f\"  âœ“ Train dataset: {len(train_dataset)} rows\")\n",
    "    logger.info(f\"  âœ“ Val dataset: {len(val_dataset)} rows\")\n",
    "    \n",
    "    # --- Calibrate height model on training dataset and propagate to val/test ---\n",
    "    logger.info(\"Calibrating height estimator using train dataset features...\")\n",
    "    \n",
    "    # Create a static flag on the function to ensure ONE-TIME calibration\n",
    "    if not hasattr(create_data_loaders, \"_height_calibrated_once\"):\n",
    "        create_data_loaders._height_calibrated_once = False\n",
    "    \n",
    "    calib_res = None\n",
    "    def _propagate_calibration(dst_dataset, calib_res):\n",
    "        \"\"\"Copy fitted artifacts onto dataset instance (powerlaw a,b and ridge model).\"\"\"\n",
    "        if calib_res is None:\n",
    "            return\n",
    "        # powerlaw\n",
    "        pl = calib_res.get('powerlaw')\n",
    "        if pl and 'a' in pl and 'b' in pl:\n",
    "            setattr(dst_dataset, 'height_a', float(pl['a']))\n",
    "            setattr(dst_dataset, 'height_b', float(pl['b']))\n",
    "    \n",
    "        # ridge/model: check several possible locations\n",
    "        ridge_info = calib_res.get('ridge', {}) or {}\n",
    "        model_obj = ridge_info.get('model', None) or calib_res.get('_ridge_model_obj', None)\n",
    "    \n",
    "        # if still None, try to read from train_dataset attr (if calib_res came from that instance)\n",
    "        if model_obj is None:\n",
    "            try:\n",
    "                src = calib_res.get('_source_dataset', None)\n",
    "                if src is not None and hasattr(src, 'height_model') and getattr(src, 'height_model', None) is not None:\n",
    "                    model_obj = getattr(src, 'height_model')\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "        if model_obj is not None:\n",
    "            try:\n",
    "                setattr(dst_dataset, 'height_model', model_obj)\n",
    "                # prefer explicit type if present\n",
    "                ht = ridge_info.get('height_model_type') or calib_res.get('height_model_type') or getattr(model_obj, 'height_model_type', None)\n",
    "                if ht:\n",
    "                    setattr(dst_dataset, 'height_model_type', ht)\n",
    "                else:\n",
    "                    # fallback default\n",
    "                    setattr(dst_dataset, 'height_model_type', 'log1p')\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"_propagate_calibration: failed to set height_model: {e}\")\n",
    "\n",
    "    \n",
    "    # ====== CASE A: First call â†’ run calibration ======\n",
    "    if not create_data_loaders._height_calibrated_once:\n",
    "    \n",
    "        try:\n",
    "            calib_res = train_dataset.calibrate_height_model(\n",
    "                image_col='image_path',\n",
    "                height_col='Height_Ave_cm',\n",
    "                test_size=0.2,\n",
    "                random_state=CONFIG.get('random_seed', 42),\n",
    "                min_positive_samples=5,\n",
    "                fit_ridge=True,\n",
    "                ridge_alphas=(0.01, 0.1, 1.0, 10.0)\n",
    "            )\n",
    "            logger.info(f\"Calibration results: {calib_res.get('powerlaw')}\")\n",
    "            if calib_res.get('ridge') is not None:\n",
    "                logger.info(f\"  Ridge test RMSE: {calib_res['ridge']['rmse']:.3f}\")\n",
    "    \n",
    "            # mark as done so we NEVER run this again\n",
    "            create_data_loaders._height_calibrated_once = True\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Height calibration failed: {e}\")\n",
    "            calib_res = None\n",
    "    \n",
    "    # ====== CASE B: Later calls â†’ load stored calibration only ======\n",
    "    else:\n",
    "        logger.info(\"âœ“ Skipping height calibration (already performed once).\")\n",
    "        # Attempt to load saved calibration if available\n",
    "        try:\n",
    "            import json, joblib\n",
    "            calib_res = {}\n",
    "            out_dir = OUTPUTS_DIR if isinstance(OUTPUTS_DIR, Path) else Path(OUTPUTS_DIR)\n",
    "            pl_path = out_dir / \"height_powerlaw.json\"\n",
    "            ridge_path = out_dir / \"height_ridge.joblib\"\n",
    "    \n",
    "            if pl_path.exists():\n",
    "                try:\n",
    "                    calib_res['powerlaw'] = json.loads(pl_path.read_text())\n",
    "                    logger.info(\"Loaded saved powerlaw calibration from disk.\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Failed to read powerlaw json: {e}\")\n",
    "    \n",
    "            if ridge_path.exists():\n",
    "                try:\n",
    "                    ridge_model = joblib.load(ridge_path)\n",
    "                    calib_res['ridge'] = {'model': ridge_model, 'height_model_type': 'log1p'}\n",
    "                    logger.info(\"Loaded saved ridge calibration from disk.\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Failed to load ridge model: {e}\")\n",
    "    \n",
    "            # If loaded nothing, leave calib_res None to maintain previous behavior\n",
    "            if not calib_res:\n",
    "                calib_res = None\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Failed loading saved calibration: {e}\")\n",
    "            calib_res = None\n",
    "\n",
    "    # Always propagate whatever calibration we have\n",
    "    _propagate_calibration(train_dataset, calib_res)\n",
    "    _propagate_calibration(val_dataset, calib_res)\n",
    "    _propagate_calibration(test_dataset, calib_res)\n",
    "    \n",
    "    \n",
    "    # Quick sanity checks\n",
    "    try:\n",
    "        logger.info(\"Sanity check - sample calibrated heights:\")\n",
    "        sample_img_path = train_dataset.df.iloc[0]['image_path']\n",
    "        img = train_dataset._load_image(sample_img_path)\n",
    "        h_train = train_dataset.estimate_height_final(np.array(img))\n",
    "        logger.info(f\"  sample train estimated height: {h_train} cm\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Sanity check train failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        sample_img_path = test_dataset.df.iloc[0]['image_path']\n",
    "        img = test_dataset._load_image(sample_img_path)\n",
    "        h_test = test_dataset.estimate_height_final(np.array(img))\n",
    "        logger.info(f\"  sample test estimated height: {h_test} cm\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Sanity check test failed: {e}\")\n",
    "\n",
    "\n",
    "    def collate_patches(batch):\n",
    "        \"\"\"\n",
    "        Collate function for patch-based dataset.\n",
    "        \n",
    "        Input batch items (7 elements):\n",
    "            (images, tabular, species_idx, target_idx, target, sample_id, target_name)\n",
    "        \n",
    "        Returns:\n",
    "            (images_batch, tabular_batch, species_batch, target_idx_batch, targets_batch, \n",
    "             sample_ids, target_names)\n",
    "        \"\"\"\n",
    "        PATCHES_PER_IMAGE = 8\n",
    "        C, H, W = 3, 224, 224\n",
    "    \n",
    "        # detect TAB_DIM\n",
    "        TAB_DIM = None\n",
    "        for item in batch:\n",
    "            try:\n",
    "                tab = item[1]\n",
    "                TAB_DIM = tab.shape[-1]\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "        if TAB_DIM is None:\n",
    "            TAB_DIM = 30  # default for meta-learner\n",
    "    \n",
    "        sentinel_images = torch.zeros((PATCHES_PER_IMAGE, C, H, W))\n",
    "        sentinel_tab = torch.zeros((PATCHES_PER_IMAGE, TAB_DIM))\n",
    "        sentinel_target = torch.tensor(0.0)\n",
    "        sentinel_target_idx = torch.tensor(0, dtype=torch.long)\n",
    "    \n",
    "        per_sample_images = []\n",
    "        per_sample_tabular = []\n",
    "        per_sample_species = []\n",
    "        per_sample_target_idx = []  # NEW: store target_idx per sample\n",
    "        per_sample_targets = []\n",
    "        per_sample_sample_ids = []\n",
    "        per_sample_target_names = []\n",
    "    \n",
    "        # parse batch items safely and collect per-sample scalars\n",
    "        for item in batch:\n",
    "            try:\n",
    "                # Handle 7-item return (NEW FORMAT with target_idx)\n",
    "                if len(item) == 7:\n",
    "                    images, tabular, species, target_idx, target, sample_id, target_name = item\n",
    "                # Handle 6-item return (OLD FORMAT - backward compat)\n",
    "                elif len(item) == 6:\n",
    "                    images, tabular, species, target, sample_id, target_name = item\n",
    "                    target_idx = 0  # default fallback\n",
    "                # Handle 5-item return (even older format - backward compat)\n",
    "                elif len(item) == 5:\n",
    "                    images, tabular, target, sample_id, target_name = item\n",
    "                    species = None\n",
    "                    target_idx = 0\n",
    "                else:\n",
    "                    # flexible fallback\n",
    "                    images = item[0] if len(item) > 0 else sentinel_images.clone()\n",
    "                    tabular = item[1] if len(item) > 1 else sentinel_tab.clone()\n",
    "                    species = item[2] if len(item) > 2 else None\n",
    "                    target_idx = item[3] if len(item) > 3 else 0  # NEW: try to get from position 3\n",
    "                    target = item[4] if len(item) > 4 else None\n",
    "                    sample_id = item[-2] if len(item) >= 2 else \"None\"\n",
    "                    target_name = item[-1] if len(item) >= 1 else \"None\"\n",
    "    \n",
    "                sample_id = \"None\" if sample_id is None else sample_id\n",
    "                target_name = \"None\" if target_name is None else target_name\n",
    "    \n",
    "                # ensure images shape = (PATCHES_PER_IMAGE, C, H, W)\n",
    "                if not (isinstance(images, torch.Tensor) and images.ndim == 4 and images.size(0) == PATCHES_PER_IMAGE):\n",
    "                    logger.warning(f\"[collate] BAD IMAGES for sample {sample_id} -> shape={getattr(images, 'shape', None)}; using sentinel\")\n",
    "                    images = sentinel_images.clone()\n",
    "    \n",
    "                # ensure tabular shape = (PATCHES_PER_IMAGE, TAB_DIM) or (TAB_DIM,) (convert)\n",
    "                if isinstance(tabular, torch.Tensor) and tabular.ndim == 1:\n",
    "                    tabular = tabular.unsqueeze(0).repeat(PATCHES_PER_IMAGE, 1)\n",
    "                if not (isinstance(tabular, torch.Tensor) and tabular.ndim == 2 and tabular.size(0) == PATCHES_PER_IMAGE):\n",
    "                    logger.warning(f\"[collate] BAD TABULAR for sample {sample_id} -> shape={getattr(tabular, 'shape', None)}; using sentinel\")\n",
    "                    tabular = sentinel_tab.clone()\n",
    "    \n",
    "                per_sample_images.append(images)\n",
    "                per_sample_tabular.append(tabular)\n",
    "                per_sample_species.append(species)\n",
    "                \n",
    "                # NEW: Store target_idx (convert to tensor if needed)\n",
    "                if isinstance(target_idx, torch.Tensor):\n",
    "                    per_sample_target_idx.append(target_idx.long())\n",
    "                else:\n",
    "                    per_sample_target_idx.append(torch.tensor(int(target_idx), dtype=torch.long))\n",
    "    \n",
    "                # store one scalar or None\n",
    "                if target is None:\n",
    "                    per_sample_targets.append(None)\n",
    "                else:\n",
    "                    # ensure scalar float tensor\n",
    "                    t = torch.tensor(float(target), dtype=torch.float32) if not isinstance(target, torch.Tensor) else target.float().reshape(())\n",
    "                    per_sample_targets.append(t)\n",
    "    \n",
    "                per_sample_sample_ids.append(str(sample_id))\n",
    "                per_sample_target_names.append(str(target_name))\n",
    "    \n",
    "            except Exception as e:\n",
    "                logger.exception(f\"[collate] EXCEPTION parsing sample -> {e}\")\n",
    "                per_sample_images.append(sentinel_images.clone())\n",
    "                per_sample_tabular.append(sentinel_tab.clone())\n",
    "                per_sample_species.append(None)\n",
    "                per_sample_target_idx.append(sentinel_target_idx.clone())  # NEW: add sentinel\n",
    "                per_sample_targets.append(sentinel_target)\n",
    "                per_sample_sample_ids.append(\"None\")\n",
    "                per_sample_target_names.append(\"None\")\n",
    "    \n",
    "        # Now expand per-sample -> per-patch deterministically\n",
    "        images_batch = torch.cat(per_sample_images, dim=0)          # shape (B*P, C, H, W)\n",
    "        tabular_batch = torch.cat(per_sample_tabular, dim=0)       # shape (B*P, TAB_DIM)\n",
    "    \n",
    "        # species batch: convert to tensor if all ints else keep list\n",
    "        species_is_int = all((x is None) or isinstance(x, (int, np.integer, torch.Tensor)) for x in per_sample_species)\n",
    "        if species_is_int:\n",
    "            clean_species = []\n",
    "            for x in per_sample_species:\n",
    "                if x is None:\n",
    "                    clean_species.append(0)\n",
    "                elif isinstance(x, torch.Tensor):\n",
    "                    clean_species.append(int(x.item()))\n",
    "                else:\n",
    "                    clean_species.append(int(x))\n",
    "            species_batch = torch.tensor(clean_species, dtype=torch.long)\n",
    "        else:\n",
    "            species_batch = [None if x is None else x for x in per_sample_species]\n",
    "    \n",
    "        # NEW: target_idx_batch (repeat per patch, per sample)\n",
    "        target_idx_list = []\n",
    "        for tidx in per_sample_target_idx:\n",
    "            # Each sample's target_idx repeated PATCHES_PER_IMAGE times\n",
    "            tidx_val = tidx.item() if isinstance(tidx, torch.Tensor) else int(tidx)\n",
    "            target_idx_list.extend([tidx_val] * PATCHES_PER_IMAGE)\n",
    "        target_idx_batch = torch.tensor(target_idx_list, dtype=torch.long)\n",
    "    \n",
    "        # Build targets_list (per patch) from per_sample_targets to avoid accidental length mismatch\n",
    "        targets_list = []\n",
    "        for t in per_sample_targets:\n",
    "            if t is None:\n",
    "                # keep no-target marker (we use None > caller expects None for test)\n",
    "                targets_list.extend([None] * PATCHES_PER_IMAGE)\n",
    "            else:\n",
    "                targets_list.extend([t] * PATCHES_PER_IMAGE)\n",
    "    \n",
    "        # sample_ids and target_names repeated per patch\n",
    "        sample_ids = []\n",
    "        target_names = []\n",
    "        for sid, tn in zip(per_sample_sample_ids, per_sample_target_names):\n",
    "            sample_ids.extend([sid] * PATCHES_PER_IMAGE)\n",
    "            target_names.extend([tn] * PATCHES_PER_IMAGE)\n",
    "    \n",
    "        # Final alignment checks & conversions\n",
    "        expected_len = len(batch) * PATCHES_PER_IMAGE\n",
    "        assert images_batch.size(0) == expected_len, f\"images length {images_batch.size(0)} != expected {expected_len}\"\n",
    "        assert tabular_batch.size(0) == expected_len, f\"tabular length {tabular_batch.size(0)} != expected {expected_len}\"\n",
    "        assert target_idx_batch.size(0) == expected_len, f\"target_idx length {target_idx_batch.size(0)} != expected {expected_len}\"  # NEW\n",
    "        assert len(sample_ids) == expected_len, f\"sample_ids length {len(sample_ids)} != expected {expected_len}\"\n",
    "        assert len(target_names) == expected_len, f\"target_names length {len(target_names)} != expected {expected_len}\"\n",
    "        assert len(targets_list) == expected_len, f\"targets_list length {len(targets_list)} != expected {expected_len}\"\n",
    "    \n",
    "        # If we have no targets (test mode -> all targets None) return None target batch\n",
    "        if all(t is None for t in targets_list):\n",
    "            # NEW: return 7 items including target_idx_batch\n",
    "            return images_batch, tabular_batch, species_batch, target_idx_batch, None, sample_ids, target_names\n",
    "    \n",
    "        # else convert targets_list (some elements may be torch tensors already)\n",
    "        targ_tensors = []\n",
    "        for t in targets_list:\n",
    "            if t is None:\n",
    "                targ_tensors.append(torch.tensor(0.0))   # sentinel for safety (shouldn't happen in train/val)\n",
    "            elif isinstance(t, torch.Tensor) and t.numel() == 1:\n",
    "                targ_tensors.append(t.reshape(()))\n",
    "            else:\n",
    "                targ_tensors.append(torch.tensor(float(t), dtype=torch.float32))\n",
    "        targets_batch = torch.stack(targ_tensors, dim=0).float()\n",
    "    \n",
    "        # NEW: return 7 items including target_idx_batch\n",
    "        return images_batch, tabular_batch, species_batch, target_idx_batch, targets_batch, sample_ids, target_names\n",
    "\n",
    "\n",
    "    # STEP 5: CREATE DATALOADERS\n",
    "    logger.info(\"\\nStep 5: Creating DataLoaders\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=CONFIG['pin_memory'],\n",
    "        collate_fn=collate_patches,\n",
    "        drop_last=True \n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=CONFIG['pin_memory'],\n",
    "        collate_fn=collate_patches,\n",
    "        drop_last=True \n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=CONFIG['pin_memory'],\n",
    "        collate_fn=collate_patches,\n",
    "        drop_last=False \n",
    "    )\n",
    "    \n",
    "    logger.info(f\"  âœ“ Train loader: {len(train_loader)} batches\")\n",
    "    logger.info(f\"  âœ“ Val loader: {len(val_loader)} batches\")\n",
    "    logger.info(f\"  âœ“ Test loader: {len(test_loader)} batches\")\n",
    "    logger.info(f\"\\n  Batch size: {CONFIG['batch_size']} images\")\n",
    "    logger.info(f\"  Per batch: {CONFIG['batch_size']} images Ã— 8 patches = {CONFIG['batch_size']*8} patches\")\n",
    "    logger.info(f\"  Batch shapes:\")\n",
    "    logger.info(f\"    - images: [{CONFIG['batch_size']*8}, 3, 224, 224]\")\n",
    "    logger.info(f\"    - tabular: [{CONFIG['batch_size']*8}, {TOTAL_TABULAR_DIM}]\")\n",
    "    logger.info(f\"    - targets: [{CONFIG['batch_size']*8}]\")\n",
    "    logger.info(\"\\nâœ“ Data loaders created successfully!\")\n",
    "    logger.info(\"  âœ“ Test feature fetching: TARGET-SPECIFIC at ALL LEVELS\")\n",
    "    logger.info(\"  âœ“ Patches per image: 8 (4Ã—2 grid from 2000Ã—1000 images)\")\n",
    "    logger.info(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_split_df, val_split_df\n",
    "\n",
    "logger.info(\"âœ“ Data Augmentation and Preparation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e67d7",
   "metadata": {},
   "source": [
    "## 5: LOSS FUNCTION - WEIGHTED RÂ²\n",
    "\n",
    "**Purpose**: Implement competition metric as neural network loss function.\n",
    "\n",
    "**Weighted RÂ² Formula**:\n",
    "```\n",
    "RÂ² = 1 - (SS_residual / SS_total)\n",
    "\n",
    "Where:\n",
    "  SS_residual = Î£(w_i Ã— (Å·_i - y_i)Â²)   [weighted squared errors]\n",
    "  SS_total    = Î£(w_i Ã— (y_i - È³_weighted)Â²)  [weighted variance]\n",
    "  w_i         = weight for target type i\n",
    "  È³_weighted  = Î£(w_i Ã— y_i) / Î£(w_i)  [weighted mean]\n",
    "```\n",
    "\n",
    "**Weighting Scheme** (Competition Metric):\n",
    "\n",
    "| Target | Weight | Interpretation |\n",
    "|--------|--------|-----------------|\n",
    "| Dry_Total_g | 0.50 | Primary focus (50% of loss) |\n",
    "| GDM_g | 0.20 | Secondary focus (20%) |\n",
    "| Dry_Green_g | 0.10 | Supporting (10%) |\n",
    "| Dry_Dead_g | 0.10 | Supporting (10%) |\n",
    "| Dry_Clover_g | 0.10 | Supporting (10%) |\n",
    "\n",
    "**Implementation Details**:\n",
    "\n",
    "1. **Prediction Clamping**: Ensure predictions â‰¥ 0 (non-negative biomass)\n",
    "2. **Weight Normalization**: Normalize weights to sum to 1.0\n",
    "3. **Numerical Stability**: Check SS_total > 1e-8 before division\n",
    "4. **Gradient Direction**: Return -RÂ² for minimization (loss to minimize)\n",
    "\n",
    "**Training Usage**:\n",
    "```python\n",
    "loss = weighted_r2_loss(predictions, targets, target_names)\n",
    "loss.backward()  # Backpropagation\n",
    "```\n",
    "\n",
    "**Validation Usage**:\n",
    "```python\n",
    "r2_metric = compute_weighted_r2_metric(preds_np, targets_np, names_np)\n",
    "# Display positive RÂ² (higher is better)\n",
    "```\n",
    "\n",
    "**Key Properties**:\n",
    "- RÂ² âˆˆ [-100, 1]: Clamped to prevent numerical instability\n",
    "- Perfect prediction: RÂ² = 1 (loss = 0)\n",
    "- Mean prediction: RÂ² = 0 (loss = 0)\n",
    "- Worse than mean: RÂ² < 0 (loss > 0)\n",
    "\n",
    "**Output**: \n",
    "- Weighted RÂ² loss function defined\n",
    "- Compatible with PyTorch backpropagation\n",
    "- Metric computation for evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bbe8ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[32m    212\u001b[39m         r2 = \u001b[32m1.0\u001b[39m - ss_res / ss_tot\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.clip(r2, -\u001b[32m100.0\u001b[39m, \u001b[32m1.0\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[43mlogger\u001b[49m.info(\u001b[33m'\u001b[39m\u001b[33mâœ“ Weighted RÂ² loss functions defined\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "def weighted_r2_loss(\n",
    "    predictions, \n",
    "    targets, \n",
    "    target_names, \n",
    "    device=None, \n",
    "    weights_config=None,\n",
    "    eps=1e-8,\n",
    "    strict_length_check=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Production-ready weighted RÂ² loss (differentiable).\n",
    "    \n",
    "    Args:\n",
    "        predictions (torch.Tensor): Model predictions, shape [N] or [N, 1]\n",
    "        targets (torch.Tensor): Ground truth values, same shape as predictions\n",
    "        target_names (torch.Tensor | np.ndarray | list): Target type names for weighting\n",
    "        weights_config (dict): Mapping of {target_name: weight}, e.g. {'dry_total_g': 2.0}\n",
    "                              If None, uses uniform weights\n",
    "        device (torch.device | str): Device for computation\n",
    "        eps (float): Small constant for numerical stability\n",
    "        strict_length_check (bool): If True, raise error on length mismatch instead of truncating\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Scalar loss = 1.0 - RÂ²_weighted (0 = perfect, higher = worse)\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: If inputs are not torch tensors\n",
    "        ValueError: If shapes are incompatible or tensors are empty\n",
    "    \"\"\"\n",
    "    # 1. INPUT VALIDATION\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    if not torch.is_tensor(predictions) or not torch.is_tensor(targets):\n",
    "        raise TypeError(\"predictions and targets must be torch tensors\")\n",
    "    \n",
    "    if predictions.numel() == 0 or targets.numel() == 0:\n",
    "        raise ValueError(\"Empty tensors not supported\")\n",
    "    \n",
    "    preds = predictions.view(-1).float()\n",
    "    targs = targets.view(-1).float()\n",
    "    \n",
    "    if preds.shape != targs.shape:\n",
    "        raise ValueError(\n",
    "            f\"Shape mismatch after flattening: predictions={preds.shape}, targets={targs.shape}\"\n",
    "        )\n",
    "    \n",
    "    # 2. DEVICE HANDLING\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    dev = device if device is not None else preds.device\n",
    "    if not isinstance(dev, torch.device):\n",
    "        dev = torch.device(dev)\n",
    "    \n",
    "    preds = preds.to(dev)\n",
    "    targs = targs.to(dev)\n",
    "    \n",
    "    # 3. PROCESS TARGET NAMES\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    if target_names is None:\n",
    "        names_list = [\"__uniform__\"] * preds.numel()\n",
    "    elif isinstance(target_names, torch.Tensor):\n",
    "        # Detach to avoid gradient issues\n",
    "        target_names = target_names.detach().view(-1)\n",
    "        names_list = [str(x).strip().lower() for x in target_names.cpu().tolist()]\n",
    "    else:\n",
    "        names_arr = np.asarray(target_names).flatten()\n",
    "        names_list = [str(x).strip().lower() for x in names_arr]\n",
    "    \n",
    "    # 4. LENGTH ALIGNMENT\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    if len(names_list) != preds.numel():\n",
    "        if strict_length_check:\n",
    "            raise ValueError(\n",
    "                f\"Length mismatch: predictions={preds.numel()}, \"\n",
    "                f\"targets={targs.numel()}, target_names={len(names_list)}\"\n",
    "            )\n",
    "        else:\n",
    "            # Lenient mode: truncate to shortest\n",
    "            m = min(len(names_list), preds.numel())\n",
    "            logger.warning(\n",
    "                f\"weighted_r2_loss: length mismatch, truncating to {m} samples \"\n",
    "                f\"(preds={preds.numel()}, targets={targs.numel()}, names={len(names_list)})\"\n",
    "            )\n",
    "            names_list = names_list[:m]\n",
    "            preds = preds[:m]\n",
    "            targs = targs[:m]\n",
    "    \n",
    "    # 5. BUILD WEIGHT MAP\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    weights_map = {}\n",
    "    if weights_config is not None:\n",
    "        weights_map = {str(k).strip().lower(): float(v) for k, v in weights_config.items()}\n",
    "    elif 'CONFIG' in globals():\n",
    "        # Fallback to global CONFIG if available\n",
    "        weights_map = {str(k).strip().lower(): float(v) \n",
    "                      for k, v in globals()['CONFIG'].get('r2_weights', {}).items()}\n",
    "    \n",
    "    # 6. CREATE WEIGHT TENSOR \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    if weights_map:\n",
    "        # Vectorized lookup via numpy (faster than list comprehension for large batches)\n",
    "        row_weights_np = np.array([weights_map.get(name, 0.0) for name in names_list], \n",
    "                                   dtype=np.float32)\n",
    "        row_weights = torch.from_numpy(row_weights_np).to(dev)\n",
    "    else:\n",
    "        row_weights = torch.ones(preds.numel(), dtype=torch.float32, device=dev)\n",
    "    \n",
    "    # Fallback to uniform weights if all zeros\n",
    "    if row_weights.sum() <= eps:\n",
    "        logger.debug(\"All weights are zero; using uniform weights\")\n",
    "        row_weights = torch.ones_like(row_weights)\n",
    "    \n",
    "    # 7. COMPUTE WEIGHTED RÂ²\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Weighted mean: È³_w = Î£(w_i * y_i) / Î£(w_i)\n",
    "    wsum = row_weights.sum() + eps\n",
    "    y_wbar = (row_weights * targs).sum() / wsum\n",
    "    \n",
    "    # Sum of squares\n",
    "    ss_res = ((targs - preds).pow(2) * row_weights).sum()  # Residual\n",
    "    ss_tot = ((targs - y_wbar).pow(2) * row_weights).sum()  # Total\n",
    "    \n",
    "    # RÂ² = 1 - (SS_res / SS_tot)\n",
    "    r2 = 1.0 - ss_res / (ss_tot + eps)\n",
    "    \n",
    "    # Clamp to reasonable bounds (RÂ² âˆˆ [-100, 1])\n",
    "    r2 = r2.clamp(min=-1.0, max=1.0)\n",
    "    \n",
    "    # Return loss (1 - RÂ²): perfect model â†’ loss = 0\n",
    "    return 1.0 - r2\n",
    "\n",
    "\n",
    "def compute_weighted_r2_metric(\n",
    "    predictions, \n",
    "    targets, \n",
    "    target_names, \n",
    "    weights_config=None,\n",
    "    eps=1e-8\n",
    "):\n",
    "    \"\"\"\n",
    "    NumPy implementation of weighted RÂ² (evaluation only).\n",
    "    \n",
    "    Args:\n",
    "        predictions (np.ndarray | list): Model predictions\n",
    "        targets (np.ndarray | list): Ground truth values\n",
    "        target_names (np.ndarray | list): Target type names for weighting\n",
    "        weights_config (dict): Mapping of {target_name: weight}\n",
    "        eps (float): Small constant for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        float: RÂ²_weighted âˆˆ [-100, 1] (1 = perfect, 0 = baseline, negative = worse than mean)\n",
    "    \"\"\"\n",
    "    # 1. CONVERT TO NUMPY\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    preds = np.asarray(predictions).flatten()\n",
    "    targs = np.asarray(targets).flatten()\n",
    "    \n",
    "    if target_names is None:\n",
    "        names = np.array([\"__uniform__\"] * len(preds))\n",
    "    else:\n",
    "        names = np.asarray(target_names).flatten()\n",
    "    \n",
    "    # 2. ALIGN LENGTHS\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    min_len = min(len(preds), len(targs), len(names))\n",
    "    if not (len(preds) == len(targs) == len(names)):\n",
    "        logger.warning(\n",
    "            f\"compute_weighted_r2_metric: length mismatch, truncating to {min_len} \"\n",
    "            f\"(preds={len(preds)}, targets={len(targs)}, names={len(names)})\"\n",
    "        )\n",
    "        preds = preds[:min_len]\n",
    "        targs = targs[:min_len]\n",
    "        names = names[:min_len]\n",
    "    \n",
    "    if min_len == 0:\n",
    "        logger.error(\"No valid samples after alignment\")\n",
    "        return 0.0\n",
    "    \n",
    "    # 3. BUILD WEIGHT MAP\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    names_norm = np.array([str(x).strip().lower() for x in names], dtype=object)\n",
    "    \n",
    "    weights_map = {}\n",
    "    if weights_config is not None:\n",
    "        weights_map = {str(k).strip().lower(): float(v) for k, v in weights_config.items()}\n",
    "    elif 'CONFIG' in globals():\n",
    "        weights_map = {str(k).strip().lower(): float(v) \n",
    "                      for k, v in globals()['CONFIG'].get('r2_weights', {}).items()}\n",
    "    \n",
    "    # 4. CREATE WEIGHTS ARRAY\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    if weights_map:\n",
    "        row_w = np.array([weights_map.get(name, 0.0) for name in names_norm], dtype=np.float32)\n",
    "    else:\n",
    "        row_w = np.ones(len(preds), dtype=np.float32)\n",
    "    \n",
    "    # Fallback to uniform weights\n",
    "    if row_w.sum() == 0:\n",
    "        logger.warning(\"compute_weighted_r2_metric: no matching weights; using uniform\")\n",
    "        row_w[:] = 1.0\n",
    "    \n",
    "    # 5. COMPUTE WEIGHTED RÂ²\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    wsum = row_w.sum() + eps\n",
    "    y_wbar = (row_w * targs).sum() / wsum\n",
    "    \n",
    "    ss_res = ((targs - preds) ** 2 * row_w).sum()\n",
    "    ss_tot = ((targs - y_wbar) ** 2 * row_w).sum()\n",
    "    \n",
    "    if ss_tot < eps:\n",
    "        logger.debug(\"SS_tot â‰ˆ 0; returning RÂ² = 0\")\n",
    "        r2 = 0.0\n",
    "    else:\n",
    "        r2 = 1.0 - ss_res / ss_tot\n",
    "    \n",
    "    return float(np.clip(r2, -100.0, 1.0))\n",
    "\n",
    "\n",
    "logger.info('âœ“ Weighted RÂ² loss functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346693cb",
   "metadata": {},
   "source": [
    "##  6: MODEL ARCHITECTURES - 6 MODELS\n",
    "\n",
    "**Purpose**: Define 6 models for ensemble learning system.\n",
    "\n",
    "### Model 1: Vision Transformer (ViT-Base)\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Input: [batch*8, 3, 224, 224] patches\n",
    "  â†“\n",
    "ViT-Base Encoder\n",
    "- Patch embedding: 16Ã—16 patches\n",
    "- 12 transformer layers\n",
    "- 12 attention heads\n",
    "- Hidden dim: 768\n",
    "  â†“\n",
    "Global average pooling â†’ [batch*8, 768]\n",
    "  â†“\n",
    "Regression Head\n",
    "- FC: 768 â†’ 256 (GELU + Dropout 0.3)\n",
    "- FC: 256 â†’ 128 (GELU + Dropout 0.3)\n",
    "- FC: 128 â†’ 1\n",
    "  â†“\n",
    "Output: [batch*8] predictions\n",
    "```\n",
    "\n",
    "**Configuration**:\n",
    "- Pretrained: ImageNet weights (timm)\n",
    "- Learning rate: 1e-4\n",
    "- Epochs: 50\n",
    "- Early stopping: patience=20\n",
    "\n",
    "### Model 2: ResNet-50\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Input: [batch*8, 3, 224, 224]\n",
    "  â†“\n",
    "ResNet-50 Backbone\n",
    "- Conv blocks with residual connections\n",
    "- 50 layers total\n",
    "- Output: [batch*8, 2048]\n",
    "  â†“\n",
    "Global Average Pooling â†’ [batch*8, 2048]\n",
    "  â†“\n",
    "Regression Head\n",
    "- FC: 2048 â†’ 512 (ReLU + Dropout 0.3)\n",
    "- FC: 512 â†’ 256 (ReLU + Dropout 0.2)\n",
    "- FC: 256 â†’ 1\n",
    "  â†“\n",
    "Output: [batch*8] predictions\n",
    "```\n",
    "\n",
    "**Configuration**:\n",
    "- Pretrained: ImageNet weights\n",
    "- Learning rate: 5e-5\n",
    "- Epochs: 50\n",
    "\n",
    "### Model 3: DenseNet-121\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Input: [batch*8, 3, 224, 224]\n",
    "  â†“\n",
    "DenseNet-121 Backbone\n",
    "- Dense connections between layers\n",
    "- 121 layers total\n",
    "- Output: [batch*8, 1024]\n",
    "  â†“\n",
    "Global Average Pooling â†’ [batch*8, 1024]\n",
    "  â†“\n",
    "Regression Head\n",
    "- FC: 1024 â†’ 512 (ReLU + Dropout 0.3)\n",
    "- FC: 512 â†’ 256 (ReLU + Dropout 0.2)\n",
    "- FC: 256 â†’ 1\n",
    "  â†“\n",
    "Output: [batch*8] predictions\n",
    "```\n",
    "\n",
    "**Configuration**:\n",
    "- Pretrained: ImageNet weights\n",
    "- Learning rate: 5e-5\n",
    "- Epochs: 50\n",
    "\n",
    "### Model 4: XGBoost (Tabular Model)\n",
    "\n",
    "**Purpose**: Learn from 29 tabular features alone (without image patches)\n",
    "\n",
    "**Hyperparameters**:\n",
    "```python\n",
    "XGBRegressor(\n",
    "    n_estimators=1000,     # Boosting rounds\n",
    "    max_depth=6,           # Tree depth\n",
    "    learning_rate=0.03,    # Step size\n",
    "    subsample=0.85,        # Row subsampling\n",
    "    colsample_bytree=0.85, # Feature subsampling\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "```\n",
    "\n",
    "**Features**: 29 tabular features (NDVI, height, month, state, species, target type)\n",
    "\n",
    "**Training**:\n",
    "- Image-level (not patch-level)\n",
    "- One prediction per training row\n",
    "- Optional: Separate models per target type\n",
    "\n",
    "### Model 5: Meta-Learner (Stacking)\n",
    "\n",
    "**Purpose**: Learn optimal combination of 5 base model predictions\n",
    "\n",
    "**Input Fusion**:\n",
    "```\n",
    "5 base predictions + 29 tabular features = 34 dimensions\n",
    "```\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Input: [batch, 34] (5 predictions + 29 features)\n",
    "  â†“\n",
    "Layer 1: FC(34â†’64) + BatchNorm + ReLU + Dropout(0.2)\n",
    "  â†“\n",
    "Layer 2: FC(64â†’32) + BatchNorm + ReLU + Dropout(0.15)\n",
    "  â†“\n",
    "Layer 3: FC(32â†’16) + ReLU + Dropout(0.1)\n",
    "  â†“\n",
    "Output: FC(16â†’1)\n",
    "  â†“\n",
    "Final prediction\n",
    "```\n",
    "\n",
    "**Training**:\n",
    "- Input: Predictions from 5 base models on training data\n",
    "- Target: Ground truth biomass values\n",
    "- Loss: Weighted RÂ²\n",
    "- Epochs: 100\n",
    "- Early stopping: patience=20\n",
    "\n",
    "### Model 6: Species Classification ViT\n",
    "\n",
    "**Purpose**: Predict species from  image patches (improves test feature fetching)\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Input: [batch*8, 3, 224, 224] patches\n",
    "  â†“\n",
    "ViT-Base backbone â†’ [batch*8, 768]\n",
    "  â†“\n",
    "Classification Head\n",
    "- FC(768â†’256) + GELU + Dropout(0.3)\n",
    "- FC(256â†’128) + GELU + Dropout(0.2)\n",
    "- FC(128â†’15 logits)\n",
    "  â†“\n",
    "Output: [batch*8, 15] logits (15 species classes)\n",
    "```\n",
    "\n",
    "**Training**:\n",
    "- Loss: CrossEntropyLoss (classification)\n",
    "- Optimizer: AdamW\n",
    "\n",
    "### Ensemble Strategy Summary\n",
    "\n",
    "| Component | Type | Input | Output | Purpose |\n",
    "|-----------|------|-------|--------|---------|\n",
    "| ViT-Base | Image | Patches | Prediction | Transformer attention |\n",
    "| ResNet-50 | Image | Patches | Prediction | Residual connections |\n",
    "| DenseNet-121 | Image | Patches | Prediction | Dense connections |\n",
    "| XGBoost | Tabular | 29 features | Prediction | Gradient boosting |\n",
    "| Meta-Learner | Fusion | 5+29 | Final | Learned combination |\n",
    "| Species ViT | Image | Patches | Species class | Improve fallback |\n",
    "\n",
    "**Output**: \n",
    "- 6 model classes defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c193de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Multiple Instance Learning Aggregator for patch-based predictions.\n",
    "\n",
    "    Learns attention weights for each patch to perform weighted aggregation.\n",
    "    Designed to work seamlessly with your 8-patch strategy.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim=512, num_patches=8, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_dim (int): Feature dimension from models (ViT: 768, ResNet: 2048, DenseNet: 1024)\n",
    "            num_patches (int): Number of patches per image (default: 8)\n",
    "            dropout (float): Dropout rate for regularization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        # Attention network: learns importance of each patch\n",
    "        self.attention_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, max(128, feature_dim // 4)),\n",
    "            nn.LayerNorm(max(128, feature_dim // 4)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(max(128, feature_dim // 4), 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, patch_features, return_weights=False):\n",
    "        \"\"\"\n",
    "        Aggregate patch-level features using learned attention weights.\n",
    "\n",
    "        Args:\n",
    "            patch_features: [batch_size*num_patches, feature_dim]\n",
    "                           OR [batch_size, num_patches, feature_dim]\n",
    "            return_weights: If True, return attention weights for visualization\n",
    "\n",
    "        Returns:\n",
    "            aggregated: [batch_size, feature_dim] - image-level aggregated features\n",
    "            weights (optional): [batch_size, num_patches] - attention weights\n",
    "        \"\"\"\n",
    "        # Handle different input shapes\n",
    "        if patch_features.ndim == 2:\n",
    "            # Reshape from [B*P, D] to [B, P, D]\n",
    "            batch_size = patch_features.shape[0] // self.num_patches\n",
    "            patch_features = patch_features.view(batch_size, self.num_patches, self.feature_dim)\n",
    "        else:\n",
    "            batch_size = patch_features.shape[0]\n",
    "\n",
    "        # Compute attention scores for each patch\n",
    "        scores = self.attention_net(patch_features.view(-1, self.feature_dim))  # [B*P, 1]\n",
    "        scores = scores.view(batch_size, self.num_patches)  # [B, P]\n",
    "\n",
    "        # Convert scores to weights via softmax\n",
    "        weights = torch.nn.functional.softmax(scores, dim=1)  # [B, P]  \n",
    "\n",
    "        # Weighted aggregation of patches\n",
    "        weighted_features = patch_features * weights.unsqueeze(-1)  # [B, P, D] * [B, P, 1]\n",
    "        aggregated = weighted_features.sum(dim=1)  # [B, D]\n",
    "\n",
    "        if return_weights:\n",
    "            return aggregated, weights\n",
    "        return aggregated\n",
    "\n",
    "\n",
    "class TaskEmbedding(nn.Module):\n",
    "    def __init__(self, num_targets=5, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.task_embeddings = nn.Embedding(num_targets, embed_dim)\n",
    "    \n",
    "    def forward(self, target_idx):\n",
    "        return self.task_embeddings(target_idx)\n",
    "\n",
    "\n",
    "class VisionTransformerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Vision Transformer regression model with optional MIL aggregation and task conditioning.\n",
    "\n",
    "    - If use_mil=False: expects x shaped [B, 3, H, W] and returns [B] regression outputs.\n",
    "    - If use_mil=True: expects x shaped [B*P, 3, H, W] (patches grouped per-image) and returns [B] outputs.\n",
    "    - target_idx may be a tensor/array/list of length B (image-level targets) or length N (patch-level) but will be normalized.\n",
    "    - return_features: when True:\n",
    "        * if use_mil=False -> returns backbone features [B, D]\n",
    "        * if use_mil=True  -> returns per-patch features [B*P, D] (useful for MIL training)\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained=False, use_mil=False, num_patches=8):\n",
    "        super().__init__()\n",
    "        self.use_mil = bool(use_mil)\n",
    "        self.num_patches = int(num_patches)\n",
    "        self.task_embed = TaskEmbedding()  # expects to exist in scope\n",
    "\n",
    "        # Create ViT backbone (try with pretrained flag, fallback to pretrained=False)\n",
    "        try:\n",
    "            self.backbone = create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "            logger.info(f\"âœ“ ViT backbone created (pretrained={pretrained})\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ViT create_model(pretrained={pretrained}) failed ({e}) -> retrying with pretrained=False\")\n",
    "            self.backbone = create_model('vit_base_patch16_224', pretrained=False)\n",
    "\n",
    "        # Remove final classification head (support common naming)\n",
    "        if hasattr(self.backbone, \"head\"):\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif hasattr(self.backbone, \"fc\"):\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        elif hasattr(self.backbone, \"classifier\"):\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # Infer ViT embedding dim robustly\n",
    "        vit_feat_dim = getattr(self.backbone, 'embed_dim', None) \\\n",
    "                       or getattr(self.backbone, 'num_features', None) \\\n",
    "                       or 768\n",
    "        self.vit_feat_dim = int(vit_feat_dim)\n",
    "\n",
    "        # MIL aggregator (if requested) â€” uses runtime vit_feat_dim\n",
    "        if self.use_mil:\n",
    "            self.mil_aggregator = MILAggregator(\n",
    "                feature_dim=self.vit_feat_dim,\n",
    "                num_patches=self.num_patches,\n",
    "                dropout=0.2\n",
    "            )\n",
    "\n",
    "        # Regression head: use runtime embedding dim + task embedding dim (64)\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.vit_feat_dim + 64, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        logger.info(f\"VisionTransformerModel initialized (use_mil={self.use_mil}, num_patches={self.num_patches}, vit_feat_dim={self.vit_feat_dim})\")\n",
    "\n",
    "    def forward(self, x, target_idx=None, return_features=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: torch.Tensor\n",
    "               - if use_mil=False: shape [B, 3, H, W]\n",
    "               - if use_mil=True:  shape [B*P, 3, H, W] where P = self.num_patches\n",
    "            target_idx: tensor/list/ndarray of target indices (image-level), length B (preferred)\n",
    "            return_features: bool - if True returns features (no regression head applied)\n",
    "        Returns:\n",
    "            - if return_features True:\n",
    "                * use_mil=False -> (B, D)\n",
    "                * use_mil=True  -> (B*P, D)\n",
    "            - else:\n",
    "                * use_mil=False -> (B,) regression outputs\n",
    "                * use_mil=True  -> (B,) regression outputs\n",
    "        \"\"\"\n",
    "        # Backbone forward\n",
    "        features = self.backbone(x)  # many vit backbones return shape [N, 1, D] or [N, D]\n",
    "\n",
    "        # Normalize feature shape: if backbone returns sequence-like [N, seq, D], pick CLS token position 0\n",
    "        if features.ndim == 3:\n",
    "            # e.g. [N, 1, D] or [N, S, D] -> take first token\n",
    "            features = features[:, 0, :]  # [N, D]\n",
    "        elif features.ndim == 4:\n",
    "            # unlikely for ViT, but flatten safely\n",
    "            features = features.view(features.size(0), -1)\n",
    "\n",
    "        # If return_features requested and not using MIL: return per-batch features\n",
    "        if return_features and not self.use_mil:\n",
    "            # features is [B, D] expected\n",
    "            return features\n",
    "\n",
    "        # Ensure features is 2D [N, D]\n",
    "        assert features.ndim == 2, f\"Backbone produced unexpected feature dims: {features.shape}\"\n",
    "\n",
    "        # Ensure target_idx is a LongTensor on same device when used for embedding\n",
    "        if target_idx is not None:\n",
    "            if not torch.is_tensor(target_idx):\n",
    "                target_idx = torch.tensor(target_idx, dtype=torch.long, device=features.device)\n",
    "            else:\n",
    "                target_idx = target_idx.long().to(features.device)\n",
    "\n",
    "        # Non-MIL mode: treat features as per-image features (batch size = features.size(0))\n",
    "        if not self.use_mil:\n",
    "            B = features.size(0)\n",
    "            # prepare task embedding: expects one index per image in batch\n",
    "            if target_idx is not None:\n",
    "                # If user passed per-patch indices accidentally, try to reduce to per-image\n",
    "                if target_idx.dim() > 1:\n",
    "                    target_idx = target_idx.view(-1)[:B]\n",
    "                # if length mismatches, try to broadcast or slice\n",
    "                if target_idx.numel() != B:\n",
    "                    if target_idx.numel() < B:\n",
    "                        # extend with zeros (warning)\n",
    "                        pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=features.device)\n",
    "                        target_idx = torch.cat([target_idx, pad], dim=0)\n",
    "                    else:\n",
    "                        target_idx = target_idx[:B]\n",
    "                task_emb = self.task_embed(target_idx)\n",
    "            else:\n",
    "                task_emb = torch.zeros(B, 64, device=features.device)\n",
    "\n",
    "            combined = torch.cat([features, task_emb], dim=-1)  # [B, D+64]\n",
    "            out = self.regression_head(combined).squeeze(-1)     # [B]\n",
    "            return out\n",
    "\n",
    "        # MIL mode: aggregate patches\n",
    "        # If return_features True: return per-patch features (useful to build MIL losses)\n",
    "        if return_features and self.use_mil:\n",
    "            return features  # [B*P, D]\n",
    "\n",
    "        # EXPECT features is [N, D] where N = B * P\n",
    "        N = features.size(0)\n",
    "        assert N % self.num_patches == 0, f\"Number of feature rows ({N}) is not divisible by num_patches ({self.num_patches})\"\n",
    "        B = N // self.num_patches\n",
    "        C = features.size(-1)\n",
    "        # Reshape into [B, P, D]\n",
    "        patches = features.view(B, self.num_patches, C).contiguous()  # [B, P, D]\n",
    "\n",
    "        # Aggregate patches to image-level embedding\n",
    "        aggregated = self.mil_aggregator(patches)  # [B, D]\n",
    "\n",
    "        # Prepare task embedding for B images; ensure device/dtype correctness\n",
    "        if target_idx is not None:\n",
    "            # If target_idx was per-patch, convert to per-image by taking every num_patches-th element\n",
    "            if target_idx.numel() == N:\n",
    "                target_idx_img = target_idx.view(B, self.num_patches)[:, 0]\n",
    "            elif target_idx.numel() == B:\n",
    "                target_idx_img = target_idx\n",
    "            elif target_idx.numel() < B:\n",
    "                # pad with zeros\n",
    "                pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=features.device)\n",
    "                target_idx_img = torch.cat([target_idx, pad], dim=0)\n",
    "            else:\n",
    "                target_idx_img = target_idx[:B]\n",
    "            target_idx_img = target_idx_img.long().to(aggregated.device)\n",
    "            task_emb = self.task_embed(target_idx_img)\n",
    "        else:\n",
    "            task_emb = torch.zeros(B, 64, device=aggregated.device)\n",
    "\n",
    "        combined = torch.cat([aggregated, task_emb], dim=-1)  # [B, D+64]\n",
    "        predictions = self.regression_head(combined).squeeze(-1)  # [B]\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "class ResNet50Model(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet50 regression model with optional MIL aggregation and task conditioning.\n",
    "\n",
    "    - If use_mil=False: expects x shaped [B, 3, H, W] and returns [B] regression outputs.\n",
    "    - If use_mil=True: expects x shaped [B*P, 3, H, W] (patches grouped per-image) and returns [B] outputs.\n",
    "    - return_features: when True:\n",
    "        * if use_mil=False -> returns backbone features [B, D]\n",
    "        * if use_mil=True  -> returns per-patch features [B*P, D]\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained=False, use_mil=False, num_patches=8):\n",
    "        super().__init__()\n",
    "        self.use_mil = bool(use_mil)\n",
    "        self.num_patches = int(num_patches)\n",
    "        self.task_embed = TaskEmbedding()\n",
    "\n",
    "        # Load ResNet backbone (try pretrained flag, fallback to pretrained=False)\n",
    "        try:\n",
    "            self.backbone = resnet50(pretrained=pretrained)\n",
    "            logger.info(f\"âœ“ ResNet50 backbone created (pretrained={pretrained})\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"ResNet50 create failed ({e}) -> retrying with pretrained=False\")\n",
    "            self.backbone = resnet50(pretrained=False)\n",
    "\n",
    "        # Remove final fc/classifier so backbone returns embeddings\n",
    "        # Many resnet implementations have `.fc` as final; replace with Identity\n",
    "        if hasattr(self.backbone, \"fc\"):\n",
    "            self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # Attempt to infer output feature dim robustly\n",
    "        out_dim = getattr(self.backbone, \"num_features\", None) \\\n",
    "                  or getattr(self.backbone, \"out_features\", None) \\\n",
    "                  or 2048\n",
    "        self.out_dim = int(out_dim)\n",
    "\n",
    "        # MIL aggregator uses runtime out_dim\n",
    "        if self.use_mil:\n",
    "            self.mil_aggregator = MILAggregator(feature_dim=self.out_dim, num_patches=self.num_patches, dropout=0.2)\n",
    "\n",
    "        # Regression head uses runtime out_dim + task embedding (64)\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.out_dim + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        logger.info(f\"ResNet50Model initialized (use_mil={self.use_mil}, num_patches={self.num_patches}, out_dim={self.out_dim})\")\n",
    "\n",
    "    def _normalize_target_idx(self, target_idx, features_rows):\n",
    "        \"\"\"\n",
    "        Ensure target_idx is LongTensor on same device and aligns to image-level B.\n",
    "        features_rows: number of rows from backbone (N), equals B when non-MIL, or B*P when MIL.\n",
    "        \"\"\"\n",
    "        if target_idx is None:\n",
    "            return None\n",
    "\n",
    "        if not torch.is_tensor(target_idx):\n",
    "            target_idx = torch.tensor(target_idx, dtype=torch.long, device=next(self.parameters()).device)\n",
    "        else:\n",
    "            target_idx = target_idx.long().to(next(self.parameters()).device)\n",
    "\n",
    "        return target_idx\n",
    "\n",
    "    def forward(self, x, target_idx=None, return_features=False):\n",
    "        \"\"\"\n",
    "        x: [B,3,H,W] (non-MIL) OR [B*P,3,H,W] (MIL)\n",
    "        target_idx: optional indices (per-image preferred)\n",
    "        \"\"\"\n",
    "        features = self.backbone(x)\n",
    "        # backbone output may be: [N, C, 1, 1] (if conv output), [N, C] or [N, S, C]\n",
    "        if features.ndim == 4:\n",
    "            # [N, C, 1, 1] -> flatten to [N, C]\n",
    "            features = torch.nn.functional.adaptive_avg_pool2d(features, 1)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        elif features.ndim == 3:\n",
    "            # e.g. [N, 1, C] or [N, S, C] -> take first token (safe)\n",
    "            features = features[:, 0, :]\n",
    "\n",
    "        assert features.ndim == 2, f\"ResNet backbone returned unexpected feature tensor shape {features.shape}\"\n",
    "\n",
    "        # Normalize target_idx to tensor on the right device\n",
    "        target_idx = self._normalize_target_idx(target_idx, features.size(0))\n",
    "\n",
    "        # Non-MIL mode: per-image features\n",
    "        if not self.use_mil:\n",
    "            B = features.size(0)\n",
    "            if target_idx is not None:\n",
    "                # attempt to align length\n",
    "                if target_idx.numel() != B:\n",
    "                    if target_idx.numel() < B:\n",
    "                        pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=features.device)\n",
    "                        target_idx = torch.cat([target_idx, pad], dim=0)\n",
    "                    else:\n",
    "                        target_idx = target_idx[:B]\n",
    "                target_idx_img = target_idx\n",
    "                task_emb = self.task_embed(target_idx_img)\n",
    "            else:\n",
    "                task_emb = torch.zeros(B, 64, device=features.device)\n",
    "\n",
    "            combined = torch.cat([features, task_emb], dim=-1)\n",
    "            out = self.regression_head(combined).squeeze(-1)\n",
    "            if return_features:\n",
    "                return features\n",
    "            return out\n",
    "\n",
    "        # MIL mode\n",
    "        if return_features and self.use_mil:\n",
    "            return features  # per-patch features [B*P, D]\n",
    "\n",
    "        N = features.size(0)\n",
    "        assert N % self.num_patches == 0, f\"Number of rows ({N}) not divisible by num_patches ({self.num_patches})\"\n",
    "        B = N // self.num_patches\n",
    "        C = features.size(-1)\n",
    "        patches = features.view(B, self.num_patches, C).contiguous()  # [B, P, D]\n",
    "        aggregated = self.mil_aggregator(patches)  # [B, D]\n",
    "\n",
    "        # prepare image-level target_idx\n",
    "        if target_idx is not None:\n",
    "            if target_idx.numel() == N:\n",
    "                target_idx_img = target_idx.view(B, self.num_patches)[:, 0]\n",
    "            elif target_idx.numel() == B:\n",
    "                target_idx_img = target_idx\n",
    "            elif target_idx.numel() < B:\n",
    "                pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=features.device)\n",
    "                target_idx_img = torch.cat([target_idx, pad], dim=0)\n",
    "            else:\n",
    "                target_idx_img = target_idx[:B]\n",
    "            target_idx_img = target_idx_img.long().to(aggregated.device)\n",
    "            task_emb = self.task_embed(target_idx_img)\n",
    "        else:\n",
    "            task_emb = torch.zeros(B, 64, device=aggregated.device)\n",
    "\n",
    "        combined = torch.cat([aggregated, task_emb], dim=-1)\n",
    "        preds = self.regression_head(combined).squeeze(-1)\n",
    "        return preds\n",
    "\n",
    "\n",
    "class DenseNet121Model(nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet121 regression model with optional MIL aggregation and task conditioning.\n",
    "\n",
    "    Same interface as ResNet50Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained=False, use_mil=False, num_patches=8):\n",
    "        super().__init__()\n",
    "        self.use_mil = bool(use_mil)\n",
    "        self.num_patches = int(num_patches)\n",
    "        self.task_embed = TaskEmbedding()\n",
    "\n",
    "        # Load DenseNet backbone\n",
    "        try:\n",
    "            self.backbone = densenet121(pretrained=pretrained)\n",
    "            logger.info(f\"âœ“ DenseNet121 backbone created (pretrained={pretrained})\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"DenseNet121 create failed ({e}) -> retrying with pretrained=False\")\n",
    "            self.backbone = densenet121(pretrained=False)\n",
    "\n",
    "        # Remove classifier head if present\n",
    "        if hasattr(self.backbone, \"classifier\"):\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # infer out_dim robustly\n",
    "        out_dim = getattr(self.backbone, \"num_features\", None) \\\n",
    "                  or getattr(self.backbone, \"out_features\", None) \\\n",
    "                  or 1024\n",
    "        self.out_dim = int(out_dim)\n",
    "\n",
    "        if self.use_mil:\n",
    "            self.mil_aggregator = MILAggregator(feature_dim=self.out_dim, num_patches=self.num_patches, dropout=0.2)\n",
    "\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(self.out_dim + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        logger.info(f\"DenseNet121Model initialized (use_mil={self.use_mil}, num_patches={self.num_patches}, out_dim={self.out_dim})\")\n",
    "\n",
    "    def _normalize_target_idx(self, target_idx):\n",
    "        if target_idx is None:\n",
    "            return None\n",
    "        if not torch.is_tensor(target_idx):\n",
    "            target_idx = torch.tensor(target_idx, dtype=torch.long, device=next(self.parameters()).device)\n",
    "        else:\n",
    "            target_idx = target_idx.long().to(next(self.parameters()).device)\n",
    "        return target_idx\n",
    "\n",
    "    def forward(self, x, target_idx=None, return_features=False):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # DenseNet may return [N, C, 1, 1] or [N, C] or [N, S, C], normalize\n",
    "        if features.ndim == 4:\n",
    "            features = torch.nn.functional.adaptive_avg_pool2d(features, 1)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        elif features.ndim == 3:\n",
    "            features = features[:, 0, :]\n",
    "\n",
    "        assert features.ndim == 2, f\"DenseNet backbone returned unexpected features shape: {features.shape}\"\n",
    "\n",
    "        target_idx = self._normalize_target_idx(target_idx)\n",
    "\n",
    "        if not self.use_mil:\n",
    "            B = features.size(0)\n",
    "            if target_idx is not None:\n",
    "                if target_idx.numel() != B:\n",
    "                    if target_idx.numel() < B:\n",
    "                        pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=features.device)\n",
    "                        target_idx = torch.cat([target_idx, pad], dim=0)\n",
    "                    else:\n",
    "                        target_idx = target_idx[:B]\n",
    "                task_emb = self.task_embed(target_idx)\n",
    "            else:\n",
    "                task_emb = torch.zeros(B, 64, device=features.device)\n",
    "\n",
    "            combined = torch.cat([features, task_emb], dim=-1)\n",
    "            out = self.regression_head(combined).squeeze(-1)\n",
    "            if return_features:\n",
    "                return features\n",
    "            return out\n",
    "\n",
    "        # MIL mode\n",
    "        if return_features and self.use_mil:\n",
    "            return features\n",
    "\n",
    "        N = features.size(0)\n",
    "        assert N % self.num_patches == 0, f\"Rows ({N}) not divisible by num_patches ({self.num_patches})\"\n",
    "        B = N // self.num_patches\n",
    "        C = features.size(-1)\n",
    "        patches = features.view(B, self.num_patches, C).contiguous()\n",
    "        aggregated = self.mil_aggregator(patches)\n",
    "\n",
    "        if target_idx is not None:\n",
    "            if target_idx.numel() == N:\n",
    "                target_idx_img = target_idx.view(B, self.num_patches)[:, 0]\n",
    "            elif target_idx.numel() == B:\n",
    "                target_idx_img = target_idx\n",
    "            elif target_idx.numel() < B:\n",
    "                pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=features.device)\n",
    "                target_idx_img = torch.cat([target_idx, pad], dim=0)\n",
    "            else:\n",
    "                target_idx_img = target_idx[:B]\n",
    "            target_idx_img = target_idx_img.long().to(aggregated.device)\n",
    "            task_emb = self.task_embed(target_idx_img)\n",
    "        else:\n",
    "            task_emb = torch.zeros(B, 64, device=aggregated.device)\n",
    "\n",
    "        combined = torch.cat([aggregated, task_emb], dim=-1)\n",
    "        preds = self.regression_head(combined).squeeze(-1)\n",
    "        return preds\n",
    "\n",
    "\n",
    "class XGBoostTabularModel:\n",
    "    \"\"\"\n",
    "    XGBoost model for tabular features.\n",
    "    Trains separate XGBoost models for each biomass target type.\n",
    "    \n",
    "    FIXED IMPROVEMENTS:\n",
    "    - Added regularization: reg_alpha, reg_lambda, min_child_weight, gamma\n",
    "    - Added early stopping for validation-based training\n",
    "    - FIXED: Proper train/val split to prevent data contamination\n",
    "    - Better hyperparameters for noisy tabular features\n",
    "    - More conservative settings to prevent overfitting\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lookups_dict, targets=None):\n",
    "        \"\"\"\n",
    "        Initialize XGBoost models for each target.\n",
    "\n",
    "        Args:\n",
    "            lookups_dict: Dictionary with STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS\n",
    "            targets: optional list of target names to initialize (defaults to known list)\n",
    "        \"\"\"\n",
    "        STATE_COLS = lookups_dict.get('STATE_COLS', [])\n",
    "        SPECIES_COLS = lookups_dict.get('SPECIES_COLS', [])\n",
    "        TARGET_TYPE_COLS = lookups_dict.get('TARGET_TYPE_COLS', [])\n",
    "\n",
    "        self.models = {}\n",
    "        self.feature_names = (\n",
    "            ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'Month', 'DayOfYear', 'Quarter']\n",
    "            + STATE_COLS + SPECIES_COLS + TARGET_TYPE_COLS\n",
    "        )\n",
    "\n",
    "        logger.info(\"âœ“ XGBoost initialized (tree-based model)\")\n",
    "        logger.info(f\"  - Features: {len(self.feature_names)} ({', '.join(self.feature_names[:3])}...)\")\n",
    "        logger.info(\"  - Separate model for each biomass target type\")\n",
    "        logger.info(\"  - WITH regularization and early stopping\")\n",
    "        logger.info(\"  - FIXED: Proper train/val split to prevent overfitting\")\n",
    "\n",
    "        if targets is None:\n",
    "            targets = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "        # Initialize one model per target\n",
    "        for target_name in targets:\n",
    "            self.models[target_name] = xgb.XGBRegressor(\n",
    "                n_estimators=CONFIG.get('xgb_n_estimators', 1000),              # Reduced from 1500\n",
    "                max_depth=CONFIG.get('xgb_max_depth', 4),                       # Reduced from 5\n",
    "                learning_rate=CONFIG.get('xgb_learning_rate', 0.05),            # Increased from 0.015\n",
    "                subsample=CONFIG.get('xgb_subsample', 0.75),                    # Reduced from 0.8\n",
    "                colsample_bytree=CONFIG.get('xgb_colsample_bytree', 0.75),      # Reduced from 0.8\n",
    "                min_child_weight=CONFIG.get('xgb_min_child_weight', 5),         # Increased from 4\n",
    "                reg_alpha=CONFIG.get('xgb_reg_alpha', 0.5),                     # Increased from 0.3\n",
    "                reg_lambda=CONFIG.get('xgb_reg_lambda', 1.5),                   # Increased from 1.0\n",
    "                gamma=CONFIG.get('xgb_gamma', 1.0),                             # Increased from 0.8\n",
    "                random_state=CONFIG.get('random_seed', 42),\n",
    "                tree_method='gpu_hist' if torch.cuda.is_available() else 'auto',\n",
    "                verbosity=0\n",
    "            )\n",
    "\n",
    "    def fit(self, X, y, target_names):\n",
    "        \"\"\"\n",
    "        Train XGBoost models with early stopping.\n",
    "        \n",
    "        FIXED: Implements proper train/eval split to prevent data contamination.\n",
    "        The key fix is that we create eval sets from training data only,\n",
    "        ensuring that validation data used for early stopping is completely\n",
    "        separate from any external evaluation or meta-learner training.\n",
    "\n",
    "        Args:\n",
    "            X (np.array or pd.DataFrame): Tabular features (n_samples, len(feature_names))\n",
    "            y (np.array): Target values (n_samples,)\n",
    "            target_names (np.array): Target type names (n_samples,)\n",
    "        \"\"\"\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        # accept DataFrame or numpy; ensure numpy for xgboost .fit\n",
    "        if hasattr(X, \"values\"):\n",
    "            X_arr = X.values\n",
    "        else:\n",
    "            X_arr = np.asarray(X)\n",
    "\n",
    "        for target_type, model in self.models.items():\n",
    "            mask = (np.array(target_names) == target_type)\n",
    "            n = int(mask.sum())\n",
    "            if n > 0:\n",
    "                X_target = X_arr[mask]\n",
    "                y_target = np.asarray(y)[mask]\n",
    "                \n",
    "                # Use early stopping if enough samples\n",
    "                if n > 50:  # Increased threshold from 30 to 50\n",
    "                    # FIXED: Create internal train/eval split for early stopping\n",
    "                    # This is used ONLY for early stopping, not for external validation\n",
    "                    X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "                        X_target, y_target,\n",
    "                        test_size=0.15,  # Reduced from 0.2 to have larger training set\n",
    "                        random_state=CONFIG.get('random_seed', 42)\n",
    "                    )\n",
    "                    \n",
    "                    model.fit(\n",
    "                        X_train, y_train,\n",
    "                        eval_set=[(X_eval, y_eval)],\n",
    "                        eval_metric='rmse',  # Explicit metric specification\n",
    "                        early_stopping_rounds=CONFIG.get('xgb_early_stopping_rounds', 50),  # Reduced from 75\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # Log diagnostics to monitor overfitting\n",
    "                    best_iter = model.best_iteration\n",
    "                    best_score = model.best_score\n",
    "                    logger.info(f\"âœ“ XGBoost trained for {target_type} ({n} samples, early stopping)\")\n",
    "                    logger.info(f\"  - Best iteration: {best_iter}, Best RMSE: {best_score:.4f}\")\n",
    "                    logger.info(f\"  - Train samples: {len(X_train)}, Eval samples: {len(X_eval)}\")\n",
    "                    \n",
    "                    # Alert if using too many trees (potential overfitting sign)\n",
    "                    if best_iter > 800:\n",
    "                        logger.warning(f\"  âš ï¸ WARNING: Used {best_iter} trees - monitor for overfitting!\")\n",
    "                else:\n",
    "                    # Train without early stopping if not enough samples\n",
    "                    model.fit(X_target, y_target)\n",
    "                    logger.info(f\"âœ“ XGBoost trained for {target_type} ({n} samples, no early stopping)\")\n",
    "            else:\n",
    "                logger.info(f\"â†’ No samples for {target_type}; skipping training\")\n",
    "\n",
    "    def predict(self, X, target_name):\n",
    "        \"\"\"\n",
    "        Make predictions.\n",
    "\n",
    "        Args:\n",
    "            X (np.array or pd.DataFrame): Tabular features (n_samples, len(feature_names))\n",
    "            target_name (str): Target type\n",
    "\n",
    "        Returns:\n",
    "            np.array: Predictions\n",
    "        \"\"\"\n",
    "        if target_name not in self.models:\n",
    "            raise ValueError(f\"Model for target '{target_name}' not found. Available: {list(self.models.keys())}\")\n",
    "\n",
    "        if hasattr(X, \"values\"):\n",
    "            X_arr = X.values\n",
    "        else:\n",
    "            X_arr = np.asarray(X)\n",
    "\n",
    "        return self.models[target_name].predict(X_arr)\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Save models to a pickle file (only models dict).\"\"\"\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump({'models': self.models, 'feature_names': self.feature_names}, f)\n",
    "        logger.info(f\"âœ“ XGBoost models saved to {path}\")\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"Load models from a pickle file.\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        self.models = data.get('models', {})\n",
    "        self.feature_names = data.get('feature_names', self.feature_names)\n",
    "        logger.info(f\"âœ“ XGBoost models loaded from {path}\")\n",
    "\n",
    "        \n",
    "class MetaLearnerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    âœ“ Refactored for small data (~1700 samples)\n",
    "    âœ“ Symmetric treatment of all 5 inputs: [ViT, ResNet, DenseNet, XGBoost, Smart_Ensemble]\n",
    "    âœ“ Task-conditioned gating based on research in Mixture-of-Experts\n",
    "    âœ“ Minimal overfitting risk through regularization\n",
    "    âœ“ Backward compatible with existing training loop\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_rate=0.1, pretrained=False, num_base_preds=5):\n",
    "        super().__init__()\n",
    "        self.num_base_preds = int(num_base_preds)  # Keep for backward compat\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "        # ============ TASK EMBEDDING ============\n",
    "        # Reduced from 64 â†’ 32 to prevent overfitting on small data\n",
    "        self.task_embed = TaskEmbedding(num_targets=5, embed_dim=32)\n",
    "        \n",
    "        # ============ GATING NETWORK (Task-Conditioned Expert Weighting) ============\n",
    "        # Takes task context (32D) and outputs weights for ALL 5 models\n",
    "        # Research shows this is more stable than arbitrary slicing\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(32, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, 16),  # Bottleneck to regularize\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate * 0.8),\n",
    "            nn.Linear(16, self.num_base_preds)  # Output: 1 weight per model\n",
    "        )\n",
    "        \n",
    "        # ============ TRUNK (Residual Correction) ============\n",
    "        # Small correction network (not the main predictor)\n",
    "        # Input: 5 (raw preds) + 1 (weighted ensemble) + 32 (task) = 38\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Linear(5 + 1 + 32, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate * 0.8),\n",
    "            nn.Linear(16, 1)  # Output: correction scalar\n",
    "        )\n",
    "        \n",
    "        self.register_buffer('_eps', torch.tensor(1e-6))\n",
    "    \n",
    "    def forward(self, predictions, target_idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: [B, 5] - predictions from 5 base models\n",
    "                        Index 0: ViT\n",
    "                        Index 1: ResNet\n",
    "                        Index 2: DenseNet\n",
    "                        Index 3: XGBoost\n",
    "                        Index 4: Smart_Ensemble (Inverse-Variance Weighted)\n",
    "            target_idx: [B] - target type indices (0-4)\n",
    "        \n",
    "        Returns:\n",
    "            [B] - final meta-learner predictions\n",
    "        \"\"\"\n",
    "        preds = predictions.float()\n",
    "        \n",
    "        if preds.ndim != 2:\n",
    "            raise ValueError(f\"predictions must be 2D [B, num_preds], got {preds.shape}\")\n",
    "        \n",
    "        B = preds.shape[0]\n",
    "        \n",
    "        # ========== DEVICE & SHAPE HANDLING (Backward Compatible) ==========\n",
    "        if not torch.is_tensor(target_idx):\n",
    "            target_idx = torch.tensor(target_idx, dtype=torch.long, device=preds.device)\n",
    "        else:\n",
    "            target_idx = target_idx.long().to(preds.device)\n",
    "        \n",
    "        if target_idx.numel() != B:\n",
    "            if target_idx.numel() < B:\n",
    "                pad = torch.zeros(B - target_idx.numel(), dtype=torch.long, device=preds.device)\n",
    "                target_idx = torch.cat([target_idx, pad], dim=0)\n",
    "            else:\n",
    "                target_idx = target_idx[:B]\n",
    "        \n",
    "        # ========== CORE LOGIC (FIXED) ==========\n",
    "        \n",
    "        # 1. Get Task Context\n",
    "        task_embedding = self.task_embed(target_idx)  # [B, 32]\n",
    "        \n",
    "        # 2. Compute Dynamic Weights for ALL 5 Models (Symmetric)\n",
    "        # This is the KEY FIX: Use softmax so weights sum to 1.0 and all models compete equally\n",
    "        gate_logits = self.gate(task_embedding)  # [B, 5]\n",
    "        gate_weights = torch.softmax(gate_logits, dim=1)  # [B, 5] - sums to 1\n",
    "        \n",
    "        # 3. Weighted Ensemble Prediction (Symmetric)\n",
    "        # Now XGBoost (index 3) and Smart_Ensemble (index 4) have equal opportunity to be weighted\n",
    "        weighted_ensemble = torch.sum(gate_weights * preds, dim=1, keepdim=True)  # [B, 1]\n",
    "        \n",
    "        # 4. Residual Correction (Reduced Size)\n",
    "        # The trunk sees the raw votes + the weighted ensemble + task context\n",
    "        # It learns a small CORRECTION, not the full prediction\n",
    "        trunk_input = torch.cat([preds, weighted_ensemble, task_embedding], dim=1)  # [B, 38]\n",
    "        correction = self.trunk(trunk_input).squeeze(-1)  # [B]\n",
    "        \n",
    "        # 5. Final Output = Weighted Ensemble + Correction\n",
    "        final = weighted_ensemble.squeeze(-1) + correction  # [B]\n",
    "        \n",
    "        return final\n",
    "\n",
    "\n",
    "\n",
    "class SpeciesClassificationViT(nn.Module):\n",
    "    \"\"\"\n",
    "    Vision Transformer for species classification with optional MIL aggregation.\n",
    "\n",
    "    Inputs:\n",
    "      - x: [B*P, 3, 224, 224] patches (P = num_patches, default 8)\n",
    "\n",
    "    Modes:\n",
    "      - use_mil = False -> output per-patch logits: [B*P, num_classes]\n",
    "      - use_mil = True  -> aggregate patches -> output image-level logits: [B, num_classes]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_species_classes=16, pretrained=False, use_mil=False, num_patches=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # create backbone (honour pretrained flag)\n",
    "        self.backbone = create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "\n",
    "        # remove default head (return embedding vectors)\n",
    "        if hasattr(self.backbone, \"head\"):\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif hasattr(self.backbone, \"fc\"):\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        elif hasattr(self.backbone, \"classifier\"):\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # infer embedding dim robustly\n",
    "        in_dim = getattr(self.backbone, 'num_features', None) \\\n",
    "                 or getattr(self.backbone, 'embed_dim', None) \\\n",
    "                 or 768\n",
    "        self.in_dim = int(in_dim)\n",
    "\n",
    "        self.num_classes = int(num_species_classes)\n",
    "        self.use_mil = bool(use_mil)\n",
    "        self.num_patches = int(num_patches)\n",
    "\n",
    "        # classification head (works on either aggregated image embedding or per-patch embedding)\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, self.num_classes)\n",
    "        )\n",
    "\n",
    "        # optional MIL aggregator\n",
    "        if self.use_mil:\n",
    "            self.mil_aggregator = MILAggregator(feature_dim=self.in_dim, num_patches=self.num_patches, dropout=0.2)\n",
    "\n",
    "        self.species_list = FIXED_SPECIES_LIST\n",
    "        assert len(self.species_list) == self.num_classes, (\n",
    "            f\"species_list length ({len(self.species_list)}) must equal num_species_classes ({self.num_classes})\"\n",
    "        )\n",
    "\n",
    "        logger.info(\"âœ“ Species Classification ViT initialized\")\n",
    "        logger.info(f\" - use_mil={self.use_mil}, num_patches={self.num_patches}, in_dim={self.in_dim}, num_classes={self.num_classes}\")\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [N, 3, H, W] where N = B*P (patches)\n",
    "            return_features: if True (during training), return features before classification\n",
    "        \n",
    "        Returns:\n",
    "            if use_mil and return_features: [B*P, in_dim] features (for training)\n",
    "            if use_mil and not return_features: [B, num_classes] logits (for inference)\n",
    "            else: [N, num_classes] logits\n",
    "        \"\"\"\n",
    "        features = self.backbone(x)\n",
    "        if features.ndim == 3:\n",
    "            features = features[:, 0, :]\n",
    "        \n",
    "        if not self.use_mil:\n",
    "            logits = self.classification_head(features)\n",
    "            return logits\n",
    "        \n",
    "        if return_features:\n",
    "            # Return raw features for training\n",
    "            return features  # [B*P, in_dim]\n",
    "        else:\n",
    "            # Return fully aggregated logits for inference\n",
    "            N = features.size(0)\n",
    "            assert N % self.num_patches == 0\n",
    "            aggregated = self.mil_aggregator(features)\n",
    "            logits = self.classification_head(aggregated)\n",
    "            return logits\n",
    "\n",
    "\n",
    "    def predict_species(self, x, with_probs=False):\n",
    "        \"\"\"\n",
    "        Convenience: run forward and return predicted index and name(s).\n",
    "\n",
    "        If model.use_mil=True and x contains patches for multiple images, x must be arranged\n",
    "        such that patches for each image are consecutive and len(x) % num_patches == 0.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)  # either [N, C] or [B, C]\n",
    "            if logits.ndim == 2:\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                preds = probs.argmax(dim=1).cpu().numpy().astype(int)\n",
    "            else:\n",
    "                # fallback in case of unexpected shape\n",
    "                logits = logits.view(-1, self.num_classes)\n",
    "                probs = FF.softmax(logits, dim=1)\n",
    "                preds = probs.argmax(dim=1).cpu().numpy().astype(int)\n",
    "\n",
    "        names = [self.species_list[p] if 0 <= p < len(self.species_list) else \"Unknown\" for p in preds]\n",
    "        if with_probs:\n",
    "            return preds, names, probs.cpu().numpy()\n",
    "        return preds, names\n",
    "\n",
    "    def save_backbone_weights(self, path):\n",
    "        try:\n",
    "            torch.save(self.backbone.state_dict(), path)\n",
    "            logger.info(f\"âœ“ Saved Species ViT backbone weights to {path}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save Species ViT backbone weights: {e}\")\n",
    "\n",
    "    def load_backbone_weights(self, path, strict=False, map_location=None):\n",
    "        try:\n",
    "            state = torch.load(path, map_location=map_location)\n",
    "            self.backbone.load_state_dict(state, strict=strict)\n",
    "            logger.info(f\"âœ“ Loaded Species ViT backbone weights from {path}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Backbone weights not found: {path}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to load Species ViT backbone weights from {path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def compute_and_save_ndvi_stats_with_sklearn(\n",
    "    train_df,\n",
    "    base_dir= RAW_DATA_DIR,\n",
    "    image_path_col=\"image_path\",\n",
    "    species_col=\"Species\",\n",
    "    ndvi_col_candidates=('Pre_GSHH_NDVI','ndvi', 'NDVI', 'vndvi'),\n",
    "    out_path= OUTPUTS_DIR / 'ndvidata.csv',\n",
    "    compute_rgb_indices=True,\n",
    "    resize_to=(512, 512),\n",
    "    min_samples_for_ml=20,\n",
    "    max_images=None,\n",
    "    force_recompute=False,\n",
    "    random_state=42,\n",
    "    model_params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute per-image RGB indices and (optionally) train per-species sklearn regressors\n",
    "    to predict the provided NDVI column. Aggregate per-species stats and save CSV.\n",
    "    \"\"\"\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if out_path.exists() and not force_recompute:\n",
    "        logger.info(\"Loading existing NDVI stats from %s\", out_path)\n",
    "        return pd.read_csv(out_path)\n",
    "\n",
    "    # validate columns\n",
    "    if image_path_col not in train_df.columns:\n",
    "        raise KeyError(f\"train_df missing column '{image_path_col}'\")\n",
    "    if species_col not in train_df.columns:\n",
    "        raise KeyError(f\"train_df missing column '{species_col}'\")\n",
    "\n",
    "    # find ndvi column if any\n",
    "    ndvi_col = None\n",
    "    for c in ndvi_col_candidates:\n",
    "        if c in train_df.columns:\n",
    "            ndvi_col = c\n",
    "            break\n",
    "    if ndvi_col is None:\n",
    "        logger.info(\"No NDVI column found in train_df; ML regression will be skipped, we will use computed indices only.\")\n",
    "\n",
    "    # model default\n",
    "    if model_params is None:\n",
    "        model_params = {'n_estimators': 100, 'max_depth': 10, 'random_state': random_state, 'n_jobs': -1}\n",
    "\n",
    "    # subset rows\n",
    "    rows = train_df[[image_path_col, species_col]].dropna().reset_index(drop=True)\n",
    "    if max_images:\n",
    "        rows = rows.iloc[:max_images]\n",
    "        logger.info(\"Limiting to first %d images\", max_images)\n",
    "    logger.info(\"Processing %d images...\", len(rows))\n",
    "\n",
    "    # storage per-image\n",
    "    per_image = []\n",
    "    # iterate\n",
    "    for idx, row in tqdm(rows.iterrows(), total=len(rows), desc=\"Extract features\"):\n",
    "        rel = row[image_path_col]\n",
    "        species = row[species_col]\n",
    "        full_path = os.path.join(base_dir, rel)\n",
    "\n",
    "        if not os.path.exists(full_path):\n",
    "            logger.warning(\"Missing image: %s\", full_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = Image.open(full_path).convert(\"RGB\")\n",
    "            if resize_to is not None:\n",
    "                img = img.resize(resize_to, Image.BILINEAR)\n",
    "            img_np = np.asarray(img, dtype=np.float32)\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np /= 255.0\n",
    "\n",
    "            R = img_np[:, :, 0]\n",
    "            G = img_np[:, :, 1]\n",
    "            B = img_np[:, :, 2]\n",
    "\n",
    "            # features\n",
    "            # vNDVI\n",
    "            denom = (G + R)\n",
    "            denom_safe = np.where(np.isclose(denom, 0.0), 1e-8, denom)\n",
    "            vndvi_arr = (G - R) / denom_safe\n",
    "            vndvi_mean = float(np.nanmean(vndvi_arr))\n",
    "\n",
    "            # rgbvi\n",
    "            if compute_rgb_indices:\n",
    "                denom_rgbvi = (G*G + R*B)\n",
    "                denom_rgbvi_safe = np.where(np.isclose(denom_rgbvi, 0.0), 1e-8, denom_rgbvi)\n",
    "                rgbvi_arr = (G*G - R*B) / denom_rgbvi_safe\n",
    "                rgbvi_mean = float(np.nanmean(rgbvi_arr))\n",
    "                denom_vari = (G + R - B)\n",
    "                denom_vari_safe = np.where(np.isclose(denom_vari, 0.0), 1e-8, denom_vari)\n",
    "                vari_arr = (G - R) / denom_vari_safe\n",
    "                vari_mean = float(np.nanmean(vari_arr))\n",
    "            else:\n",
    "                rgbvi_mean = np.nan\n",
    "                vari_mean = np.nan\n",
    "\n",
    "            mean_r = float(np.nanmean(R))\n",
    "            mean_g = float(np.nanmean(G))\n",
    "            mean_b = float(np.nanmean(B))\n",
    "            green_intensity = mean_g\n",
    "\n",
    "            # assemble features\n",
    "            features = {\n",
    "                \"image_path\": full_path,\n",
    "                \"species\": species,\n",
    "                \"vndvi_raw\": vndvi_mean,\n",
    "                \"vndvi_clamped\": float(np.clip(vndvi_mean, 0.0, 1.0)),\n",
    "                \"rgbvi\": float(rgbvi_mean) if compute_rgb_indices else np.nan,\n",
    "                \"vari\": float(vari_mean) if compute_rgb_indices else np.nan,\n",
    "                \"mean_r\": mean_r,\n",
    "                \"mean_g\": mean_g,\n",
    "                \"mean_b\": mean_b,\n",
    "                \"green_intensity\": green_intensity\n",
    "            }\n",
    "\n",
    "            # true ndvi if present in train_df\n",
    "            if ndvi_col is not None:\n",
    "                # attempt to locate matching row in train_df to get true ndvi (by image_path)\n",
    "                # We assume train_df may have duplicate image paths; pick the first\n",
    "                try:\n",
    "                    # find exact row in the original train_df (iloc of matching relative path)\n",
    "                    match = train_df[train_df[image_path_col] == rel]\n",
    "                    if len(match) > 0 and ndvi_col in match.columns:\n",
    "                        features[\"true_ndvi\"] = float(match[ndvi_col].iloc[0])\n",
    "                    else:\n",
    "                        features[\"true_ndvi\"] = np.nan\n",
    "                except Exception:\n",
    "                    features[\"true_ndvi\"] = np.nan\n",
    "            else:\n",
    "                features[\"true_ndvi\"] = np.nan\n",
    "\n",
    "            per_image.append(features)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Error processing %s: %s\", full_path, e)\n",
    "\n",
    "    per_image_df = pd.DataFrame(per_image)\n",
    "    if per_image_df.empty:\n",
    "        logger.error(\"No valid images processed.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare output structure\n",
    "    species_rows = []\n",
    "\n",
    "    # group by species and optionally train a model per species\n",
    "    grouped = per_image_df.groupby(\"species\")\n",
    "    for species, g in grouped:\n",
    "        g = g.reset_index(drop=True)\n",
    "        sample_count = len(g)\n",
    "        logger.info(\"Species='%s': samples=%d\", species, sample_count)\n",
    "\n",
    "        # default per-image ndvi estimate (vndvi_clamped)\n",
    "        g[\"pred_ndvi_baseline\"] = g[\"vndvi_clamped\"].values\n",
    "\n",
    "        used_model = False\n",
    "        model_score = None\n",
    "\n",
    "        # train ML only if we have true_ndvi and enough samples\n",
    "        if ndvi_col is not None and g[\"true_ndvi\"].notna().sum() >= min_samples_for_ml:\n",
    "            # features to use\n",
    "            feat_cols = [\"vndvi_raw\", \"rgbvi\", \"vari\", \"mean_r\", \"mean_g\", \"mean_b\", \"green_intensity\"]\n",
    "            # drop rows with NaN in features or target\n",
    "            df_train = g.dropna(subset=[\"true_ndvi\"] + feat_cols)\n",
    "            if len(df_train) >= min_samples_for_ml:\n",
    "                X = df_train[feat_cols].astype(float).values\n",
    "                y = df_train[\"true_ndvi\"].astype(float).values\n",
    "\n",
    "                # quick train/val split to guard overfitting\n",
    "                X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.15, random_state=random_state)\n",
    "\n",
    "                try:\n",
    "                    rf = RandomForestRegressor(**model_params)\n",
    "                    rf.fit(X_tr, y_tr)\n",
    "                    y_pred_val = rf.predict(X_val)\n",
    "                    r2 = r2_score(y_val, y_pred_val)\n",
    "                    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "                    model_score = {\"r2_val\": float(r2), \"mae_val\": float(mae)}\n",
    "                    logger.info(\"  Trained RF (species=%s): r2=%.4f, mae=%.4f\", species, r2, mae)\n",
    "\n",
    "                    # predict for all rows of this species that have features\n",
    "                    idx_has_feat = ~g[feat_cols].isnull().any(axis=1)\n",
    "                    if idx_has_feat.sum() > 0:\n",
    "                        X_all = g.loc[idx_has_feat, feat_cols].astype(float).values\n",
    "                        preds_all = rf.predict(X_all)\n",
    "                        g.loc[idx_has_feat, \"pred_ndvi_ml\"] = preds_all\n",
    "                        # where ML preds exist prefer them\n",
    "                        g[\"pred_ndvi_final\"] = g[\"pred_ndvi_ml\"].combine_first(g[\"pred_ndvi_baseline\"])\n",
    "                    else:\n",
    "                        g[\"pred_ndvi_final\"] = g[\"pred_ndvi_baseline\"]\n",
    "\n",
    "                    used_model = True\n",
    "                except Exception as e:\n",
    "                    logger.warning(\"  ML training failed for species %s: %s\", species, e)\n",
    "                    g[\"pred_ndvi_final\"] = g[\"pred_ndvi_baseline\"]\n",
    "            else:\n",
    "                logger.info(\"  Not enough clean rows for ML after dropna (%d < %d)\", len(df_train), min_samples_for_ml)\n",
    "                g[\"pred_ndvi_final\"] = g[\"pred_ndvi_baseline\"]\n",
    "        else:\n",
    "            # no NDVI column or not enough samples -> fallback to baseline\n",
    "            g[\"pred_ndvi_final\"] = g[\"pred_ndvi_baseline\"]\n",
    "\n",
    "        # enforce sane range\n",
    "        g[\"pred_ndvi_final\"] = g[\"pred_ndvi_final\"].clip(0.0, 1.0)\n",
    "\n",
    "        # compute aggregated stats\n",
    "        nd_mean = float(g[\"pred_ndvi_final\"].mean())\n",
    "        nd_min = float(g[\"pred_ndvi_final\"].min())\n",
    "        nd_max = float(g[\"pred_ndvi_final\"].max())\n",
    "\n",
    "        species_rows.append({\n",
    "            \"species\": species,\n",
    "            \"ndvi_mean\": nd_mean,\n",
    "            \"ndvi_min\": nd_min,\n",
    "            \"ndvi_max\": nd_max,\n",
    "            \"sample_count\": int(sample_count),\n",
    "            \"used_model\": bool(used_model),\n",
    "            \"model_score\": model_score\n",
    "        })\n",
    "\n",
    "    agg = pd.DataFrame(species_rows)\n",
    "    if \"model_score\" in agg.columns:\n",
    "        agg[\"model_score\"] = agg[\"model_score\"].apply(lambda x: \"\" if x is None else str(x))\n",
    "    agg.to_csv(out_path, index=False, float_format=\"%.6f\")\n",
    "    logger.info(\"Saved NDVI stats to %s (rows=%d)\", out_path, len(agg))\n",
    "    return agg\n",
    "\n",
    "\n",
    "            \n",
    "logger.info(\"âœ“ Model Architectures-6 Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8a58c",
   "metadata": {},
   "source": [
    "## 7: TRAINING FUNCTIONS\n",
    "\n",
    "**Purpose**: Train all models with monitoring, checkpointing, and memory management.\n",
    "\n",
    "### Deep Learning Training\n",
    "\n",
    "**For each vision model** (ViT, ResNet, DenseNet):\n",
    "\n",
    "```python\n",
    "def train_deep_learning_model(\n",
    "    model, train_loader, val_loader,\n",
    "    model_name, learning_rate, num_epochs, device\n",
    ")\n",
    "```\n",
    "\n",
    "**Training Loop**:\n",
    "```\n",
    "For each epoch:\n",
    "  1. Set model to training mode\n",
    "  2. Iterate through train_loader batches\n",
    "     a. Forward pass: predictions = model(images, tabular)\n",
    "     b. Compute loss: weighted_r2_loss(predictions, targets)\n",
    "     c. Backward: loss.backward()\n",
    "     d. Clip gradients: torch.nn.utils.clip_grad_norm_\n",
    "     e. Update: optimizer.step()\n",
    "     f. Clear gradients: optimizer.zero_grad()\n",
    "  3. Validation pass on val_loader\n",
    "     a. Set model to eval mode\n",
    "     b. No gradient computation\n",
    "     c. Compute RÂ² metric\n",
    "  4. Early stopping check: if no improvement for 20 epochs, stop\n",
    "  5. Save checkpoint if validation RÂ² improved\n",
    "  6. Update learning rate (cosine schedule)\n",
    "  7. Log metrics\n",
    "```\n",
    "\n",
    "\n",
    "**Memory Management**:\n",
    "- Move model to device before training\n",
    "- Clear gradients each step\n",
    "- Periodic garbage collection\n",
    "- Cleanup after training\n",
    "\n",
    "### XGBoost Training\n",
    "\n",
    "**Process**:\n",
    "1. Create XGBRegressor with configuration\n",
    "2. Train with eval_set for early stopping\n",
    "3. Monitor validation RÂ² each round\n",
    "4. Stop if no improvement for 50 rounds\n",
    "5. Return trained model + feature importance\n",
    "\n",
    "**Output**: Binary pickle file with trained weights\n",
    "\n",
    "### Meta-Learner Training\n",
    "\n",
    "**Input Format**:\n",
    "- train_pred: [n_train, 5] predictions from 5 base models\n",
    "- train_tab: [n_train, 29] tabular features\n",
    "- train_tgt: [n_train] ground truth targets\n",
    "\n",
    "**Process**:\n",
    "1. Concatenate predictions + tabular: [n, 34]\n",
    "2. Create MetaLearner network\n",
    "3. Train with weighted RÂ² loss (100 epochs)\n",
    "4. Early stopping if val RÂ² doesn't improve\n",
    "5. Save best checkpoint\n",
    "\n",
    "**Output**: \n",
    "- All models trained and checkpointed\n",
    "- Training/validation curves logged\n",
    "- Best epoch per model documented\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f1e40",
   "metadata": {},
   "source": [
    "# Helper: compute per-image targets by averaging per-patch targets\n",
    "def _image_targets_from_patch_targets(targets_per_patch, B, P, device):\n",
    "    \"\"\"\n",
    "    targets_per_patch: tensor shape (N,) or (N,1) or numpy-like, with N = B*P\n",
    "    returns: numpy array shape (B,) of per-image targets (mean across patches)\n",
    "    \"\"\"\n",
    "    if not isinstance(targets_per_patch, torch.Tensor):\n",
    "        targets_t = torch.tensor(np.asarray(targets_per_patch).ravel(), dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        targets_t = targets_per_patch.view(-1).float().to(device)\n",
    "\n",
    "    N = targets_t.numel()\n",
    "    if N != B * P:\n",
    "        # If it's already image-level (B), warn and coerce\n",
    "        if N == B:\n",
    "            return targets_t.view(B).detach().cpu().numpy()\n",
    "        # As fallback, attempt safe truncation / padding\n",
    "        if N > B * P:\n",
    "            targets_t = targets_t[: B * P]\n",
    "        else:\n",
    "            # pad with mean value if fewer than expected\n",
    "            pad_n = B * P - N\n",
    "            pad_vals = targets_t.mean().repeat(pad_n).to(device) if N > 0 else torch.zeros(pad_n, device=device)\n",
    "            targets_t = torch.cat([targets_t, pad_vals], dim=0)\n",
    "    \n",
    "    img_t = targets_t.view(B, P).mean(dim=1)\n",
    "    return img_t.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# Provided earlier but safe & identical implementation\n",
    "def _sample_ids_to_image_ids(sample_ids, patches_per_image=8):\n",
    "    \"\"\"\n",
    "    Robustly convert sample_ids (either image-level or patch-level) into\n",
    "    an ordered list of image_ids (one per image in the batch).\n",
    "    Uses run-length collapse of consecutive sample_ids so it works for:\n",
    "      - image-level: ['IMG1__T','IMG2__T', ...] -> ['IMG1','IMG2']\n",
    "      - patch-level:  ['IMG1__T', 'IMG1__T', ... (8x), 'IMG2__T', ...] -> ['IMG1','IMG2']\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sids = [str(s) for s in sample_ids]\n",
    "    except Exception:\n",
    "        sids = list(sample_ids)\n",
    "\n",
    "    if len(sids) == 0:\n",
    "        return []\n",
    "\n",
    "    img_ids = []\n",
    "    prev = None\n",
    "    for s in sids:\n",
    "        img = str(s).split(\"__\")[0]\n",
    "        if img != prev:\n",
    "            img_ids.append(img)\n",
    "            prev = img\n",
    "    return img_ids\n",
    "\n",
    "\n",
    "def _collapse_target_names_by_sample_ids(sample_ids, target_names, patches_per_image):\n",
    "    \"\"\"\n",
    "    Use sample_ids to deterministically collapse per-patch target_names to per-image names.\n",
    "    Returns ordered list of image-level names (length inferred B).\n",
    "    \"\"\"\n",
    "    # normalize\n",
    "    try:\n",
    "        sids = [str(s) for s in sample_ids]\n",
    "    except Exception:\n",
    "        sids = list(sample_ids)\n",
    "\n",
    "    try:\n",
    "        tns = [str(t) for t in target_names]\n",
    "    except Exception:\n",
    "        tns = list(target_names)\n",
    "\n",
    "    if len(sids) != len(tns):\n",
    "        # best-effort: if one is shorter/longer, fallback to simple truncation/tiling\n",
    "        if len(tns) == 1:\n",
    "            # single name -> repeat\n",
    "            # infer B\n",
    "            inferred_B = max(1, len(sids) // max(1, patches_per_image))\n",
    "            return [tns[0]] * inferred_B\n",
    "        # otherwise attempt to tile/truncate\n",
    "        if len(sids) % patches_per_image == 0:\n",
    "            # group by sids\n",
    "            img_ids = _sample_ids_to_image_ids(sids, patches_per_image)\n",
    "            img_to_name = {}\n",
    "            for sid, tn in zip(sids, tns[:len(sids)]):\n",
    "                img = sid.split(\"__\")[0]\n",
    "                if img not in img_to_name:\n",
    "                    img_to_name[img] = tn\n",
    "            return [img_to_name.get(img, \"None\") for img in img_ids]\n",
    "        else:\n",
    "            # fallback: flat unique over provided tns\n",
    "            unique = []\n",
    "            for t in tns:\n",
    "                if t not in unique:\n",
    "                    unique.append(t)\n",
    "            return unique\n",
    "\n",
    "    # normal case: len(sids) == len(tns)\n",
    "    img_ids = _sample_ids_to_image_ids(sids, patches_per_image)\n",
    "    # map first encountered patch -> name for each image (deterministic)\n",
    "    img_to_name = {}\n",
    "    for sid, tn in zip(sids, tns):\n",
    "        img = sid.split(\"__\")[0]\n",
    "        if img not in img_to_name:\n",
    "            img_to_name[img] = tn\n",
    "    return [img_to_name.get(img, \"None\") for img in img_ids]\n",
    "\n",
    "\n",
    "def _align_target_names(sample_ids, raw_target_names, pred_len, B, P):\n",
    "    \"\"\"\n",
    "    Return aligned_target_names (list of strings) length == pred_len.\n",
    "    Uses sample_ids to do deterministic grouping when possible.\n",
    "    Cases:\n",
    "     - pred_len == B (image-level predictions): return one name per image\n",
    "     - pred_len == B*P (patch-level preds): return one name per patch\n",
    "    \"\"\"\n",
    "    # Normalize raw_target_names into a list\n",
    "    if isinstance(raw_target_names, torch.Tensor):\n",
    "        try:\n",
    "            tn_list = raw_target_names.tolist()\n",
    "        except Exception:\n",
    "            tn_list = [str(x) for x in raw_target_names.cpu().numpy().ravel()]\n",
    "    elif isinstance(raw_target_names, (np.ndarray, tuple, list)):\n",
    "        tn_list = list(raw_target_names)\n",
    "    else:\n",
    "        tn_list = [str(raw_target_names)]\n",
    "\n",
    "    tn_list = [str(x) for x in tn_list]\n",
    "\n",
    "    # If lengths already match desired, simply return truncated copy\n",
    "    if len(tn_list) == pred_len:\n",
    "        return tn_list[:pred_len]\n",
    "\n",
    "    # If we have sample_ids, prefer deterministic collapse/expand\n",
    "    if sample_ids is not None:\n",
    "        try:\n",
    "            collapsed = _collapse_target_names_by_sample_ids(sample_ids, tn_list, P)\n",
    "            if pred_len == len(collapsed):  # image-level\n",
    "                return collapsed\n",
    "            elif pred_len == len(collapsed) * P:\n",
    "                # expand image names to patch-level\n",
    "                out = []\n",
    "                for nm in collapsed:\n",
    "                    out.extend([nm] * P)\n",
    "                return out[:pred_len]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Fallback heuristics:\n",
    "    if pred_len == B and len(tn_list) == B * P:\n",
    "        # collapse by taking first of each group\n",
    "        return [tn_list[i * P] for i in range(B)]\n",
    "    if pred_len == B * P and len(tn_list) == B:\n",
    "        # expand by repeating each name P times\n",
    "        out = []\n",
    "        for nm in tn_list:\n",
    "            out.extend([nm] * P)\n",
    "        return out[:pred_len]\n",
    "    # As last resort, tile/truncate\n",
    "    if len(tn_list) == 0:\n",
    "        return [\"None\"] * pred_len\n",
    "    return (tn_list * ((pred_len // len(tn_list)) + 1))[:pred_len]\n",
    "\n",
    "\n",
    "\n",
    "def train_deep_learning_model(model, train_loader, val_loader, model_name,\n",
    "                               learning_rate, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Train a patch-based deep learning model.\n",
    "\n",
    "    Keeps original variable names and overall logic, but:\n",
    "      - Uses a safe builder for target_idx from tabular features\n",
    "      - Fails fast on prediction/target length mismatches (logs and skips batch)\n",
    "      - Ensures target_idx is LongTensor on same device as model\n",
    "      - Preserves MIL / non-MIL modes and most original defensive behavior\n",
    "\n",
    "    Args:\n",
    "        model: torch.nn.Module (patch-based model). Expects signature model(images, target_idx, return_features=False)\n",
    "        train_loader, val_loader: data loaders yielding batches in the same format used previously\n",
    "        model_name: string (used for saving)\n",
    "        learning_rate: float\n",
    "        num_epochs: int\n",
    "        device: torch.device or string\n",
    "    Returns:\n",
    "        history dict with train/val loss and R2 series\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(f\"TRAINING {model_name.upper()} (PATCH-ONLY, NO TABULAR)\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "\n",
    "    use_mil = CONFIG.get(\"use_mil\", False)\n",
    "    patches_per_image = getattr(model, \"num_patches\", CONFIG.get(\"num_patches\", 8))\n",
    "    logger.info(f\"MIL Mode: {'ENABLED' if use_mil else 'DISABLED'}\")\n",
    "    logger.info(f\"Batch size: {CONFIG['batch_size']} images Ã— {patches_per_image} patches\")\n",
    "\n",
    "    # normalize device\n",
    "    try:\n",
    "        device = device if isinstance(device, torch.device) else torch.device(device if device is not None else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    except Exception:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.05)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_r2': [], 'val_r2': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Configurable target one-hot region (avoid hard-coded 25)\n",
    "    TARGET_ONEHOT_START = CONFIG.get('target_onehot_start', 25)\n",
    "    NUM_TARGET_ONEHOT = CONFIG.get('num_target_onehot', 5)\n",
    "\n",
    "    def build_target_idx_from_tabular(tabular_tensor, N, B, P, want_image_level, device):\n",
    "        \"\"\"\n",
    "        Robustly build target_idx (LongTensor) for model embedding lookup.\n",
    "        - tabular_tensor: torch.Tensor shaped (N, D) or (B, D). May be on cpu.\n",
    "        - N: number of rows in batch (patch-level)\n",
    "        - B: number of images in batch\n",
    "        - P: patches_per_image\n",
    "        - want_image_level: True -> return length B. False -> return length N\n",
    "        \"\"\"\n",
    "        if tabular_tensor is None:\n",
    "            raw = torch.zeros(N, dtype=torch.long, device=device)\n",
    "        else:\n",
    "            try:\n",
    "                tab = tabular_tensor\n",
    "                if not torch.is_tensor(tab):\n",
    "                    tab = torch.tensor(np.asarray(tab), device=device)\n",
    "                else:\n",
    "                    tab = tab.to(device)\n",
    "                D = tab.size(1)\n",
    "                if D >= (TARGET_ONEHOT_START + NUM_TARGET_ONEHOT):\n",
    "                    raw = torch.argmax(tab[:, TARGET_ONEHOT_START: TARGET_ONEHOT_START + NUM_TARGET_ONEHOT].float(), dim=-1).long().to(device)\n",
    "                else:\n",
    "                    logger.debug(f\"Tabular width {D} < required {TARGET_ONEHOT_START + NUM_TARGET_ONEHOT} for one-hot; using zeros for raw target idx\")\n",
    "                    raw = torch.zeros(tab.size(0), dtype=torch.long, device=device)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse tabular for target_idx: {e}\")\n",
    "                raw = torch.zeros(N, dtype=torch.long, device=device)\n",
    "\n",
    "        # Now unify length/shape\n",
    "        cnt = raw.numel()\n",
    "        if want_image_level:\n",
    "            # target_idx length should be B\n",
    "            if cnt == N:\n",
    "                # assume patch-level -> take first patch per image\n",
    "                try:\n",
    "                    return raw.view(B, P)[:, 0].long().to(device)\n",
    "                except Exception:\n",
    "                    # fallback: trunc/pad\n",
    "                    return raw[:B].long().to(device) if cnt >= B else raw.repeat((B // max(1, cnt)) + 1)[:B].long().to(device)\n",
    "            elif cnt == B:\n",
    "                return raw.long().to(device)\n",
    "            else:\n",
    "                if cnt > B:\n",
    "                    return raw[:B].long().to(device)\n",
    "                if cnt == 0:\n",
    "                    return torch.zeros(B, dtype=torch.long, device=device)\n",
    "                return raw.repeat((B // cnt) + 1)[:B].long().to(device)\n",
    "        else:\n",
    "            # want patch-level N\n",
    "            if cnt == N:\n",
    "                return raw.long().to(device)\n",
    "            elif cnt == B:\n",
    "                return raw.view(B, 1).repeat(1, P).view(-1).long().to(device)\n",
    "            else:\n",
    "                if cnt > N:\n",
    "                    return raw[:N].long().to(device)\n",
    "                if cnt == 0:\n",
    "                    return torch.zeros(N, dtype=torch.long, device=device)\n",
    "                return raw.repeat((N // cnt) + 1)[:N].long().to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_targets = []\n",
    "        train_target_names = []\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [TRAIN]\") as pbar:\n",
    "            for batch_idx, batch_data in enumerate(pbar):\n",
    "                # Unpack batch\n",
    "                try:\n",
    "                    if len(batch_data) == 7:\n",
    "                        images, tabular, species_batch, target_idx_batch, targets_per_patch, sample_ids, target_names = batch_data\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected batch length: {len(batch_data)}\")\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"Failed to unpack batch: {e}\")\n",
    "                    continue\n",
    "\n",
    "                if targets_per_patch is None:\n",
    "                    logger.debug(\"Skipping batch without targets.\")\n",
    "                    continue\n",
    "\n",
    "                # Move tensors to device when possible\n",
    "                try:\n",
    "                    images = images.to(device)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to move images to device: {e}\")\n",
    "\n",
    "                try:\n",
    "                    targets_per_patch = targets_per_patch.to(device).float()\n",
    "                except Exception:\n",
    "                    # allow numpy-like targets; coerce\n",
    "                    try:\n",
    "                        targets_per_patch = torch.tensor(np.asarray(targets_per_patch).ravel(), dtype=torch.float32, device=device)\n",
    "                    except Exception:\n",
    "                        logger.warning(\"Could not coerce targets_per_patch to tensor â€” skipping batch\")\n",
    "                        continue\n",
    "\n",
    "                try:\n",
    "                    tabular = tabular.to(device) if (tabular is not None and torch.is_tensor(tabular)) else tabular\n",
    "                except Exception:\n",
    "                    logger.debug(\"tabular could not be moved to device; will be handled in helper\")\n",
    "\n",
    "                # Determine sizes and safe-truncate\n",
    "                N = images.size(0)\n",
    "                P = patches_per_image\n",
    "                if N % P != 0:\n",
    "                    keep_sets = N // P\n",
    "                    if keep_sets == 0:\n",
    "                        logger.warning(f\"Batch too small: N={N}, P={P}. Skipping.\")\n",
    "                        continue\n",
    "                    keep_count = keep_sets * P\n",
    "                    images = images[:keep_count]\n",
    "                    targets_per_patch = targets_per_patch[:keep_count]\n",
    "                    if sample_ids is not None:\n",
    "                        try:\n",
    "                            sample_ids = sample_ids[:keep_count]\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    if target_names is not None:\n",
    "                        try:\n",
    "                            target_names = target_names[:keep_count]\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    N = images.size(0)\n",
    "\n",
    "                B = N // P\n",
    "\n",
    "                # Build target_idx robustly\n",
    "                try:\n",
    "                    target_idx = build_target_idx_from_tabular(tabular, N, B, P, want_image_level=use_mil, device=device)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to build target_idx: {e}\")\n",
    "                    # fallback to zeros of appropriate length\n",
    "                    target_idx = torch.zeros(B if use_mil else N, dtype=torch.long, device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                try:\n",
    "                    # Forward\n",
    "                    predictions = model(images, target_idx, return_features=False)\n",
    "                    # Determine expected length\n",
    "                    expected_len = B if use_mil else N\n",
    "                    pred_len = predictions.view(-1).numel()\n",
    "                    if pred_len != expected_len:\n",
    "                        logger.error(f\"Model returned unexpected length: {predictions.shape} (expected {expected_len}). Skipping batch {batch_idx}.\")\n",
    "                        continue\n",
    "\n",
    "                    # Build image-level targets when needed\n",
    "                    img_targets = _image_targets_from_patch_targets(targets_per_patch, B, P, device)\n",
    "                    if not isinstance(img_targets, torch.Tensor):\n",
    "                        img_targets = torch.from_numpy(img_targets).float().to(device)\n",
    "                    if use_mil:\n",
    "                        # predictions are image-level [B]\n",
    "                        loss_preds = predictions.view(-1)\n",
    "                        loss_targets = img_targets.view(-1)\n",
    "                    else:\n",
    "                        # predictions are patch-level [N]\n",
    "                        loss_preds = predictions.view(-1)\n",
    "                        loss_targets = targets_per_patch.view(-1)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"Forward pass failed: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Ensure same length\n",
    "                if loss_preds.shape[0] != loss_targets.shape[0]:\n",
    "                    logger.error(f\"Length mismatch preds {loss_preds.shape} vs targets {loss_targets.shape} â€” skipping batch\")\n",
    "                    continue\n",
    "\n",
    "                # Compute aligned target names for weighted loss\n",
    "                try:\n",
    "                    if use_mil:\n",
    "                        try:\n",
    "                            unique_target_names = get_unique_sample_id(target_names, patches_per_image=P)\n",
    "                            aligned_target_names = unique_target_names[:B]\n",
    "                        except Exception:\n",
    "                            aligned_target_names = _collapse_target_names_by_sample_ids(sample_ids or [], target_names or [], P)[:B]\n",
    "                    else:\n",
    "                        aligned_target_names = _align_target_names(sample_ids, target_names, pred_len=loss_targets.shape[0], B=B, P=P)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to align target names: {e}\")\n",
    "                    aligned_target_names = [\"None\"] * loss_targets.shape[0]\n",
    "\n",
    "                # Compute loss\n",
    "                try:\n",
    "                    loss = weighted_r2_loss(loss_preds, loss_targets, aligned_target_names, device)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Loss computation failed: {e}\")\n",
    "                    continue\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG.get('gradient_clip', 5.0))\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += float(loss.item())\n",
    "                train_preds.append(loss_preds.detach().cpu().numpy().ravel())\n",
    "                train_targets.append(loss_targets.detach().cpu().numpy().ravel())\n",
    "\n",
    "                # store aligned names (replicate/trim to match numeric length)\n",
    "                try:\n",
    "                    if use_mil:\n",
    "                        names_to_extend = aligned_target_names if isinstance(aligned_target_names, (list, tuple, np.ndarray)) else [aligned_target_names]\n",
    "                    else:\n",
    "                        names_to_extend = _align_target_names(sample_ids, target_names, pred_len=loss_targets.shape[0], B=B, P=P)\n",
    "                except Exception:\n",
    "                    names_to_extend = (target_names[:len(loss_targets)]\n",
    "                                       if (isinstance(target_names, (list, tuple, np.ndarray)) and len(target_names) >= len(loss_targets))\n",
    "                                       else [\"None\"] * len(loss_targets))\n",
    "\n",
    "                numeric_len = train_preds[-1].shape[0]\n",
    "                if len(names_to_extend) != numeric_len:\n",
    "                    names_to_extend = (list(names_to_extend) * ((numeric_len // max(1, len(names_to_extend))) + 1))[:numeric_len]\n",
    "\n",
    "                train_target_names.extend(names_to_extend)\n",
    "\n",
    "                pbar.set_postfix({'loss': float(loss.item())})\n",
    "\n",
    "        # Scheduler step at epoch end\n",
    "        try:\n",
    "            scheduler.step()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # ===== VALIDATION =====\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        val_target_names = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [VAL]\") as pbar:\n",
    "                for batch_idx, batch_data in enumerate(pbar):\n",
    "                    try:\n",
    "                        if len(batch_data) == 7:\n",
    "                            images, tabular, species_batch, target_idx_batch, targets_per_patch, sample_ids, target_names = batch_data\n",
    "                        else:\n",
    "                            raise ValueError(f\"Unexpected batch length: {len(batch_data)}\")\n",
    "                    except Exception as e:\n",
    "                        logger.exception(f\"Failed to unpack batch: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    if targets_per_patch is None:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        images = images.to(device)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        targets_per_patch = targets_per_patch.to(device).float()\n",
    "                    except Exception:\n",
    "                        try:\n",
    "                            targets_per_patch = torch.tensor(np.asarray(targets_per_patch).ravel(), dtype=torch.float32, device=device)\n",
    "                        except Exception:\n",
    "                            logger.warning(\"Could not coerce val targets_per_patch to tensor; skipping\")\n",
    "                            continue\n",
    "\n",
    "                    N = images.size(0)\n",
    "                    P = patches_per_image\n",
    "                    if N % P != 0:\n",
    "                        keep_sets = N // P\n",
    "                        if keep_sets == 0:\n",
    "                            continue\n",
    "                        keep_count = keep_sets * P\n",
    "                        images = images[:keep_count]\n",
    "                        targets_per_patch = targets_per_patch[:keep_count]\n",
    "                        if sample_ids is not None:\n",
    "                            try:\n",
    "                                sample_ids = sample_ids[:keep_count]\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        if target_names is not None:\n",
    "                            try:\n",
    "                                target_names = target_names[:keep_count]\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        N = images.size(0)\n",
    "\n",
    "                    B = N // P\n",
    "\n",
    "                    # build target_idx\n",
    "                    try:\n",
    "                        target_idx = build_target_idx_from_tabular(tabular, N, B, P, want_image_level=use_mil, device=device)\n",
    "                    except Exception:\n",
    "                        target_idx = torch.zeros(B if use_mil else N, dtype=torch.long, device=device)\n",
    "\n",
    "                    try:\n",
    "                        predictions = model(images, target_idx, return_features=False)\n",
    "                        expected_len = B if use_mil else N\n",
    "                        if predictions.view(-1).numel() != expected_len:\n",
    "                            logger.error(f\"Val model returned unexpected length: {predictions.shape} (expected {expected_len}). Skipping val batch {batch_idx}.\")\n",
    "                            continue\n",
    "\n",
    "                        img_targets = _image_targets_from_patch_targets(targets_per_patch, B, P, device)\n",
    "                        if not isinstance(img_targets, torch.Tensor):\n",
    "                            img_targets = torch.from_numpy(img_targets).float().to(device)\n",
    "\n",
    "                        if use_mil:\n",
    "                            loss_preds = predictions.view(-1)\n",
    "                            loss_targets = img_targets.view(-1)\n",
    "                        else:\n",
    "                            loss_preds = predictions.view(-1)\n",
    "                            loss_targets = targets_per_patch.view(-1)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logger.exception(f\"Val forward pass failed: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    if loss_preds.shape[0] != loss_targets.shape[0]:\n",
    "                        logger.error(f\"Val length mismatch preds {loss_preds.shape} vs targets {loss_targets.shape} â€” skipping\")\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        if use_mil:\n",
    "                            try:\n",
    "                                unique_target_names = get_unique_sample_id(target_names, patches_per_image=P)\n",
    "                                aligned_target_names = unique_target_names[:B]\n",
    "                            except Exception:\n",
    "                                aligned_target_names = _collapse_target_names_by_sample_ids(sample_ids or [], target_names or [], P)[:B]\n",
    "                        else:\n",
    "                            aligned_target_names = _align_target_names(sample_ids, target_names, pred_len=loss_targets.shape[0], B=B, P=P)\n",
    "                        loss = weighted_r2_loss(loss_preds, loss_targets, aligned_target_names, device)\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Val loss computation failed: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    val_loss += float(loss.item())\n",
    "                    val_preds.append(loss_preds.cpu().numpy().ravel())\n",
    "                    val_targets.append(loss_targets.cpu().numpy().ravel())\n",
    "\n",
    "                    # store aligned names for validation\n",
    "                    try:\n",
    "                        if use_mil:\n",
    "                            names_to_extend = aligned_target_names if isinstance(aligned_target_names, (list, tuple, np.ndarray)) else [aligned_target_names]\n",
    "                        else:\n",
    "                            names_to_extend = _align_target_names(sample_ids, target_names, pred_len=loss_targets.shape[0], B=B, P=P)\n",
    "                    except Exception:\n",
    "                        names_to_extend = (target_names[:len(loss_targets)]\n",
    "                                           if (isinstance(target_names, (list, tuple, np.ndarray)) and len(target_names) >= len(loss_targets))\n",
    "                                           else [\"None\"] * len(loss_targets))\n",
    "\n",
    "                    numeric_len = val_preds[-1].shape[0]\n",
    "                    if len(names_to_extend) != numeric_len:\n",
    "                        names_to_extend = (list(names_to_extend) * ((numeric_len // max(1, len(names_to_extend))) + 1))[:numeric_len]\n",
    "\n",
    "                    val_target_names.extend(names_to_extend)\n",
    "\n",
    "                    pbar.set_postfix({'loss': float(loss.item())})\n",
    "\n",
    "        # Metrics\n",
    "        train_preds_cat = np.concatenate(train_preds) if train_preds else np.array([])\n",
    "        train_targets_cat = np.concatenate(train_targets) if train_targets else np.array([])\n",
    "        val_preds_cat = np.concatenate(val_preds) if val_preds else np.array([])\n",
    "        val_targets_cat = np.concatenate(val_targets) if val_targets else np.array([])\n",
    "\n",
    "        train_r2 = compute_weighted_r2_metric(train_preds_cat, train_targets_cat, train_target_names) if len(train_preds) > 0 else 0.0\n",
    "        val_r2 = compute_weighted_r2_metric(val_preds_cat, val_targets_cat, val_target_names) if len(val_preds) > 0 else 0.0\n",
    "\n",
    "        avg_train_loss = train_loss / max(1, len(train_loader))\n",
    "        avg_val_loss = val_loss / max(1, len(val_loader))\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_r2'].append(train_r2)\n",
    "        history['val_r2'].append(val_r2)\n",
    "\n",
    "        logger.info(\n",
    "            f\"Epoch {epoch+1}/{num_epochs} â†’ \"\n",
    "            f\"Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f} | \"\n",
    "            f\"Train RÂ²={train_r2:.4f}, Val RÂ²={val_r2:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Save best\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            patience_counter = 0\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_path = MODELS_DIR / f\"{model_name}_best.pth\"\n",
    "            try:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                logger.info(f\"âœ“ Saved best {model_name} model\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to save model: {e}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG.get('early_stopping_patience', 10):\n",
    "                logger.info(f\"âœ“ Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    logger.info(f\"\\nâœ“ {model_name} training finished in {elapsed/60:.2f} minutes\")\n",
    "    logger.info(f\"Best Val Loss = {best_val_loss:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def train_xgboost_model(train_split_df, val_split_df, lookups_dict):\n",
    "    \"\"\"\n",
    "    Train XGBoost on image-level tabular features.\n",
    "    \n",
    "    Args:\n",
    "        train_split_df: Training dataframe\n",
    "        val_split_df: Validation dataframe\n",
    "        lookups_dict: Dictionary with STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(\"TRAINING XGBOOST (TABULAR - IMAGE LEVEL)\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #  Get from lookups_dict\n",
    "    STATE_COLS = lookups_dict['STATE_COLS']\n",
    "    SPECIES_COLS = lookups_dict['SPECIES_COLS']\n",
    "    TARGET_TYPE_COLS = lookups_dict['TARGET_TYPE_COLS']\n",
    "    \n",
    "    xgb_feature_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'Month', 'DayOfYear', 'Quarter']\n",
    "    xgb_feature_cols += STATE_COLS + SPECIES_COLS + TARGET_TYPE_COLS\n",
    "    xgb_feature_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'Month', 'DayOfYear', 'Quarter']\n",
    "    xgb_feature_cols += STATE_COLS + SPECIES_COLS\n",
    "    \n",
    "    xgb_feature_cols += TARGET_TYPE_COLS  # 1st copy\n",
    "    xgb_feature_cols += TARGET_TYPE_COLS  # 2nd copy\n",
    "    xgb_feature_cols += TARGET_TYPE_COLS  # 3rd copy\n",
    "\n",
    "    \n",
    "    # Safeguard: ensure required columns exist\n",
    "    missing_cols = [c for c in xgb_feature_cols if c not in train_split_df.columns]\n",
    "    if missing_cols:\n",
    "        logger.error(f\"âœ— Missing columns for XGBoost training: {missing_cols}\")\n",
    "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "    \n",
    "    X = train_split_df[xgb_feature_cols].values\n",
    "    y = train_split_df['target'].values\n",
    "    target_names = train_split_df['target_name'].values\n",
    "    \n",
    "    # Sanity check shapes\n",
    "    assert X.shape[0] == y.shape[0] == target_names.shape[0], (\n",
    "        \"Training lengths mismatch: X={}, y={}, target_names={}\".format(X.shape[0], len(y), len(target_names))\n",
    "    )\n",
    "\n",
    "    X = X.astype(np.float64)\n",
    "    y = y.astype(np.float64)\n",
    "\n",
    "    logger.info(f\"XGBoost training samples: {len(X)} (image level)\")\n",
    "    logger.info(f\"XGBoost features: {len(xgb_feature_cols)} ({', '.join(xgb_feature_cols[:3])}...)\")\n",
    "    \n",
    "\n",
    "    # Tabular-noise augmentation\n",
    "    # Use same style as meta-learner augmentation: multiplicative / scaled Gaussian noise.\n",
    "    noise_scale = CONFIG.get('xgb_noise_scale', 0.05)  # default 5% if not set\n",
    "    n_augment_rounds = int(CONFIG.get('xgb_augment_rounds', 1))  # how many augmented copies to create\n",
    "    \n",
    "    if n_augment_rounds > 0 and noise_scale > 0:\n",
    "        logger.info(f\"âœ“ Applying tabular noise augmentation to XGBoost training: rounds={n_augment_rounds}, noise_scale={noise_scale}\")\n",
    "        # create augmented copies and concatenate\n",
    "        X_aug_list = [X]\n",
    "        y_aug_list = [y]\n",
    "        target_names_aug_list = [target_names]\n",
    "        rng = np.random.RandomState(CONFIG.get('random_seed', 42))\n",
    "        \n",
    "        for r in range(n_augment_rounds):\n",
    "            base_scale = noise_scale\n",
    "            # Create noise shaped like X\n",
    "            # We scale noise per-element by max(1.0, abs(X)) to allow both absolute and relative perturbation\n",
    "            noise = rng.normal(loc=0.0, scale=base_scale * np.maximum(1.0, np.abs(X)), size=X.shape)\n",
    "            X_noisy = X + noise\n",
    "            # For one-hot columns (state/species/target-type) it's better to clip to [0,1]\n",
    "            # identify one-hot offsets:\n",
    "            numeric_dim = 5\n",
    "            state_dim = len(STATE_COLS)\n",
    "            species_dim = len(SPECIES_COLS)\n",
    "            target_dim = len(TARGET_TYPE_COLS)\n",
    "            # clip one-hot ranges to [0,1] for those columns\n",
    "            start_state = numeric_dim\n",
    "            end_state = start_state + state_dim\n",
    "            start_species = end_state\n",
    "            end_species = start_species + species_dim\n",
    "            start_target = end_species\n",
    "            end_target = start_target + target_dim\n",
    "            if state_dim > 0:\n",
    "                X_noisy[:, start_state:end_state] = np.clip(X_noisy[:, start_state:end_state], 0.0, 1.0)\n",
    "            if species_dim > 0:\n",
    "                X_noisy[:, start_species:end_species] = np.clip(X_noisy[:, start_species:end_species], 0.0, 1.0)\n",
    "            if target_dim > 0:\n",
    "                X_noisy[:, start_target:end_target] = np.clip(X_noisy[:, start_target:end_target], 0.0, 1.0)\n",
    "            \n",
    "            X_aug_list.append(X_noisy)\n",
    "            y_aug_list.append(y.copy())\n",
    "            target_names_aug_list.append(target_names.copy())\n",
    "        \n",
    "        # Concatenate original + augmented\n",
    "        X_train_final = np.vstack(X_aug_list)\n",
    "        y_train_final = np.concatenate(y_aug_list)\n",
    "        target_names_final = np.concatenate(target_names_aug_list)\n",
    "        \n",
    "        logger.info(f\"  Augmented training size: {X_train_final.shape[0]} (original {X.shape[0]})\")\n",
    "    else:\n",
    "        X_train_final = X\n",
    "        y_train_final = y\n",
    "        target_names_final = target_names\n",
    "\n",
    "\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 1000),\n",
    "        'max_depth': randint(3, 12),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.6, 1.0),\n",
    "        'colsample_bytree': uniform(0.6, 1.0),\n",
    "        'min_child_weight': randint(1, 10),\n",
    "        'gamma': uniform(0, 5),\n",
    "        'reg_alpha': uniform(0, 1),      \n",
    "        'reg_lambda': uniform(0, 1),\n",
    "    }\n",
    "    \n",
    "    # Initialize model\n",
    "    xgb_base = xgb.XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        xgb_base,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logger.info(f\"  Running RandomizedSearchCV with n_iter=50, cv=5...\")\n",
    "\n",
    "    with tqdm(total=20, desc=\"ðŸ” XGBoost Hyperparameter Search\", unit=\"trial\") as pbar:\n",
    "        search.fit(X_train_final, y_train_final)\n",
    "        pbar.update(2)\n",
    "\n",
    "\n",
    "    logger.info(f\"âœ“ Best CV score: {search.best_score_:.4f}\")\n",
    "    logger.info(f\"âœ“ Best parameters:\")\n",
    "    \n",
    "    # ===== UPDATE CONFIG WITH BEST PARAMETERS =====\n",
    "    CONFIG['xgb_n_estimators'] = int(search.best_params_['n_estimators'])\n",
    "    CONFIG['xgb_max_depth'] = int(search.best_params_['max_depth'])\n",
    "    CONFIG['xgb_learning_rate'] = float(search.best_params_['learning_rate'])\n",
    "    CONFIG['xgb_subsample'] = float(search.best_params_['subsample'])\n",
    "    CONFIG['xgb_colsample_bytree'] = float(search.best_params_['colsample_bytree'])\n",
    "\n",
    "    xgb_model = XGBoostTabularModel(lookups_dict)\n",
    "    xgb_model.fit(X_train_final, y_train_final, target_names_final)\n",
    "    logger.info(\"âœ“ XGBoost training complete\")\n",
    "    \n",
    "    # Validation\n",
    "    X_val = val_split_df[xgb_feature_cols].values\n",
    "    y_val = val_split_df['target'].values\n",
    "    target_names_val = val_split_df['target_name'].values\n",
    "\n",
    "    X_val = X_val.astype(np.float64)\n",
    "    y_val = y_val.astype(np.float64)\n",
    "\n",
    "    \n",
    "    # Sanity check\n",
    "    assert X_val.shape[0] == y_val.shape[0] == target_names_val.shape[0], (\n",
    "        \"Validation lengths mismatch: X_val={}, y_val={}, target_names_val={}\".format(X_val.shape[0], len(y_val), len(target_names_val))\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"XGBoost validation samples: {len(X_val)} (image level)\")\n",
    "    \n",
    "    val_preds_all = np.zeros(len(y_val), dtype=np.float32)\n",
    "    \n",
    "    # Make predictions for each target type \n",
    "    for target_type in np.unique(target_names_val):\n",
    "        mask = target_names_val == target_type\n",
    "        X_target = X_val[mask]\n",
    "        try:\n",
    "            pred = xgb_model.predict(X_target, target_type)\n",
    "            val_preds_all[mask] = pred\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"XGBoost predict failed for target {target_type}: {e}\")\n",
    "            # fallback: use mean of train target for that target_type\n",
    "            fallback = train_split_df[train_split_df['target_name'] == target_type]['target'].mean()\n",
    "            logger.warning(f\"Using fallback mean {fallback:.4f} for {target_type}\")\n",
    "            val_preds_all[mask] = fallback\n",
    "    \n",
    "    # Now compute RÂ² with MATCHING order\n",
    "    val_r2 = compute_weighted_r2_metric(\n",
    "        val_preds_all,     \n",
    "        y_val,              \n",
    "        target_names_val   \n",
    "    )\n",
    "    logger.info(f\"XGBoost Validation RÂ²: {val_r2:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    xgb_model.save(MODELS_DIR / 'xgboost_best.pkl')\n",
    "    logger.info(f\"âœ“ XGBoost model saved\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info(f\"âœ“ XGBoost training completed in {elapsed_time/60:.2f} minutes\\n\")\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "def train_meta_learner_model(\n",
    "    base_model_preds_train, base_model_preds_val,\n",
    "    num_epochs,\n",
    "    device=device,\n",
    "    pretrained_model=None,\n",
    "    optimize_hparams=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Train meta-learner on pre-computed base model predictions.\n",
    "    \n",
    "    UPDATED: Now uses target_idx (from TaskEmbedding) instead of tabular features.\n",
    "    \n",
    "    Args:\n",
    "        base_model_preds_train: Dict with training predictions (vit, resnet, densenet, xgboost, ensemble)\n",
    "        base_model_preds_val: Dict with validation predictions\n",
    "        num_epochs: Number of epochs\n",
    "        device: torch device\n",
    "        pretrained_model: Optional pretrained meta-learner\n",
    "        optimize_hparams: Whether to run hyperparameter search\n",
    "    \n",
    "    Returns:\n",
    "        Trained meta-learner model\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\\\n{'='*80}\")\n",
    "    logger.info(\"TRAINING META-LEARNER (IMAGE LEVEL ENSEMBLE + TASK EMBEDDING)\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "     \n",
    "    required_keys = ['vit', 'resnet', 'densenet', 'xgboost', 'ensemble', 'tabular', 'targets', 'target_names', 'target_idx']\n",
    "    for k in required_keys:\n",
    "        if k not in base_model_preds_train or k not in base_model_preds_val:\n",
    "            logger.error(f\"Missing key '{k}' in base_model_preds_train or base_model_preds_val\")\n",
    "            raise KeyError(k)\n",
    "    \n",
    "    n_samples_train = len(base_model_preds_train['targets'])\n",
    "    n_samples_val = len(base_model_preds_val['targets'])\n",
    "    \n",
    "    logger.info(f\"Training samples: {n_samples_train} (image level)\")\n",
    "    logger.info(f\"Validation samples: {n_samples_val} (image level)\")\n",
    "    logger.info(f\"Meta-learner input: 5 base predictions + 64D task embedding = 69 dims\")\n",
    "    \n",
    "    # Normalize device\n",
    "    try:\n",
    "        device = device if isinstance(device, torch.device) else torch.device(\n",
    "            device if device is not None else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "    except Exception:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    logger.info(f\"Meta-learner training device: {device}\")\n",
    "    \n",
    "    # âœ… NEW: HYPERPARAMETER OPTIMIZATION\n",
    "    if optimize_hparams:\n",
    "        logger.info(f\"\\\\nðŸ” Starting Meta-Learner hyperparameter optimization...\")\n",
    "        \n",
    "        param_grid = {\n",
    "            'lr': [1e-4, 5e-4, 1e-3],\n",
    "            'weight_decay': [1e-5, 1e-4],\n",
    "            'dropout': [0.05, 0.1, 0.15],\n",
    "        }\n",
    "        \n",
    "        best_meta_score = float('-inf')\n",
    "        best_meta_params = None\n",
    "        total_combinations = len(param_grid['lr']) * len(param_grid['weight_decay']) * len(param_grid['dropout'])\n",
    "        \n",
    "        with tqdm(total=total_combinations, desc=\"ðŸ” Meta-Learner Hyperparameter Search\", unit=\"config\") as pbar:\n",
    "            for lr in param_grid['lr']:\n",
    "                for wd in param_grid['weight_decay']:\n",
    "                    for dropout in param_grid['dropout']:\n",
    "                        trial_params = {\n",
    "                            'learning_rate': lr,\n",
    "                            'weight_decay': wd,\n",
    "                            'dropout': dropout,\n",
    "                        }\n",
    "                        \n",
    "                        logger.debug(f\"\\\\n  Trial: lr={lr:.0e}, wd={wd:.0e}, dropout={dropout:.2f}\")\n",
    "                        \n",
    "                        try:\n",
    "                            # Create trial model with TaskEmbedding\n",
    "                            trial_model = MetaLearnerModel(dropout_rate=dropout, pretrained=False).to(device)\n",
    "                            trial_model.train()\n",
    "                            \n",
    "                            trial_optimizer = torch.optim.AdamW(\n",
    "                                trial_model.parameters(),\n",
    "                                lr=lr,\n",
    "                                weight_decay=wd\n",
    "                            )\n",
    "                            \n",
    "                            trial_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                                trial_optimizer, T_0=5, T_mult=2\n",
    "                            )\n",
    "                            \n",
    "                            batch_size = CONFIG['batch_size']\n",
    "                            best_trial_val_r2 = float('-inf')\n",
    "                            patience = 5\n",
    "                            patience_counter = 0\n",
    "                            search_epochs = min(20, num_epochs)\n",
    "                            \n",
    "                            for search_epoch in range(search_epochs):\n",
    "                                trial_model.train()\n",
    "                                train_loss = 0.0\n",
    "                                \n",
    "                                indices = np.random.permutation(n_samples_train)\n",
    "                                \n",
    "                                for i in range(0, n_samples_train, batch_size):\n",
    "                                    end_idx = min(i + batch_size, n_samples_train)\n",
    "                                    batch_indices = indices[i:end_idx]\n",
    "                                    \n",
    "                                    # Build batch predictions (5 base models)\n",
    "                                    base_preds = np.column_stack([\n",
    "                                        base_model_preds_train['vit'][batch_indices],\n",
    "                                        base_model_preds_train['resnet'][batch_indices],\n",
    "                                        base_model_preds_train['densenet'][batch_indices],\n",
    "                                        base_model_preds_train['xgboost'][batch_indices],\n",
    "                                        base_model_preds_train['ensemble'][batch_indices],\n",
    "                                    ])\n",
    "                                    \n",
    "                                    target_idx = torch.tensor(\n",
    "                                        base_model_preds_train['target_idx'][batch_indices],\n",
    "                                        dtype=torch.long).to(device)\n",
    "\n",
    "                                    base_preds = torch.tensor(base_preds, dtype=torch.float32).to(device)\n",
    "                                    targets = torch.tensor(\n",
    "                                        base_model_preds_train['targets'][batch_indices],\n",
    "                                        dtype=torch.float32\n",
    "                                    ).to(device)\n",
    "                                    target_names_batch = np.array(base_model_preds_train['target_names'])[batch_indices]\n",
    "                                    \n",
    "                                    # âœ… NEW: Pass target_idx instead of tabular\n",
    "                                    predictions = trial_model(base_preds, target_idx)\n",
    "                                    loss = weighted_r2_loss(predictions, targets, target_names_batch, device)\n",
    "                                    \n",
    "                                    trial_optimizer.zero_grad()\n",
    "                                    loss.backward()\n",
    "                                    torch.nn.utils.clip_grad_norm_(trial_model.parameters(), CONFIG['gradient_clip'])\n",
    "                                    trial_optimizer.step()\n",
    "                                    \n",
    "                                    train_loss += float(loss.item())\n",
    "                                \n",
    "                                trial_scheduler.step()\n",
    "                                \n",
    "                                # Validate\n",
    "                                trial_model.eval()\n",
    "                                val_preds_all = []\n",
    "                                val_targets_all = []\n",
    "                                val_names_all = []\n",
    "                                \n",
    "                                with torch.no_grad():\n",
    "                                    for i in range(0, n_samples_val, batch_size):\n",
    "                                        end_idx = min(i + batch_size, n_samples_val)\n",
    "                                        batch_indices = np.arange(i, end_idx)\n",
    "                                        \n",
    "                                        base_preds_val = np.column_stack([\n",
    "                                            base_model_preds_val['vit'][batch_indices],\n",
    "                                            base_model_preds_val['resnet'][batch_indices],\n",
    "                                            base_model_preds_val['densenet'][batch_indices],\n",
    "                                            base_model_preds_val['xgboost'][batch_indices],\n",
    "                                            base_model_preds_val['ensemble'][batch_indices],\n",
    "                                        ])\n",
    "                                        target_idx_val = torch.tensor(\n",
    "                                            base_model_preds_val['target_idx'][batch_indices],\n",
    "                                            dtype=torch.long\n",
    "                                        ).to(device)\n",
    "\n",
    "                                        base_preds_val = torch.tensor(base_preds_val, dtype=torch.float32).to(device)\n",
    "                                        targets_val = torch.tensor(\n",
    "                                            base_model_preds_val['targets'][batch_indices],\n",
    "                                            dtype=torch.float32\n",
    "                                        ).to(device)\n",
    "                                        target_names_val_batch = np.array(base_model_preds_val['target_names'])[batch_indices]\n",
    "                                        \n",
    "                                        # âœ… NEW: Pass target_idx instead of tabular\n",
    "                                        predictions = trial_model(base_preds_val, target_idx_val)\n",
    "                                        val_preds_all.append(predictions.cpu().numpy())\n",
    "                                        val_targets_all.append(targets_val.cpu().numpy())\n",
    "                                        val_names_all.append(target_names_val_batch)\n",
    "                                \n",
    "                                if not val_preds_all:\n",
    "                                    logger.warning(\"No validation predictions collected during hyperopt trial\")\n",
    "                                    trial_val_r2 = float('-inf')\n",
    "                                else:\n",
    "                                    val_preds = np.concatenate(val_preds_all)\n",
    "                                    val_targets = np.concatenate(val_targets_all)\n",
    "                                    val_names = np.concatenate(val_names_all)\n",
    "                                    trial_val_r2 = compute_weighted_r2_metric(val_preds, val_targets, val_names)\n",
    "                                \n",
    "                                if trial_val_r2 > best_trial_val_r2:\n",
    "                                    best_trial_val_r2 = trial_val_r2\n",
    "                                    patience_counter = 0\n",
    "                                else:\n",
    "                                    patience_counter += 1\n",
    "                                    if patience_counter >= patience:\n",
    "                                        break\n",
    "                            \n",
    "                            logger.info(f\"    â†’ Best validation RÂ²: {best_trial_val_r2:.4f}\")\n",
    "                            \n",
    "                            if best_trial_val_r2 > best_meta_score:\n",
    "                                best_meta_score = best_trial_val_r2\n",
    "                                best_meta_params = trial_params\n",
    "                                logger.info(f\"    âœ“ NEW BEST!\")\n",
    "                            \n",
    "                            del trial_model, trial_optimizer, trial_scheduler\n",
    "                            try:\n",
    "                                torch.cuda.empty_cache()\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                            gc.collect()\n",
    "                        \n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"    âœ— Trial failed: {e}\")\n",
    "                        \n",
    "                        pbar.update(1)\n",
    "        \n",
    "        logger.info(\"\\\\nâœ“ Meta-Learner optimization complete!\")\n",
    "        \n",
    "        if best_meta_params is None:\n",
    "            logger.warning(\"Meta-Learner hyperopt found no successful trials â€” using defaults.\")\n",
    "            best_meta_params = {\n",
    "                'learning_rate': CONFIG.get('metalearner_lr', 1e-4),\n",
    "                'weight_decay': CONFIG.get('meta_weight_decay', 1e-4),\n",
    "                'dropout': CONFIG.get('meta_dropout_rate', 0.1)\n",
    "            }\n",
    "        \n",
    "        logger.info(f\"âœ“ Best validation RÂ²: {best_meta_score:.4f}\")\n",
    "        logger.info(\"âœ“ Best parameters:\")\n",
    "        for param, value in best_meta_params.items():\n",
    "            logger.info(f\"  - {param}: {value}\")\n",
    "        \n",
    "        CONFIG['metalearner_lr'] = best_meta_params['learning_rate']\n",
    "        CONFIG['meta_weight_decay'] = best_meta_params['weight_decay']\n",
    "        CONFIG['meta_dropout_rate'] = best_meta_params['dropout']\n",
    "        logger.info(\"âœ“ CONFIG updated with best meta-learner parameters\")\n",
    "    \n",
    "    # Instantiate model\n",
    "    if pretrained_model is not None:\n",
    "        try:\n",
    "            model = pretrained_model.to(device)\n",
    "            logger.info(\"Using provided meta_learner instance for training.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load pretrained meta-learner: {e}; training from scratch\")\n",
    "            model = MetaLearnerModel(\n",
    "                dropout_rate=CONFIG.get('meta_dropout_rate', 0.1),\n",
    "                pretrained=False\n",
    "            ).to(device)\n",
    "    else:\n",
    "        model = MetaLearnerModel(\n",
    "            dropout_rate=CONFIG.get('meta_dropout_rate', 0.1),\n",
    "            pretrained=False\n",
    "        ).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['metalearner_lr'],\n",
    "        weight_decay=CONFIG.get('meta_weight_decay', 1e-4)\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "    batch_size = CONFIG['batch_size']\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        train_preds_all = []\n",
    "        train_targets_all = []\n",
    "        train_names_all = []\n",
    "        \n",
    "        indices = np.random.permutation(n_samples_train)\n",
    "        \n",
    "        for i in range(0, n_samples_train, batch_size):\n",
    "            end_idx = min(i + batch_size, n_samples_train)\n",
    "            batch_indices = indices[i:end_idx]\n",
    "            \n",
    "            # Build base predictions (5 base models)\n",
    "            base_preds = np.column_stack([\n",
    "                base_model_preds_train['vit'][batch_indices],\n",
    "                base_model_preds_train['resnet'][batch_indices],\n",
    "                base_model_preds_train['densenet'][batch_indices],\n",
    "                base_model_preds_train['xgboost'][batch_indices],\n",
    "                base_model_preds_train['ensemble'][batch_indices],\n",
    "            ])\n",
    "            target_idx = torch.tensor(\n",
    "                base_model_preds_train['target_idx'][batch_indices],\n",
    "                dtype=torch.long\n",
    "            ).to(device)\n",
    "\n",
    "            base_preds = torch.tensor(base_preds, dtype=torch.float32).to(device)\n",
    "            targets = torch.tensor(\n",
    "                base_model_preds_train['targets'][batch_indices],\n",
    "                dtype=torch.float32\n",
    "            ).to(device)\n",
    "            target_names_batch = np.array(base_model_preds_train['target_names'])[batch_indices]\n",
    "            \n",
    " \n",
    "            predictions = model(base_preds, target_idx)\n",
    "            loss = weighted_r2_loss(predictions, targets, target_names_batch, device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['gradient_clip'])\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += float(loss.item())\n",
    "            train_batches += 1\n",
    "            train_preds_all.append(predictions.detach().cpu().numpy())\n",
    "            train_targets_all.append(targets.cpu().numpy())\n",
    "            train_names_all.append(target_names_batch)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "        train_preds_concat = np.concatenate(train_preds_all) if train_preds_all else np.array([])\n",
    "        train_targets_concat = np.concatenate(train_targets_all) if train_targets_all else np.array([])\n",
    "        train_names_concat = np.concatenate(train_names_all) if train_names_all else np.array([])\n",
    "        \n",
    "        train_r2 = compute_weighted_r2_metric(\n",
    "            train_preds_concat, train_targets_concat, train_names_concat\n",
    "        ) if train_preds_concat.size else 0.0\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        val_preds_all = []\n",
    "        val_targets_all = []\n",
    "        val_names_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, n_samples_val, batch_size):\n",
    "                end_idx = min(i + batch_size, n_samples_val)\n",
    "                batch_indices = np.arange(i, end_idx)\n",
    "                \n",
    "                base_preds_val = np.column_stack([\n",
    "                    base_model_preds_val['vit'][batch_indices],\n",
    "                    base_model_preds_val['resnet'][batch_indices],\n",
    "                    base_model_preds_val['densenet'][batch_indices],\n",
    "                    base_model_preds_val['xgboost'][batch_indices],\n",
    "                    base_model_preds_val['ensemble'][batch_indices],\n",
    "                ])\n",
    "                \n",
    "                target_idx_val = torch.tensor(\n",
    "                    base_model_preds_val['target_idx'][batch_indices],\n",
    "                    dtype=torch.long\n",
    "                ).to(device)\n",
    "\n",
    "                base_preds_val = torch.tensor(base_preds_val, dtype=torch.float32).to(device)\n",
    "                targets_val = torch.tensor(\n",
    "                    base_model_preds_val['targets'][batch_indices],\n",
    "                    dtype=torch.float32\n",
    "                ).to(device)\n",
    "                target_names_val_batch = np.array(base_model_preds_val['target_names'])[batch_indices]\n",
    "                \n",
    "                predictions = model(base_preds_val, target_idx_val)\n",
    "                loss = weighted_r2_loss(predictions, targets_val, target_names_val_batch, device)\n",
    "                \n",
    "                val_loss += float(loss.item())\n",
    "                val_batches += 1\n",
    "                val_preds_all.append(predictions.cpu().numpy())\n",
    "                val_targets_all.append(targets_val.cpu().numpy())\n",
    "                val_names_all.append(target_names_val_batch)\n",
    "        \n",
    "        val_preds_concat = np.concatenate(val_preds_all) if val_preds_all else np.array([])\n",
    "        val_targets_concat = np.concatenate(val_targets_all) if val_targets_all else np.array([])\n",
    "        val_names_concat = np.concatenate(val_names_all) if val_names_all else np.array([])\n",
    "        \n",
    "        avg_train_loss = train_loss / max(1, train_batches)\n",
    "        avg_val_loss = val_loss / max(1, val_batches)\n",
    "        \n",
    "        val_r2 = compute_weighted_r2_metric(\n",
    "            val_preds_concat, val_targets_concat, val_names_concat\n",
    "        ) if val_preds_concat.size else 0.0\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                f\"Train RÂ²={train_r2:.4f}, Val RÂ²={val_r2:.4f} | \"\n",
    "                f\"Loss={avg_val_loss:.6f}\"\n",
    "            )\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            try:\n",
    "                torch.cuda.empty_cache()\n",
    "            except Exception:\n",
    "                pass\n",
    "            gc.collect()\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            torch.save(model.state_dict(), MODELS_DIR / 'metalearner_best.pth')\n",
    "            logger.info(f\"  âœ“ Best meta-learner saved (Val RÂ²={val_r2:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG['early_stopping_patience']:\n",
    "                logger.info(f\"âœ“ Early stopping at Epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "\n",
    "    best_path = MODELS_DIR / 'metalearner_best.pth'\n",
    "    if best_path.exists():\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load best meta-learner weights: {e}\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info(f\"âœ“ Meta-learner training completed in {elapsed_time/60:.2f} minutes\\\\n\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_species_model(train_loader, val_loader, train_df, num_epochs=50, device=device, model=None):\n",
    "    \"\"\"\n",
    "    Train SpeciesClassificationViT with optional MIL aggregation.\n",
    "    Returns the trained model (and saves best checkpoint as 'species_best.pth' in MODELS_DIR).\n",
    "    Notes:\n",
    "      - Supports models that return per-patch logits (B*P, C) or per-image logits (B, C).\n",
    "      - If CONFIG['use_mil'] is True but model returns per-patch logits, this function aggregates to image-level by mean.\n",
    "      - Robust device handling and shapes checks; skips problematic batches rather than crashing.\n",
    "    \"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TRAINING SPECIES CLASSIFICATION MODEL\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    if model is None:\n",
    "        raise ValueError(\"model must be provided\")\n",
    "    species_model = model\n",
    "    use_mil = CONFIG.get(\"use_mil\", False)\n",
    "    patches_per_image = getattr(species_model, \"num_patches\", None)\n",
    "    \n",
    "    if patches_per_image is None:\n",
    "        patches_per_image = CONFIG.get(\"num_patches\", 8)\n",
    "        logger.warning(f\"species_model.num_patches missing - falling back to CONFIG/assumed value {patches_per_image}\")\n",
    "\n",
    "    logger.info(f\"âœ“ use_mil_species = {use_mil}\")\n",
    "    logger.info(f\"âœ“ patches_per_image = {patches_per_image}\")\n",
    "\n",
    "    species_list = getattr(species_model, \"species_list\", None)\n",
    "    if species_list is None:\n",
    "        raise ValueError(\"species_model must expose species_list (ordered)\")\n",
    "\n",
    "    species_to_idx = {sp: i for i, sp in enumerate(species_list)}\n",
    "    num_classes = len(species_list)\n",
    "\n",
    "    optimizer = optim.AdamW(species_model.parameters(), lr=CONFIG.get(\"species_lr\", 2e-4), weight_decay=CONFIG.get(\"weight_decay\", 1e-2))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CONFIG.get(\"species_step\", 10), gamma=0.5)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    patience = CONFIG.get(\"early_stopping_patience\", 20)\n",
    "    start_time = time.time()\n",
    "\n",
    "    if \"image_id\" in train_df.columns and \"Species\" in train_df.columns:\n",
    "        image_to_species = train_df.set_index(\"image_id\")[\"Species\"].to_dict()\n",
    "    else:\n",
    "        image_to_species = {}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        species_model.train()\n",
    "        running_loss = 0.0\n",
    "        n_batches = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Species Train Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "            try:    \n",
    "                if len(batch) == 7:\n",
    "                    images, tabular, species_targets,target_idx_batch, targets_per_patch, sample_ids, target_names = batch\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Skipping train batch due to unexpected structure: {e}\")\n",
    "                continue\n",
    "            try:\n",
    "                images = images.to(device)\n",
    "            except Exception:\n",
    "                images = images.cuda() if torch.cuda.is_available() else images\n",
    "\n",
    "            # convert species_targets to indices if necessary\n",
    "            if not torch.is_tensor(species_targets):\n",
    "                try:\n",
    "                    species_targets = torch.tensor(species_targets, dtype=torch.long)\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        species_targets = torch.tensor([species_to_idx.get(str(s), 0) for s in species_targets], dtype=torch.long)\n",
    "                    except Exception:\n",
    "                        logger.warning(\"Could not coerce species_targets to tensor - skipping batch\")\n",
    "                        continue\n",
    "            species_targets = species_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if use_mil:\n",
    "                outputs = species_model(images, return_features=True)  \n",
    "            else:\n",
    "                outputs = species_model(images, return_features=False) \n",
    "            try:\n",
    "                if outputs.dim() == 1:\n",
    "                    logger.warning(\"Received 1D outputs from species model; skipping batch\")\n",
    "                    continue\n",
    "\n",
    "                if use_mil:\n",
    "                    N = outputs.size(0)\n",
    "                    C = outputs.size(-1)\n",
    "                    # if outputs are per-patch (N == B * P) and we have per-image targets (len==B), aggregate\n",
    "                    if species_targets.dim() == 1 and N % species_targets.size(0) == 0 and N // species_targets.size(0) == patches_per_image:\n",
    "                        B = species_targets.size(0)\n",
    "                        P = patches_per_image\n",
    "                        patches = outputs.view(B, P, C).contiguous()\n",
    "                        aggregated = species_model.mil_aggregator(patches) \n",
    "                        outputs_img = species_model.classification_head(aggregated)\n",
    "                        targets_img = species_targets.view(B)\n",
    "                    elif outputs.size(0) == species_targets.size(0):\n",
    "                        outputs_img = outputs\n",
    "                        targets_img = species_targets.view(-1)\n",
    "                    else:\n",
    "                        if N % patches_per_image == 0:\n",
    "                            B = N // patches_per_image\n",
    "                            try:\n",
    "                                outputs_img = outputs.view(B, patches_per_image, -1).mean(dim=1)\n",
    "                                if species_targets.size(0) == N:\n",
    "                                    targets_img = species_targets.view(B, patches_per_image)[:, 0]\n",
    "                                elif species_targets.size(0) == B:\n",
    "                                    targets_img = species_targets\n",
    "                                else:\n",
    "                                    logger.warning(\"Could not reconcile species target count with outputs under MIL; skipping batch\")\n",
    "                                    continue\n",
    "                            except Exception:\n",
    "                                logger.warning(\"Failed to reshape outputs for MIL aggregation; skipping batch\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            logger.warning(\"MIL enabled but cannot deduce B and P; skipping batch\")\n",
    "                            continue\n",
    "\n",
    "                    loss = criterion(outputs_img, targets_img.to(device))\n",
    "                else:\n",
    "                    if outputs.size(0) == species_targets.size(0):\n",
    "                        loss = criterion(outputs, species_targets.to(device))\n",
    "                    else:\n",
    "                        if outputs.size(0) == species_targets.size(0) // patches_per_image:\n",
    "                            B = outputs.size(0)\n",
    "                            P = patches_per_image\n",
    "                            expanded = outputs.view(B, 1, -1).repeat(1, P, 1).view(B * P, -1)\n",
    "                            loss = criterion(expanded, species_targets.to(device))\n",
    "                        else:\n",
    "                            logger.warning(\"Mismatch between outputs and species_targets in non-MIL mode; skipping batch\")\n",
    "                            continue\n",
    "\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(species_model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                running_loss += float(loss.item())\n",
    "                n_batches += 1\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Skipping problematic train batch: {e}\")\n",
    "                continue\n",
    "\n",
    "        avg_train_loss = (running_loss / max(1, n_batches)) if n_batches else float(\"inf\")\n",
    "\n",
    "        species_model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                try:    \n",
    "                    if len(batch) == 7:\n",
    "                        images, tabular, species_targets, target_idx_batch, targets_per_patch, sample_ids, target_names = batch\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Skipping train batch due to unexpected structure: {e}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    images = images.to(device)\n",
    "                    if not torch.is_tensor(species_targets):\n",
    "                        species_targets = torch.tensor([species_to_idx.get(str(s), 0) for s in species_targets], dtype=torch.long)\n",
    "                    species_targets = species_targets.to(device)\n",
    "                    if use_mil:\n",
    "                        outputs = species_model(images, return_features=True)\n",
    "                    else:\n",
    "                        outputs = species_model(images, return_features=False)\n",
    "                    if use_mil:\n",
    "                        N = outputs.size(0)\n",
    "                        if N % patches_per_image == 0 and species_targets.size(0) == N // patches_per_image:\n",
    "                            B = species_targets.size(0)\n",
    "                            C = outputs.size(-1)\n",
    "                            P = patches_per_image\n",
    "                            patches = outputs.view(B, P, C).contiguous()\n",
    "                            aggregated = species_model.mil_aggregator(patches)\n",
    "                            outputs_img = species_model.classification_head(aggregated)\n",
    "                            targets_img = species_targets.view(B)\n",
    "                            vloss = criterion(outputs_img, targets_img)\n",
    "                        elif outputs.size(0) == species_targets.size(0):\n",
    "                            vloss = criterion(outputs, species_targets)\n",
    "                        else:\n",
    "                            logger.warning(\"Validation MIL mismatch - trying best-effort reduction\")\n",
    "                            if outputs.dim() == 3:\n",
    "                                try:\n",
    "                                    outputs_img = outputs.mean(dim=1)\n",
    "                                    vloss = criterion(outputs_img, species_targets[:outputs_img.size(0)])\n",
    "                                except Exception:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                    else:\n",
    "                        if outputs.size(0) == species_targets.size(0):\n",
    "                            vloss = criterion(outputs, species_targets)\n",
    "                        else:\n",
    "                            if outputs.size(0) == (species_targets.size(0) // patches_per_image):\n",
    "                                B = outputs.size(0)\n",
    "                                P = patches_per_image \n",
    "                                expanded = outputs.view(B, 1, -1).repeat(1, patches_per_image, 1).view(B * patches_per_image, -1)\n",
    "                                vloss = criterion(expanded, species_targets)\n",
    "                            else:\n",
    "                                logger.warning(\"Validation non-MIL mismatch; skipping batch\")\n",
    "                                continue\n",
    "\n",
    "                    val_loss += float(vloss.item())\n",
    "                    val_batches += 1\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        avg_val_loss = (val_loss / max(1, val_batches)) if val_batches else float(\"inf\")\n",
    "        if scheduler is not None:\n",
    "            try:\n",
    "                scheduler.step()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        logger.info(f\"Epoch {epoch+1}/{num_epochs} | Train Loss={avg_train_loss:.6f} | Val Loss={avg_val_loss:.6f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            try:\n",
    "                torch.save(species_model.state_dict(), MODELS_DIR / 'species_best.pth')\n",
    "                logger.info(f\"  âœ“ Best species model saved (Val Loss={best_val_loss:.6f})\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to save species_best.pth: {e}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                logger.info(f\"âœ“ Early stopping at Epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info(f\"âœ“ Species training completed in {elapsed_time/60:.2f} minutes\")\n",
    "\n",
    "    best_path = MODELS_DIR / 'species_best.pth'\n",
    "    if best_path.exists():\n",
    "        try:\n",
    "            species_model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not strictly load best species weights: {e}\")\n",
    "\n",
    "    return species_model\n",
    "\n",
    "\n",
    "logger.info(\"âœ“ Training Functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc757d",
   "metadata": {},
   "source": [
    "## 8: ENSEMBLE TRAINING - COLLECT BASE PREDICTIONS\n",
    "\n",
    "**Purpose**: Generate predictions on test set using all 5 models and meta-learner.\n",
    "\n",
    "### Test Prediction Pipeline\n",
    "\n",
    "**For each test sample**:\n",
    "\n",
    "**Step 1: Image Loading**\n",
    "```\n",
    "Load  image (2000Ã—1000)\n",
    "â†“\n",
    "Check if file exists (missing = black image)\n",
    "â†“\n",
    "Convert BGR (OpenCV) â†’ RGB\n",
    "â†“\n",
    "Prepare PIL Image\n",
    "```\n",
    "\n",
    "**Step 2: Patch Extraction**\n",
    "```\n",
    "Image â†’ 8 patches (500Ã—500 each)\n",
    "â”œâ”€ Patch 1-4: Top row [0,500] Ã— [0,500]\n",
    "â””â”€ Patch 5-8: Bottom row [500,1000] Ã— [0,500]\n",
    "â†“\n",
    "Resize each to 224Ã—224\n",
    "â†“\n",
    "Normalize (ImageNet stats)\n",
    "â†“\n",
    "Stack: [8, 3, 224, 224]\n",
    "```\n",
    "\n",
    "**Step 3: Vision Models** (Batch all 8 patches)\n",
    "```\n",
    "Patches â†’ ViT-Base â†’ [8] predictions\n",
    "Patches â†’ ResNet-50 â†’ [8] predictions\n",
    "Patches â†’ DenseNet-121 â†’ [8] predictions\n",
    "â†“\n",
    "Average across 8 patches\n",
    "â†“\n",
    "Result: 3 predictions (one per model)\n",
    "```\n",
    "\n",
    "**Step 4: Species Prediction** (Optional)\n",
    "```\n",
    "Patches â†’ Species ViT â†’ [8, 15] logits\n",
    "â†“\n",
    "Argmax â†’ [8] class indices\n",
    "â†“\n",
    "Majority voting across 8 patches\n",
    "â†“\n",
    "Result: predicted_species (string)\n",
    "```\n",
    "\n",
    "**Step 5: Test Feature Fetching**\n",
    "```\n",
    "Apply 4-level fallback:\n",
    "Level 1: Exact sample_id match\n",
    "   â†“ If not found:\n",
    "Level 2: Image_id + predicted_species\n",
    "   â†“ If not found:\n",
    "Level 3: Random state + species combo\n",
    "   â†“ If not found:\n",
    "Level 4: Statistical generation\n",
    "â†“\n",
    "Result: 29-dim feature vector\n",
    "```\n",
    "\n",
    "**Step 6: XGBoost Prediction**\n",
    "```\n",
    "29-dim features â†’ XGBoost â†’ prediction\n",
    "â†“\n",
    "Result: 1 prediction\n",
    "```\n",
    "\n",
    "**Step 7: Meta-Learner Fusion**\n",
    "```\n",
    "Concatenate:\n",
    "- 3 vision predictions (ViT, ResNet, DenseNet)\n",
    "- 1 XGBoost prediction\n",
    "- 1 dummy/mean prediction (for 5 total)\n",
    "- 29 tabular features\n",
    "â†“\n",
    "Total: 34 dimensions\n",
    "â†“\n",
    "Meta-Learner neural network\n",
    "â†“\n",
    "Final prediction\n",
    "```\n",
    "\n",
    "**Step 8: Prediction Aggregation**\n",
    "```\n",
    "Final prediction = Meta-Learner([pred_vit, pred_resnet, \n",
    "                                 pred_densenet, pred_xgb, \n",
    "                                 mean_pred, features_29])\n",
    "```\n",
    "\n",
    "### Per-Patch vs Per-Sample\n",
    "\n",
    "**Vision Models**:\n",
    "- Compute per patch: [8] predictions\n",
    "- Average across patches: scalar prediction\n",
    "- Rationale: Spatial robustness\n",
    "\n",
    "**Tabular Model**:\n",
    "- Constant features per image\n",
    "- Single prediction: scalar\n",
    "\n",
    "**Meta-Learner**:\n",
    "- Single forward pass\n",
    "- Input: averaged predictions + features\n",
    "- Output: final prediction\n",
    "\n",
    "**Output**: \n",
    "- 5 test predictions (one per target type)\n",
    "- Predictions stored as sample_id â†’ value pairs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98195497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_sample_id(sample_ids_batch, patches_per_image=8):\n",
    "    \"\"\"\n",
    "    Safer: return one sample_id per image.\n",
    "\n",
    "    - If input already appears to be image-level (all elements unique) we return the list unchanged.\n",
    "    - If input appears patch-level with exact repetition pattern, return each first element of chunk.\n",
    "    - Otherwise fall back to run-length collapse (preserves order).\n",
    "    Always returns a list of strings.\n",
    "    \"\"\"\n",
    "    # Normalize and convert tensors/ndarrays -> python list\n",
    "    if sample_ids_batch is None:\n",
    "        return []\n",
    "\n",
    "    if isinstance(sample_ids_batch, torch.Tensor):\n",
    "        try:\n",
    "            sample_ids_batch = sample_ids_batch.cpu().tolist()\n",
    "        except Exception:\n",
    "            sample_ids_batch = list(sample_ids_batch.numpy())\n",
    "    elif isinstance(sample_ids_batch, (np.ndarray, )):\n",
    "        sample_ids_batch = sample_ids_batch.tolist()\n",
    "    elif isinstance(sample_ids_batch, (str, int)):\n",
    "        return [str(sample_ids_batch)]\n",
    "    elif not isinstance(sample_ids_batch, (list, tuple)):\n",
    "        try:\n",
    "            sample_ids_batch = list(sample_ids_batch)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    # now a python list\n",
    "    try:\n",
    "        sample_ids_batch = [str(x) for x in sample_ids_batch]\n",
    "    except Exception:\n",
    "        sample_ids_batch = list(sample_ids_batch)\n",
    "\n",
    "    total = len(sample_ids_batch)\n",
    "    if total == 0:\n",
    "        return []\n",
    "\n",
    "    # Quick: if it already looks one-per-image (all unique), return as-is\n",
    "    if len(set(sample_ids_batch)) == total:\n",
    "        return sample_ids_batch\n",
    "\n",
    "    # If exact multiple of patches_per_image AND chunks are consistent -> return first element of each chunk\n",
    "    if patches_per_image > 0 and total % patches_per_image == 0:\n",
    "        consistent = True\n",
    "        out = []\n",
    "        for i in range(0, total, patches_per_image):\n",
    "            chunk = sample_ids_batch[i:i+patches_per_image]\n",
    "            # consider chunk consistent if majority identical to first\n",
    "            if len(set(chunk)) > 1:\n",
    "                # allow small noise: require at least half to equal the first entry\n",
    "                cnt_first = sum(1 for s in chunk if s == chunk[0])\n",
    "                if cnt_first < (len(chunk) // 2 + 1):\n",
    "                    consistent = False\n",
    "                    break\n",
    "            out.append(chunk[0])\n",
    "        if consistent:\n",
    "            return out\n",
    "\n",
    "    # Fallback: run-length collapse (preserves order)\n",
    "    unique = []\n",
    "    prev = None\n",
    "    for s in sample_ids_batch:\n",
    "        if s != prev:\n",
    "            unique.append(s)\n",
    "            prev = s\n",
    "    return unique\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# fallback trim_mean if scipy not available\n",
    "try:\n",
    "    from scipy.stats import trim_mean as _scipy_trim_mean\n",
    "    def trim_mean(arr, proportion_to_cut):\n",
    "        return float(_scipy_trim_mean(np.asarray(arr, dtype=float), proportion_to_cut))\n",
    "except Exception:\n",
    "    def trim_mean(arr, proportion_to_cut):\n",
    "        a = sorted(float(x) for x in arr)\n",
    "        n = len(a)\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        cut = int(round(n * proportion_to_cut))\n",
    "        if 2 * cut >= n:\n",
    "            return float(sum(a) / n)\n",
    "        return float(sum(a[cut:n-cut]) / max(1, n - 2*cut))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "def get_base_model_predictions(vit_model, resnet_model, densenet_model, xgb_model,\n",
    "                               data_loader, species_model=None, mode='train', device=None):\n",
    "    \"\"\"\n",
    "    Robust drop-in for original get_base_model_predictions.\n",
    "    Preserves variable names & overall behavior but hardens:\n",
    "      - per-patch -> per-image target aggregation (always deterministic)\n",
    "      - robust tabular stacking / padding\n",
    "      - stable trimmed-mean fallback\n",
    "      - uses get_unique_sample_id to infer image count when possible\n",
    "    \"\"\"\n",
    "    # ====== helpers (use existing global helpers if present) ======\n",
    "    # stable trim_mean fallback\n",
    "    try:\n",
    "        from scipy.stats import trim_mean as _scipy_trim_mean\n",
    "        def trim_mean(arr, proportion_to_cut):\n",
    "            return float(_scipy_trim_mean(np.asarray(arr, dtype=float), proportion_to_cut))\n",
    "    except Exception:\n",
    "        def trim_mean(arr, proportion_to_cut):\n",
    "            a = sorted(float(x) for x in arr)\n",
    "            n = len(a)\n",
    "            if n == 0:\n",
    "                return 0.0\n",
    "            # use floor to avoid over-cutting small arrays\n",
    "            cut = int(np.floor(n * proportion_to_cut))\n",
    "            if 2 * cut >= n:\n",
    "                return float(sum(a) / n)\n",
    "            return float(sum(a[cut:n-cut]) / max(1, n - 2*cut))\n",
    "\n",
    "    # try to use existing _image_targets_from_patch_targets if defined, else fallback\n",
    "    if '_image_targets_from_patch_targets' in globals():\n",
    "        _img_targets_fn = globals()['_image_targets_from_patch_targets']\n",
    "    else:\n",
    "        def _img_targets_fn(targets_per_patch, B, P, device=None):\n",
    "            # fallback mimic of your earlier implementation -> returns numpy 1D length B\n",
    "            if targets_per_patch is None:\n",
    "                return np.zeros((B,), dtype=float)\n",
    "            if isinstance(targets_per_patch, torch.Tensor):\n",
    "                t = targets_per_patch.detach().cpu().numpy().ravel()\n",
    "            else:\n",
    "                t = np.asarray(targets_per_patch).ravel()\n",
    "            N = t.size\n",
    "            exp = B * P\n",
    "            if N != exp:\n",
    "                if N > exp:\n",
    "                    t = t[:exp]\n",
    "                else:\n",
    "                    pad_n = exp - N\n",
    "                    pad_vals = np.full((pad_n,), t.mean() if N > 0 else 0.0)\n",
    "                    t = np.concatenate([t, pad_vals], axis=0)\n",
    "            return t.reshape(B, P).mean(axis=1)\n",
    "\n",
    "    # ====== ensure device ======\n",
    "    try:\n",
    "        device = device if isinstance(device, torch.device) else torch.device(device if device is not None else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    except Exception:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    all_vit_preds = []\n",
    "    all_resnet_preds = []\n",
    "    all_densenet_preds = []\n",
    "    all_xgb_preds = []\n",
    "    all_tabular = []\n",
    "    all_targets = []\n",
    "    all_sample_ids = []\n",
    "    all_target_names = []\n",
    "    all_target_idx = []\n",
    "\n",
    "    use_mil = CONFIG.get(\"use_mil\", False)\n",
    "    patches_per_row_detected = None\n",
    "    MAX_TARGET = globals().get('MAX_TARGET', None)\n",
    "    if MAX_TARGET is None or MAX_TARGET < 0:\n",
    "        MAX_TARGET = 200\n",
    "\n",
    "    # ensure models on device & eval\n",
    "    for m in (vit_model, resnet_model, densenet_model, species_model):\n",
    "        if m is not None:\n",
    "            try:\n",
    "                m.to(device)\n",
    "                m.eval()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(data_loader, desc=f\"Base Predictions ({mode})\", unit=\"batch\")):\n",
    "            # Unpack defensively (keep your original batch shapes logic)\n",
    "            t_slice = None\n",
    "            if len(batch) == 7:\n",
    "                images, tabular, _spec,target_idx_batch, targets, sample_ids, target_names = batch\n",
    "            elif len(batch) == 5:\n",
    "                if mode in ['train', 'val']:\n",
    "                    images, tabular, targets, sample_ids, target_names = batch\n",
    "                else:\n",
    "                    images, tabular, _spec, sample_ids, target_names = batch\n",
    "                    targets = None\n",
    "            elif len(batch) == 4:\n",
    "                images, targets, sample_ids, target_names = batch\n",
    "                tabular = None\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "\n",
    "            # normalize lists for sample_ids & target_names\n",
    "            try:\n",
    "                sample_ids_list = list(sample_ids) if not isinstance(sample_ids, str) else [sample_ids]\n",
    "            except Exception:\n",
    "                sample_ids_list = [sample_ids] if sample_ids is not None else []\n",
    "            try:\n",
    "                target_names_list = list(target_names) if target_names is not None and not isinstance(target_names, str) else ([target_names] if target_names is not None else [])\n",
    "            except Exception:\n",
    "                target_names_list = [target_names] if target_names is not None else []\n",
    "\n",
    "            sample_ids_list = [str(s) for s in sample_ids_list] if len(sample_ids_list) else []\n",
    "            target_names_list = [str(t) for t in target_names_list] if len(target_names_list) else []\n",
    "\n",
    "            # move tensors to device where possible\n",
    "            try:\n",
    "                images = images.to(device)\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                if tabular is not None:\n",
    "                    tabular = tabular.to(device)\n",
    "                    target_start_idx = 25\n",
    "                    try:\n",
    "                        raw_target_idx = torch.argmax(tabular[:, target_start_idx:target_start_idx+5], dim=-1)\n",
    "                        # FIX #1: Reconstruct raw_target_idx from target_names_list\n",
    "                        # This ensures different target types get different indices\n",
    "                        if raw_target_idx is not None and len(target_names_list) > 0:\n",
    "                            TARGET_NAMES_ORDER = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "                            image_level_target_idx = []\n",
    "                            patches_per_row_temp = CONFIG.get('num_patches', 8)\n",
    "                            \n",
    "                            for i in range(0, len(target_names_list), patches_per_row_temp):\n",
    "                                target_name = target_names_list[i] if i < len(target_names_list) else 'Dry_Clover_g'\n",
    "                                if target_name in TARGET_NAMES_ORDER:\n",
    "                                    idx = TARGET_NAMES_ORDER.index(target_name)\n",
    "                                else:\n",
    "                                    idx = 0\n",
    "                                image_level_target_idx.append(idx)\n",
    "                            \n",
    "                            raw_target_idx = torch.tensor(image_level_target_idx, dtype=torch.long, device=device)\n",
    "                            logger.debug(f\"FIX #1: Reconstructed raw_target_idx from target_names: {image_level_target_idx}\")\n",
    "\n",
    "                    except Exception:\n",
    "                        raw_target_idx = None\n",
    "                else:\n",
    "                    raw_target_idx = None\n",
    "            except Exception:\n",
    "                raw_target_idx = None\n",
    "\n",
    "            total_patches = int(images.shape[0])\n",
    "\n",
    "            # infer patches_per_row safely (prefer sample_ids when possible)\n",
    "            n_unique_ids = len(list(dict.fromkeys(sample_ids_list))) if len(sample_ids_list) > 0 else 0\n",
    "            inferred_ppr = None\n",
    "            if n_unique_ids > 0:\n",
    "                inferred = total_patches // n_unique_ids if n_unique_ids > 0 else 0\n",
    "                if inferred >= 1:\n",
    "                    inferred_ppr = int(inferred)\n",
    "            patches_per_row = int(inferred_ppr) if (inferred_ppr is not None and inferred_ppr > 0) else int(CONFIG.get('num_patches', 8))\n",
    "            if patches_per_row <= 0:\n",
    "                patches_per_row = int(CONFIG.get('num_patches', 8))\n",
    "            if patches_per_row_detected is None:\n",
    "                patches_per_row_detected = patches_per_row\n",
    "            elif patches_per_row_detected != patches_per_row:\n",
    "                logger.warning(\"Varying patches_per_row across batches: previous=%s now=%s\", patches_per_row_detected, patches_per_row)\n",
    "\n",
    "            # determine n_images using unique sample ids when possible\n",
    "            unique_ids = []\n",
    "            try:\n",
    "                unique_ids = get_unique_sample_id(sample_ids_list, patches_per_image=patches_per_row)\n",
    "            except Exception:\n",
    "                unique_ids = []\n",
    "            if len(unique_ids) > 0:\n",
    "                n_images = len(unique_ids)\n",
    "            else:\n",
    "                n_images = int(total_patches // patches_per_row) if patches_per_row > 0 else 0\n",
    "\n",
    "            # --- forward passes (defensive) ---\n",
    "            try:\n",
    "                # VIT\n",
    "                try:\n",
    "                    if use_mil:\n",
    "                        # FIX #2: Use reconstructed raw_target_idx directly (no slicing)\n",
    "                        t_slice = raw_target_idx if isinstance(raw_target_idx, torch.Tensor) else None\n",
    "                        if t_slice is not None and t_slice.numel() < n_images:\n",
    "                            pad_size = n_images - t_slice.numel()\n",
    "                            t_slice = torch.cat([t_slice, torch.zeros(pad_size, dtype=torch.long, device=device)])\n",
    "                            logger.debug(f\"FIX #2: Padded t_slice to {t_slice}\")\n",
    "                        else:\n",
    "                            logger.debug(f\"FIX #2: Using reconstructed t_slice: {t_slice}\")\n",
    "                        \n",
    "                        vit_out = vit_model(images, t_slice, return_features=False)\n",
    "\n",
    "                    else:\n",
    "                        vit_out = vit_model(images, raw_target_idx, return_features=False)\n",
    "                    vit_preds = np.asarray(vit_out.detach().cpu().numpy()).ravel()\n",
    "                except Exception as e:\n",
    "                    logger.exception(\"vit forward failed in batch %d: %s\", batch_idx, e)\n",
    "                    n_expected = n_images if use_mil else total_patches\n",
    "                    vit_preds = np.zeros((n_expected,), dtype=float)\n",
    "\n",
    "                # RESNET\n",
    "                try:\n",
    "                    if use_mil:\n",
    "                        t_slice = raw_target_idx if isinstance(raw_target_idx, torch.Tensor) else None\n",
    "                        if t_slice is not None and t_slice.numel() < n_images:\n",
    "                            pad_size = n_images - t_slice.numel()\n",
    "                            t_slice = torch.cat([t_slice, torch.zeros(pad_size, dtype=torch.long, device=device)])\n",
    "                            logger.debug(f\"FIX #2: Padded t_slice to {t_slice}\")\n",
    "                        else:\n",
    "                            logger.debug(f\"FIX #2: Using reconstructed t_slice: {t_slice}\")\n",
    "                        resnet_out = resnet_model(images, t_slice, return_features=False)\n",
    "                    else:\n",
    "                        resnet_out = resnet_model(images, raw_target_idx, return_features=False)\n",
    "                    resnet_preds = np.asarray(resnet_out.detach().cpu().numpy()).ravel()\n",
    "                except Exception as e:\n",
    "                    logger.exception(\"resnet forward failed in batch %d: %s\", batch_idx, e)\n",
    "                    n_expected = n_images if use_mil else total_patches\n",
    "                    resnet_preds = np.zeros((n_expected,), dtype=float)\n",
    "\n",
    "                # DENSENET\n",
    "                try:\n",
    "                    if use_mil:\n",
    "                        t_slice = raw_target_idx if isinstance(raw_target_idx, torch.Tensor) else None\n",
    "                        if t_slice is not None and t_slice.numel() < n_images:\n",
    "                            pad_size = n_images - t_slice.numel()\n",
    "                            t_slice = torch.cat([t_slice, torch.zeros(pad_size, dtype=torch.long, device=device)])\n",
    "                            logger.debug(f\"FIX #2: Padded t_slice to {t_slice}\")\n",
    "                        else:\n",
    "                            logger.debug(f\"FIX #2: Using reconstructed t_slice: {t_slice}\")\n",
    "                        densenet_out = densenet_model(images, t_slice, return_features=False)\n",
    "                    else:\n",
    "                        densenet_out = densenet_model(images, raw_target_idx, return_features=False)\n",
    "                    densenet_preds = np.asarray(densenet_out.detach().cpu().numpy()).ravel()\n",
    "                except Exception as e:\n",
    "                    logger.exception(\"densenet forward failed in batch %d: %s\", batch_idx, e)\n",
    "                    n_expected = n_images if use_mil else total_patches\n",
    "                    densenet_preds = np.zeros((n_expected,), dtype=float)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.exception(\"Unexpected forward pass error in batch %d: %s\", batch_idx, e)\n",
    "                vit_preds = np.zeros((0,), dtype=float)\n",
    "                resnet_preds = np.zeros((0,), dtype=float)\n",
    "                densenet_preds = np.zeros((0,), dtype=float)\n",
    "\n",
    "            # clip preds\n",
    "            vit_preds = np.clip(vit_preds, 0.0, MAX_TARGET)\n",
    "            resnet_preds = np.clip(resnet_preds, 0.0, MAX_TARGET)\n",
    "            densenet_preds = np.clip(densenet_preds, 0.0, MAX_TARGET)\n",
    "\n",
    "            # --- aggregate to image-level if necessary ---\n",
    "            if use_mil:\n",
    "                vit_image_preds = vit_preds\n",
    "                resnet_image_preds = resnet_preds\n",
    "                densenet_image_preds = densenet_preds\n",
    "                n_images_eff = len(vit_image_preds)\n",
    "                logger.debug(f\"MIL mode: received {n_images_eff} image-level predictions (shape={vit_preds.shape})\")\n",
    "            else:\n",
    "                logger.debug(f\"Non-MIL mode: received {len(vit_preds)} per-patch predictions (shape={vit_preds.shape})\")\n",
    "\n",
    "                vit_image_med = aggregate_blocks(vit_preds, patches_per_row, method='median')\n",
    "                resnet_image_med = aggregate_blocks(resnet_preds, patches_per_row, method='median')\n",
    "                densenet_image_med = aggregate_blocks(densenet_preds, patches_per_row, method='median')\n",
    "\n",
    "                vit_image_trim = aggregate_blocks(vit_preds, patches_per_row, method='trimmed_mean')\n",
    "                resnet_image_trim = aggregate_blocks(resnet_preds, patches_per_row, method='trimmed_mean')\n",
    "                densenet_image_trim = aggregate_blocks(densenet_preds, patches_per_row, method='trimmed_mean')\n",
    "\n",
    "                vit_image_preds = vit_image_trim if len(vit_image_trim) == len(vit_image_med) else vit_image_med\n",
    "                resnet_image_preds = resnet_image_trim if len(resnet_image_trim) == len(resnet_image_med) else resnet_image_med\n",
    "                densenet_image_preds = densenet_image_trim if len(densenet_image_trim) == len(densenet_image_med) else densenet_image_med\n",
    "\n",
    "                n_images_eff = len(vit_image_preds)\n",
    "                logger.debug(f\"Non-MIL mode: aggregated to {n_images_eff} image-level predictions\")\n",
    "\n",
    "            # --- tabular -> per-image (take first row of each block) ---\n",
    "            try:\n",
    "                if tabular is not None:\n",
    "                    tabular_np = tabular.cpu().numpy()\n",
    "                else:\n",
    "                    tabular_np = np.zeros((total_patches, TOTAL_TABULAR_DIM))\n",
    "            except Exception:\n",
    "                tabular_np = np.zeros((total_patches, TOTAL_TABULAR_DIM))\n",
    "\n",
    "            TARGET_NAMES_ORDER = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "            tabular_image = []\n",
    "            \n",
    "            for i in range(0, total_patches, patches_per_row):\n",
    "                idx = i\n",
    "                if idx < tabular_np.shape[0]:\n",
    "                    row = tabular_np[idx, :TOTAL_TABULAR_DIM].copy()  # COPY to avoid modifying original\n",
    "                    if row.shape[0] < TOTAL_TABULAR_DIM:\n",
    "                        row = np.pad(row, (0, max(0, TOTAL_TABULAR_DIM - row.shape[0])), 'constant')\n",
    "                else:\n",
    "                    row = np.zeros((TOTAL_TABULAR_DIM,), dtype=float)\n",
    "                \n",
    "                # FIX #3: Reconstruct target-name one-hot encoding (indices 25:30)\n",
    "                patch_group_idx = i // patches_per_row  # Which image/target group is this?\n",
    "                if patch_group_idx < len(target_names_list):\n",
    "                    target_name = target_names_list[patch_group_idx]\n",
    "                    if target_name in TARGET_NAMES_ORDER:\n",
    "                        target_idx = TARGET_NAMES_ORDER.index(target_name)\n",
    "                        # Create one-hot encoding for this target\n",
    "                        one_hot = np.zeros(5, dtype=float)\n",
    "                        one_hot[target_idx] = 1.0\n",
    "                        # Replace the target encoding in the feature vector\n",
    "                        row[25:30] = one_hot\n",
    "                        logger.debug(f\"FIX #3: Set target encoding for {target_name} (idx={target_idx}): {one_hot}\")\n",
    "                \n",
    "                tabular_image.append(row)\n",
    "            \n",
    "            tabular_image = np.array(tabular_image, dtype=float)\n",
    "            logger.debug(f\"FIX #3: tabular_image shape={tabular_image.shape}, target encodings (col 25-30):\\n{tabular_image[:, 25:30]}\")\n",
    "\n",
    "\n",
    "            # --- xgboost predictions per-image ---\n",
    "            xgb_image_preds = np.zeros(n_images_eff, dtype=np.float32)\n",
    "            for row_idx in range(n_images_eff):\n",
    "                if use_mil:\n",
    "                    tn_idx = row_idx\n",
    "                else:\n",
    "                    tn_idx = row_idx * patches_per_row\n",
    "                if tn_idx < len(target_names_list):\n",
    "                    target_name = target_names_list[tn_idx]\n",
    "                elif row_idx < len(target_names_list):\n",
    "                    target_name = target_names_list[row_idx]\n",
    "                else:\n",
    "                    target_name = None\n",
    "                \n",
    "                # â† NEW: Boost target type columns to match training (3x repeat)\n",
    "                X_target_base = tabular_image[row_idx:row_idx+1, :25]        # First 25 cols\n",
    "                target_type_boost = tabular_image[row_idx:row_idx+1, 25:30]   # Target type (5 cols)\n",
    "                X_target = np.hstack([\n",
    "                    X_target_base,\n",
    "                    target_type_boost,\n",
    "                    target_type_boost,\n",
    "                    target_type_boost\n",
    "                ])\n",
    "                \n",
    "                try:\n",
    "                    xgb_pred = xgb_model.predict(X_target, target_name)\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        xgb_pred = xgb_model.predict(X_target)\n",
    "                    except Exception:\n",
    "                        xgb_pred = np.array([0.0])\n",
    "                xgb_image_preds[row_idx] = float(np.clip(np.asarray(xgb_pred).ravel()[0], 0.0, MAX_TARGET))\n",
    "\n",
    "\n",
    "            # canonical per-image sample ids: prefer get_unique_sample_id result if lengths match\n",
    "            if len(unique_ids) == n_images_eff:\n",
    "                batch_sample_ids = unique_ids\n",
    "            else:\n",
    "                # fallback: first id of each block\n",
    "                batch_sample_ids = []\n",
    "                for i in range(0, min(total_patches, patches_per_row * n_images_eff), patches_per_row):\n",
    "                    if i < len(sample_ids_list):\n",
    "                        batch_sample_ids.append(sample_ids_list[i])\n",
    "                    else:\n",
    "                        batch_sample_ids.append(\"None\")\n",
    "                batch_sample_ids = batch_sample_ids[:n_images_eff]\n",
    "\n",
    "            # canonical per-image target names\n",
    "            batch_target_names = []\n",
    "            for i in range(n_images_eff):\n",
    "                if use_mil:\n",
    "                    tn_idx = i\n",
    "                else:\n",
    "                    tn_idx = i * patches_per_row\n",
    "                if tn_idx < len(target_names_list):\n",
    "                    batch_target_names.append(target_names_list[tn_idx])\n",
    "                elif i < len(target_names_list):\n",
    "                    batch_target_names.append(target_names_list[i])\n",
    "                else:\n",
    "                    batch_target_names.append(None)\n",
    "\n",
    "            # collect\n",
    "            all_vit_preds.append(vit_image_preds)\n",
    "            all_resnet_preds.append(resnet_image_preds)\n",
    "            all_densenet_preds.append(densenet_image_preds)\n",
    "            all_xgb_preds.append(xgb_image_preds)\n",
    "            all_tabular.append(tabular_image)\n",
    "            all_sample_ids.extend(batch_sample_ids)\n",
    "            all_target_names.extend(batch_target_names)\n",
    "            \n",
    "            if t_slice is not None:\n",
    "                if isinstance(t_slice, torch.Tensor):\n",
    "                    all_target_idx.append(t_slice.detach().cpu().numpy())\n",
    "                else:\n",
    "                    all_target_idx.append(np.asarray(t_slice))\n",
    "            else:\n",
    "                # If no target_idx, append placeholder\n",
    "                all_target_idx.append(np.array([-1] * n_images_eff))\n",
    "                \n",
    "            # Targets -> robust image-level aggregation\n",
    "            if mode in ['train', 'val'] and targets is not None:\n",
    "                try:\n",
    "                    # get numpy flat\n",
    "                    try:\n",
    "                        t_np = targets.cpu().numpy().ravel() if isinstance(targets, torch.Tensor) else np.asarray(targets).ravel()\n",
    "                    except Exception:\n",
    "                        t_np = np.asarray(targets).ravel()\n",
    "                    if use_mil:\n",
    "                        # if t_np already image-level length matches n_images_eff -> use it\n",
    "                        if t_np.size == n_images_eff:\n",
    "                            t_image = t_np[:n_images_eff]\n",
    "                        else:\n",
    "                            t_image = _img_targets_fn(t_np, n_images_eff, patches_per_row, device=device)\n",
    "                    else:\n",
    "                        # non-MIL: re-group patches -> image mean\n",
    "                        if t_np.size == n_images_eff:\n",
    "                            t_image = t_np\n",
    "                        else:\n",
    "                            t_image = _img_targets_fn(t_np, n_images_eff, patches_per_row, device=device)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to compute image-level targets for batch {batch_idx}: {e}\")\n",
    "                    t_image = np.zeros((n_images_eff,), dtype=float)\n",
    "                if isinstance(t_image, torch.Tensor):\n",
    "                    t_image = t_image.detach().cpu().numpy().ravel()\n",
    "                else:\n",
    "                    t_image = np.asarray(t_image).ravel()\n",
    "            \n",
    "                all_targets.append(t_image)\n",
    "\n",
    "\n",
    "    # ===== concatenate safely =====\n",
    "    vit_preds_all = np.concatenate(all_vit_preds) if len(all_vit_preds) else np.array([])\n",
    "    resnet_preds_all = np.concatenate(all_resnet_preds) if len(all_resnet_preds) else np.array([])\n",
    "    densenet_preds_all = np.concatenate(all_densenet_preds) if len(all_densenet_preds) else np.array([])\n",
    "    xgb_preds_all = np.concatenate(all_xgb_preds) if len(all_xgb_preds) else np.array([])\n",
    "\n",
    "    if len(all_target_idx) > 0:\n",
    "        target_idx_all = np.concatenate(all_target_idx).ravel().astype(int)\n",
    "    else:\n",
    "        target_idx_all = np.array([], dtype=int)\n",
    "        \n",
    "    # STACK tabular robustly and pad/truncate columns to TOTAL_TABULAR_DIM\n",
    "    if len(all_tabular) == 0:\n",
    "        tabular_all = np.zeros((0, TOTAL_TABULAR_DIM), dtype=float)\n",
    "    else:\n",
    "        fixed_tab_list = []\n",
    "        for arr in all_tabular:\n",
    "            arr = np.asarray(arr, dtype=float)\n",
    "            if arr.ndim == 1:\n",
    "                arr = arr.reshape(-1, arr.shape[0])\n",
    "            if arr.shape[1] < TOTAL_TABULAR_DIM:\n",
    "                arr = np.pad(arr, ((0,0),(0, TOTAL_TABULAR_DIM - arr.shape[1])), 'constant', constant_values=0.0)\n",
    "            elif arr.shape[1] > TOTAL_TABULAR_DIM:\n",
    "                arr = arr[:, :TOTAL_TABULAR_DIM]\n",
    "            fixed_tab_list.append(arr)\n",
    "        tabular_all = np.vstack(fixed_tab_list) if fixed_tab_list else np.zeros((0, TOTAL_TABULAR_DIM), dtype=float)\n",
    "\n",
    "    # ensemble \n",
    "    if vit_preds_all.size:\n",
    "        stack = np.vstack([vit_preds_all, resnet_preds_all, densenet_preds_all]).astype(np.float64)\n",
    "        stack = np.nan_to_num(stack, nan=0.0, posinf=1e8, neginf=0.0)\n",
    "        med = np.median(stack, axis=0, keepdims=True)\n",
    "        abs_dev = np.abs(stack - med)\n",
    "        pseudo_var_model = (abs_dev + 1e-6) ** 2\n",
    "        inv_var_model = 1.0 / (pseudo_var_model + 1e-12)\n",
    "\n",
    "        temp = 1.0\n",
    "        inv_var_adj = inv_var_model ** (1.0 / temp)\n",
    "        max_w = 0.9\n",
    "        weights = inv_var_adj / (inv_var_adj.sum(axis=0, keepdims=True) + 1e-12)\n",
    "        weights = np.minimum(weights, max_w)\n",
    "        weights = weights / (weights.sum(axis=0, keepdims=True) + 1e-12)\n",
    "\n",
    "        ensemble_preds = np.sum(weights * stack, axis=0)\n",
    "        overall_var = np.var(stack, axis=0)\n",
    "        low_var_mask = overall_var < 1e-3\n",
    "        if np.any(low_var_mask):\n",
    "            ensemble_preds[low_var_mask] = np.median(stack[:, low_var_mask], axis=0)\n",
    "        ensemble_preds = np.clip(ensemble_preds.astype(np.float32), 0.0, MAX_TARGET)\n",
    "    else:\n",
    "        ensemble_preds = np.array([])\n",
    "        \n",
    "    if vit_preds_all.size:\n",
    "        # XGBoost Quality Check: Replace Values >10% Different from Ensemble\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \n",
    "        # Step 1: Calculate percentage difference from ensemble\n",
    "        # percentage_diff = |xgb - ensemble| / ensemble * 100\n",
    "        percentage_diff = np.abs(xgb_preds_all - ensemble_preds) / (np.abs(ensemble_preds) + 1e-6) * 100\n",
    "    \n",
    "        # Step 2: Define threshold\n",
    "        PERCENT_THRESHOLD = 10.0  # Â±10% difference\n",
    "        # Tune: 5.0=strict (5%), 15.0=lenient (15%), 20.0=very lenient (20%)\n",
    "    \n",
    "        # Step 3: Identify outliers (difference > 10%)\n",
    "        outlier_mask = percentage_diff > PERCENT_THRESHOLD\n",
    "    \n",
    "        # Step 4: Replace ONLY outlier values with DenseNet\n",
    "        xgb_preds_all_fixed = xgb_preds_all.copy()\n",
    "        xgb_preds_all_fixed[outlier_mask] = ensemble_preds[outlier_mask]\n",
    "    \n",
    "        # Step 5: Logging\n",
    "        num_outliers = outlier_mask.sum()\n",
    "        pct_outliers = (num_outliers / len(xgb_preds_all)) * 100 if len(xgb_preds_all) > 0 else 0\n",
    "    \n",
    "        logger.info(f\"[XGBoost Quality Check]\")\n",
    "        logger.info(f\"  Threshold: Â±{PERCENT_THRESHOLD}% difference from ensemble\")\n",
    "        logger.info(f\"  Percentage difference: mean={percentage_diff.mean():.2f}%, max={percentage_diff.max():.2f}%\")\n",
    "        logger.info(f\"  Outliers detected: {num_outliers}/{len(xgb_preds_all)} ({pct_outliers:.1f}%)\")\n",
    "        if num_outliers > 0:\n",
    "            logger.info(f\"  Replaced {num_outliers} values with Ensemble Average\")\n",
    "    \n",
    "        # Step 6: Use updated XGBoost\n",
    "        xgb_preds_all = xgb_preds_all_fixed\n",
    "    \n",
    "    base_predictions = np.column_stack([vit_preds_all, resnet_preds_all, densenet_preds_all, xgb_preds_all, ensemble_preds]) if vit_preds_all.size else np.zeros((0,5), dtype=np.float32)\n",
    "\n",
    "    # final sanity checks (preserve previous behavior)\n",
    "    if base_predictions.shape[0] != len(all_sample_ids):\n",
    "        logger.error(\"MISMATCH: %d predictions vs %d sample_ids\", base_predictions.shape[0], len(all_sample_ids))\n",
    "        raise ValueError(\"Predictions and sample IDs don't align!\")\n",
    "\n",
    "    if len(all_sample_ids) != len(all_target_names):\n",
    "        logger.error(\"MISMATCH: %d sample_ids vs %d target_names\", len(all_sample_ids), len(all_target_names))\n",
    "        raise ValueError(\"Sample IDs and target names don't align!\")\n",
    "\n",
    "    # ensure tabular_all shape\n",
    "    if tabular_all.size != 0:\n",
    "        if tabular_all.ndim == 1:\n",
    "            tabular_all = tabular_all.reshape(-1, TOTAL_TABULAR_DIM)\n",
    "        if tabular_all.shape[1] != TOTAL_TABULAR_DIM:\n",
    "            if tabular_all.shape[1] > TOTAL_TABULAR_DIM:\n",
    "                tabular_all = tabular_all[:, :TOTAL_TABULAR_DIM]\n",
    "            else:\n",
    "                pad_width = TOTAL_TABULAR_DIM - tabular_all.shape[1]\n",
    "                tabular_all = np.pad(tabular_all, ((0,0),(0,pad_width)), 'constant', constant_values=0.0)\n",
    "\n",
    "    result = {\n",
    "        'base_predictions': base_predictions,\n",
    "        'vit': vit_preds_all,\n",
    "        'resnet': resnet_preds_all,\n",
    "        'densenet': densenet_preds_all,\n",
    "        'xgboost': xgb_preds_all,\n",
    "        'ensemble': ensemble_preds,\n",
    "        'tabular': tabular_all,\n",
    "        'sample_ids': all_sample_ids,\n",
    "        'target_idx': target_idx_all,\n",
    "        'target_names': np.array(all_target_names),\n",
    "        'patches_per_row': patches_per_row_detected if patches_per_row_detected is not None else patches_per_row\n",
    "    }\n",
    "\n",
    "    if mode in ['train', 'val']:\n",
    "        targets_all = np.concatenate(all_targets) if len(all_targets) > 0 else np.array([])\n",
    "        result['targets'] = targets_all\n",
    "\n",
    "    logger.info(\"BASE PREDICTIONS SHAPES: base=%s vit=%s resnet=%s densenet=%s xgb=%s ensemble=%s tabular=%s samples=%d (use_mil=%s)\",\n",
    "                result['base_predictions'].shape, result['vit'].shape, result['resnet'].shape,\n",
    "                result['densenet'].shape, result['xgboost'].shape, result['ensemble'].shape if hasattr(result['ensemble'], 'shape') else (), \n",
    "                result['tabular'].shape if hasattr(result['tabular'], 'shape') else (), len(result['sample_ids']), use_mil)\n",
    "    try:\n",
    "        N = 5\n",
    "        logger.info(\"\\n--- First few base_predictions rows ---\")\n",
    "        logger.info(result['base_predictions'][:N])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"DEBUG LOGGING FAILED: {e}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"âœ“ Ensemble Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9989049",
   "metadata": {},
   "source": [
    "## 9: SUBMISSION GENERATION\n",
    "\n",
    "**Purpose**: Format predictions into competition submission CSV with robust error handling and flexible scaling.\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "The updated submission generation now:\n",
    "- âœ… Works with **any number of test rows** (1, 5, 50, 500, 4000+)\n",
    "- âœ… Validates test data structure and integrity\n",
    "- âœ… Handles GPU memory errors with automatic CPU fallback\n",
    "- âœ… Automatically fixes NaN/Inf predictions\n",
    "- âœ… Provides comprehensive error handling and logging\n",
    "\n",
    "---\n",
    "\n",
    "### Required Format\n",
    "\n",
    "**CSV Structure** :\n",
    "```\n",
    "sample_id,target\n",
    "test_1__Dry_Green_g,12345.6700\n",
    "test_1__Dry_Dead_g,8901.2300\n",
    "test_1__Dry_Clover_g,3456.7800\n",
    "test_1__GDM_g,15678.9000\n",
    "test_1__Dry_Total_g,24035.6800\n",
    "```\n",
    "\n",
    "**Key Features**:\n",
    "- Column 1: `sample_id` (format: `{ImageID}__{TargetType}`)\n",
    "- Column 2: `target` (biomass predictions, 4 decimal places)\n",
    "- **Flexible rows**: Works with any number of rows\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### DataFrame Creation\n",
    "\n",
    "- Validation Checks\n",
    "\n",
    "- 1. Structure Validation\n",
    "\n",
    "- 2. Value Validation\n",
    "\n",
    "- 3. Target Type Distribution\n",
    "\n",
    "- 4. Component Consistency Check (If Dry_Total_g exists)\n",
    "\n",
    "- Save to CSV\n",
    "\n",
    "---\n",
    "\n",
    "### Output Logging Example\n",
    "\n",
    "```\n",
    "================================================================================\n",
    "GENERATING SUBMISSION FILE WITH VALIDATION\n",
    "================================================================================\n",
    "\n",
    "[STEP 1/5] Validating test data structure...\n",
    "[STEP 2/5] Validating prediction data...\n",
    "[STEP 3/5] Generating predictions...\n",
    "[STEP 4/5] Cleaning predictions...\n",
    "[STEP 5/5] Validating submission format...\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SUBMISSION FORMAT VALIDATION\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FINAL SUBMISSION PREVIEW:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  [0] ID1001187975__Dry_Clover_g              â†’ 2.338747\n",
    "  [1] ID1001187975__Dry_Dead_g                â†’ 13.354437\n",
    "  [2] ID1001187975__Dry_Green_g               â†’ 14.033021\n",
    "  [3] ID1001187975__Dry_Total_g               â†’ 31.075960\n",
    "  [4] ID1001187975__GDM_g                     â†’ 22.634264\n",
    "\n",
    "================================================================================\n",
    "âœ“ SUBMISSION GENERATION COMPLETE\n",
    "âœ“ File saved: /kaggle/working/submission.csv\n",
    "âœ“ Total: 5 rows Ã— 2 columns\n",
    "================================================================================\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93034d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 292\u001b[39m\n\u001b[32m    287\u001b[39m         logger.debug(traceback.format_exc())\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(columns=[\u001b[33m\"\u001b[39m\u001b[33msample_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[43mlogger\u001b[49m.info(\u001b[33m\"\u001b[39m\u001b[33mâœ“ Submission Function Defined\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "def _extract_target_idx_from_tabular(tab_np, device):\n",
    "    \"\"\"\n",
    "    Extract target indices from tabular one-hot encoding.\n",
    "    \n",
    "    Args:\n",
    "        tab_np: numpy array (N, D) with one-hot at columns [25:30]\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        target_idx: LongTensor of shape (N,) on device\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if tab_np is None:\n",
    "            return torch.zeros(0, dtype=torch.long, device=device)\n",
    "        \n",
    "        if not isinstance(tab_np, np.ndarray):\n",
    "            tab_np = np.asarray(tab_np)\n",
    "        \n",
    "        if tab_np.size == 0:\n",
    "            return torch.zeros(0, dtype=torch.long, device=device)\n",
    "        \n",
    "        if tab_np.ndim == 1:\n",
    "            tab_np = tab_np.reshape(1, -1)\n",
    "        \n",
    "        N = int(tab_np.shape[0])\n",
    "        D = int(tab_np.shape[1])\n",
    "        \n",
    "        # Extract one-hot region (columns 25:30 = 5 target types)\n",
    "        TARGET_ONEHOT_START = 25\n",
    "        NUM_TARGETS = 5\n",
    "        \n",
    "        if D >= TARGET_ONEHOT_START + NUM_TARGETS:\n",
    "            one_hot = tab_np[:, TARGET_ONEHOT_START:TARGET_ONEHOT_START + NUM_TARGETS]\n",
    "            target_idx = np.argmax(one_hot, axis=1)  # shape (N,)\n",
    "            return torch.from_numpy(target_idx.astype(np.int64)).to(device).long()\n",
    "        else:\n",
    "            logger.warning(\n",
    "                f\"Tabular width {D} < required {TARGET_ONEHOT_START + NUM_TARGETS}. \"\n",
    "                f\"Returning zeros.\"\n",
    "            )\n",
    "            return torch.zeros(N, dtype=torch.long, device=device)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to extract target_idx from tabular: {e}\")\n",
    "\n",
    "        try:\n",
    "            N = int(tab_np.shape[0]) if (tab_np is not None and hasattr(tab_np, 'shape')) else 0\n",
    "            return torch.zeros(N, dtype=torch.long, device=device)\n",
    "        except:\n",
    "            return torch.zeros(0, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Return default device (prefers cuda if available).\"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def run_inference_in_batches(model, X_np, tab_np, device=None, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Safe batched inference for meta-learner with TaskEmbedding.\n",
    "    \n",
    "    UPDATED: Now extracts target_idx from tabular and passes it to model.\n",
    "    \n",
    "    Args:\n",
    "        model: MetaLearnerModel with TaskEmbedding\n",
    "        X_np: Base model predictions (N, 5)\n",
    "        tab_np: Tabular features with one-hot at [25:30]\n",
    "        device: torch device\n",
    "        batch_size: batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        1-D numpy array of predictions\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = get_default_device()\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    N = int(X_np.shape[0])\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, N, batch_size):\n",
    "                end_idx = min(i + batch_size, N)\n",
    "                xb = torch.from_numpy(X_np[i:end_idx]).float().to(device)\n",
    "                \n",
    "\n",
    "                target_idx_batch = _extract_target_idx_from_tabular(tab_np[i:end_idx], device)\n",
    "\n",
    "                # Sanity checks\n",
    "                if xb.ndim != 2:\n",
    "                    logger.warning(f\"Warning: xb has wrong shape: {xb.shape}, expected 2D\")\n",
    "                if target_idx_batch.ndim != 1:\n",
    "                    logger.warning(f\"Warning: target_idx has wrong shape: {target_idx_batch.shape}, expected 1D\")\n",
    "                \n",
    "                if xb.shape[0] != target_idx_batch.shape[0]:\n",
    "                    logger.warning(\n",
    "                        f\"Batch size mismatch: xb={xb.shape}, target_idx={target_idx_batch.shape}\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "\n",
    "                out = model(xb, target_idx_batch)  # [batch_size] predictions\n",
    "                out = out.cpu().numpy().ravel()\n",
    "                preds.append(out)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"\\n===== FATAL ERROR DURING INFERENCE =====\")\n",
    "        logger.error(f\"Error message: {e}\")\n",
    "        logger.error(\"=========================================\\n\")\n",
    "        logger.debug(f\"xb shape: {xb.shape if 'xb' in locals() else 'N/A'}\")\n",
    "        logger.debug(f\"target_idx_batch shape: {target_idx_batch.shape if 'target_idx_batch' in locals() else 'N/A'}\")\n",
    "        raise\n",
    "\n",
    "    if len(preds) == 0:\n",
    "        return np.zeros((0,), dtype=np.float32)\n",
    "\n",
    "    preds_arr = np.concatenate(preds, axis=0)\n",
    "\n",
    "    logger.info(\n",
    "        \"DEBUG: run_inference_in_batches -> preds.shape=%s, min=%.4f, max=%.4f, nan_count=%d\",\n",
    "        preds_arr.shape,\n",
    "        (np.nanmin(preds_arr) if preds_arr.size else -1),\n",
    "        (np.nanmax(preds_arr) if preds_arr.size else -1),\n",
    "        int(np.isnan(preds_arr).sum()) if preds_arr.size else 0\n",
    "    )\n",
    "\n",
    "    return preds_arr\n",
    "\n",
    "def generate_submission(meta_learner, test_data, output_path, test_df=None, device=None,\n",
    "                        batch_size_gpu=1024, batch_size_cpu=256, float_format=\"%.4f\"):\n",
    "    \"\"\"\n",
    "    Runs batched inference using updated meta-learner with TaskEmbedding.\n",
    "    \n",
    "    UPDATED: Now handles target_idx extraction internally.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = get_default_device()\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\" * 70)\n",
    "    logger.info(\"SUBMISSION GENERATION (META-LEARNER WITH TASK EMBEDDING)\")\n",
    "    logger.info(\"=\" * 70)\n",
    "    \n",
    "    MAX_TARGET = globals().get('MAX_TARGET', None)\n",
    "    if MAX_TARGET is None or MAX_TARGET < 0:\n",
    "        MAX_TARGET = 200\n",
    "        \n",
    "    try:\n",
    "        # -------- SANITY CHECK --------\n",
    "        if test_data is None:\n",
    "            logger.error(\"âœ— test_data is None - returning empty DataFrame\")\n",
    "            return pd.DataFrame(columns=[\"sample_id\", \"target\"])\n",
    "\n",
    "        for key in (\"base_predictions\", \"tabular\", \"sample_ids\"):\n",
    "            if key not in test_data:\n",
    "                logger.error(f\"âœ— test_data missing key: {key}\")\n",
    "                return pd.DataFrame(columns=[\"sample_id\", \"target\"])\n",
    "\n",
    "        # -------- CONVERT INPUTS --------\n",
    "        try:\n",
    "            X_np = np.asarray(test_data[\"base_predictions\"], dtype=np.float32)\n",
    "            tab_np = np.asarray(test_data[\"tabular\"], dtype=np.float32)\n",
    "            sample_ids = [str(s).strip() for s in test_data[\"sample_ids\"]]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âœ— Error converting test_data arrays: {e}\")\n",
    "            logger.debug(traceback.format_exc())\n",
    "            return pd.DataFrame(columns=[\"sample_id\", \"target\"])\n",
    "\n",
    "        # -------- SHAPE CHECK --------\n",
    "        if X_np.shape[0] != tab_np.shape[0]: \n",
    "            min_len = min(X_np.shape[0], tab_np.shape[0]) \n",
    "            logger.warning(\n",
    "                \"âš  Shape mismatch between base_predictions and tabular. \"\n",
    "                \"Truncating both to same length: %d\", min_len  \n",
    "            )\n",
    "            X_np = X_np[:min_len]\n",
    "            tab_np = tab_np[:min_len]\n",
    "            sample_ids = sample_ids[:min_len]\n",
    "        \n",
    "        logger.info(\n",
    "            \"Test data sizes: predictions_rows=%d, tabular_rows=%d, sample_ids=%d\",\n",
    "            X_np.shape[0], tab_np.shape[0], len(sample_ids)  # âœ… Now integers\n",
    "        )\n",
    "\n",
    "\n",
    "        # -------- DEVICE INFERENCE --------\n",
    "        try:\n",
    "        \n",
    "            final_predictions = run_inference_in_batches(\n",
    "                meta_learner, X_np, tab_np, device=device, batch_size=batch_size_gpu\n",
    "            )\n",
    "            logger.info(f\"âœ“ Inference completed on device: {device}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš  Device inference raised exception: {e}\")\n",
    "            logger.debug(traceback.format_exc())\n",
    "            logger.info(\"â†’ Trying CPU fallback...\")\n",
    "\n",
    "            try:\n",
    "                final_predictions = run_inference_in_batches(\n",
    "                    meta_learner, X_np, tab_np,\n",
    "                    device=torch.device(\"cpu\"),\n",
    "                    batch_size=batch_size_cpu\n",
    "                )\n",
    "                logger.info(\"âœ“ CPU fallback successful\")\n",
    "            except Exception as e2:\n",
    "                logger.error(f\"âœ— CPU fallback also failed: {e2}\")\n",
    "                logger.debug(traceback.format_exc())\n",
    "                return pd.DataFrame(columns=[\"sample_id\", \"target\"])\n",
    "\n",
    "        final_predictions = np.asarray(final_predictions).ravel()\n",
    "\n",
    "\n",
    "        # -------- LENGTH MISMATCH PROTECTION --------\n",
    "        if final_predictions.shape[0] != len(sample_ids):  # âœ… Compare integers\n",
    "            logger.warning(\n",
    "                \"âš  Prediction mismatch: predictions=%d, sample_ids=%d. \"\n",
    "                \"Aligning by truncation.\",\n",
    "                final_predictions.shape[0], len(sample_ids)  # âœ… Both integers\n",
    "            )\n",
    "            min_len = min(final_predictions.shape[0], len(sample_ids))  # âœ… Both integers\n",
    "            final_predictions = final_predictions[:min_len]\n",
    "            sample_ids = sample_ids[:min_len]\n",
    "\n",
    "\n",
    "        # -------- CLEAN NANS --------\n",
    "        final_predictions = np.nan_to_num(final_predictions, nan=np.nan)\n",
    "        nan_mask = np.isnan(final_predictions)\n",
    "\n",
    "        if nan_mask.any():\n",
    "            fallback = float(np.nanmedian(final_predictions))\n",
    "            if np.isnan(fallback):\n",
    "                fallback = 0.0\n",
    "                logger.warning(\"All predictions NaN â†’ fallback = 0.0\")\n",
    "            else:\n",
    "                logger.warning(f\"Replacing {nan_mask.sum()} NaNs with fallback median = {fallback:.4f}\")\n",
    "\n",
    "            final_predictions[nan_mask] = fallback\n",
    "\n",
    "        final_predictions = final_predictions.astype(float)\n",
    "        final_predictions = np.clip(final_predictions, a_min=0, a_max=MAX_TARGET)\n",
    "        \n",
    "        logger.info(\n",
    "            \"Final predictions: min=%.4f, max=%.4f, mean=%.4f, std=%.4f\",\n",
    "            np.min(final_predictions), np.max(final_predictions),\n",
    "            np.mean(final_predictions), np.std(final_predictions)\n",
    "        )\n",
    "\n",
    "        # -------- BUILD SUBMISSION DF --------\n",
    "        submission_df = pd.DataFrame({\n",
    "            \"sample_id\": sample_ids,\n",
    "            \"target\": final_predictions\n",
    "        })\n",
    "\n",
    "        logger.info(f\"âœ“ Submission DataFrame created: rows={len(submission_df)}\")\n",
    "\n",
    "        # -------- OPTIONAL CHECK AGAINST OFFICIAL test_df --------\n",
    "        sorted_sample_ids = sorted(submission_df[\"sample_id\"].tolist())\n",
    "\n",
    "        if test_df is not None and \"sample_id\" in test_df.columns:\n",
    "            official = sorted(test_df[\"sample_id\"].astype(str).tolist())\n",
    "            if sorted_sample_ids == official:\n",
    "                logger.info(\"âœ“ Sorted sample_id exactly matches official ordering.\")\n",
    "            else:\n",
    "                logger.warning(\"âš  Sorted submission ids DO NOT match official test_df ordering.\")\n",
    "                logger.debug(f\"  First 5 submission: {sorted_sample_ids[:5]}\")\n",
    "                logger.debug(f\"  First 5 official:  {official[:5]}\")\n",
    "        else:\n",
    "            logger.info(\"Official test_df not provided â†’ skipping comparison.\")\n",
    "\n",
    "        # -------- SAVE --------\n",
    "        submission_df = submission_df.sort_values(\"sample_id\")\n",
    "        submission_df.to_csv(output_path, index=False, float_format=float_format)\n",
    "        logger.info(f\"âœ“ Submission saved to {output_path}\")\n",
    "        logger.info(f\"  Rows: {len(submission_df)}\")\n",
    "        logger.info(f\"  File: {output_path}\")\n",
    "\n",
    "        return submission_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"âœ— Unexpected error in generate_submission: {e}\")\n",
    "        logger.debug(traceback.format_exc())\n",
    "        return pd.DataFrame(columns=[\"sample_id\", \"target\"])\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"âœ“ Submission Function Defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d8afb",
   "metadata": {},
   "source": [
    "## 10: HELPER FUNCTIONS\n",
    "\n",
    "**Purpose**: Utility functions for memory management and weights export.\n",
    "\n",
    "### Memory Cleanup\n",
    "\n",
    "```python\n",
    "def cleanup_memory(model=None):\n",
    "    '''Aggressive GPU memory cleanup between models'''\n",
    "    \n",
    "    if model is not None:\n",
    "        model = model.cpu()  # Move to CPU\n",
    "        del model            # Delete reference\n",
    "    \n",
    "    gc.collect()            # Garbage collection\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()          # Clear GPU cache\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset counters\n",
    "    \n",
    "    # Log freed memory\n",
    "    if torch.cuda.is_available():\n",
    "        free_gb, total_gb = torch.cuda.mem_get_info()\n",
    "        logger.info(f\"GPU Memory: {free_gb/1e9:.2f}GB / {total_gb/1e9:.2f}GB\")\n",
    "```\n",
    "\n",
    "**Usage**: Call between training different models to prevent OOM errors\n",
    "\n",
    "### Weights Export\n",
    "\n",
    "```python\n",
    "def create_weights_zip_for_download(models_dir, output_dir):\n",
    "    '''Create downloadable ZIP with trained model weights'''\n",
    "    \n",
    "    model_files = [\n",
    "        'vit_best.pth',\n",
    "        'resnet_best.pth',\n",
    "        'densenet_best.pth',\n",
    "        'xgboost_best.pkl',\n",
    "        'species_best.pth',\n",
    "        'metalearner_best.pth'\n",
    "    ]\n",
    "    \n",
    "    # Find available files\n",
    "    available = []\n",
    "    for file_name in model_files:\n",
    "        file_path = models_dir / file_name\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / 1024**2\n",
    "            available.append((file_name, size_mb))\n",
    "    \n",
    "    # Create ZIP\n",
    "    with zipfile.ZipFile(output_path, 'w') as z:\n",
    "        for file_name, _ in available:\n",
    "            z.write(models_dir / file_name, arcname=file_name)\n",
    "    \n",
    "    logger.info(f\"âœ“ ZIP created: {output_path}\")\n",
    "    logger.info(f\"  - Files: {len(available)}\")\n",
    "    logger.info(f\"  - Size: {total_size_mb:.1f}MB\")\n",
    "    \n",
    "    return output_path\n",
    "```\n",
    "\n",
    "**Output Files** (Typical ~500-1000 MB total):\n",
    "- vit_best.pth: ~200-250 MB\n",
    "- resnet_best.pth: ~100-150 MB\n",
    "- densenet_best.pth: ~80-120 MB\n",
    "- xgboost_best.pkl: ~1-5 MB\n",
    "- species_best.pth: ~200-250 MB\n",
    "- metalearner_best.pth: ~1-2 MB\n",
    "\n",
    "**Output**: \n",
    "- Memory cleanup utilities ready\n",
    "- Weights ZIP prepared\n",
    "- File ready for download/sharing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f91bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_train_df_matching_schema(\n",
    "    train_df, species_model, lookups_dict, raw_dir=RAW_DATA_DIR, device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic train dataframe with EXACT SAME structure as train_df.\n",
    "    \n",
    "    PRIORITY:\n",
    "      1) Use test_features_cache (dict with computed: ndvi, height, month, state, species)\n",
    "      2) Decode species_batch (integer index) if species not in cache\n",
    "      3) Fall back to original train_df values\n",
    "      4) Use safe defaults\n",
    "    \"\"\"\n",
    "    def _doy_to_date_str(doy, year=2015):\n",
    "        try:\n",
    "            doy_i = int(round(float(doy)))\n",
    "        except Exception:\n",
    "            doy_i = 180\n",
    "        doy_i = max(1, min(365, doy_i))\n",
    "        dt = datetime(year, 1, 1) + timedelta(days=doy_i - 1)\n",
    "        return dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    def _month_to_doy(month):\n",
    "        \"\"\"Map month (1-12) to representative DOY (day of year).\"\"\"\n",
    "        try:\n",
    "            m = int(round(float(month)))\n",
    "        except Exception:\n",
    "            m = None\n",
    "        \n",
    "        if m is None or not (1 <= m <= 12):\n",
    "            return None\n",
    "        \n",
    "        MONTH_TO_DOY = {\n",
    "            1: 16, 2: 47, 3: 75, 4: 106, 5: 136, 6: 167,\n",
    "            7: 197, 8: 228, 9: 259, 10: 289, 11: 320, 12: 350\n",
    "        }\n",
    "        return MONTH_TO_DOY[m]\n",
    "\n",
    "    # Build dataset in 'test' mode\n",
    "    dataset = BiomassDataset(\n",
    "        dataframe=train_df,\n",
    "        image_dir=raw_dir / 'train',\n",
    "        transform=None,\n",
    "        mode='test',\n",
    "        train_df=train_df,\n",
    "        lookups_dict=lookups_dict,\n",
    "        species_model=species_model,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc=\"Synthetic train generation\"):\n",
    "        # Get dataloader output\n",
    "        images, features, species_batch, target_idx_batch, targets_per_patch, sample_id, target_name = dataset[i]\n",
    "        \n",
    "        image_id = str(sample_id).split(\"__\")[0].lower()\n",
    "        original = train_df.iloc[i]\n",
    "\n",
    "        #use the cached dict computed by _intelligent_feature_fetch        \n",
    "        cached = dataset.test_features_cache.get(image_id, {}) if getattr(dataset, \"test_features_cache\", None) else {}\n",
    "        \n",
    "        logger.debug(f\"Row {i} | image_id: {image_id} | cached keys: {list(cached.keys()) if cached else 'empty'}\")\n",
    "\n",
    "\n",
    "        # Extract values from cache \n",
    "        # ==========================\n",
    "        ndvi_val = cached.get(\"ndvi\", None)\n",
    "        height_val = cached.get(\"height\", cached.get(\"estimated_height\", None))\n",
    "        month_val = cached.get(\"month\", None)\n",
    "        doy_val = cached.get(\"doy\", None)\n",
    "        quarter_val = cached.get(\"quarter\", None)\n",
    "        state_val = cached.get(\"state\", None)\n",
    "        species_val = cached.get(\"predicted_species\", None)\n",
    "\n",
    "        # NDVI: cache -> original train_df -> None\n",
    "        # =========================================\n",
    "        if ndvi_val is None:\n",
    "            ndvi_val = original.get(\"Pre_GSHH_NDVI\", None)\n",
    "\n",
    "        # HEIGHT: cache -> original train_df -> 7.6\n",
    "        # ==========================================\n",
    "        if height_val is None:\n",
    "            height_val = original.get(\"Height_Ave_cm\", None)\n",
    "        try:\n",
    "            if height_val is None or (isinstance(height_val, float) and np.isnan(height_val)):\n",
    "                height_val = float(original.get(\"Height_Ave_cm\", 7.6))\n",
    "        except Exception:\n",
    "            height_val = 7.6\n",
    "\n",
    "        # SPECIES: cache -> species_batch index -> original train_df -> map to fixed\n",
    "        # ============================================================================\n",
    "        if species_val is None:\n",
    "            # Try to decode species_batch (torch.LongTensor with integer index)\n",
    "            try:\n",
    "                if isinstance(species_batch, torch.Tensor):\n",
    "                    species_idx = int(species_batch.item())\n",
    "                else:\n",
    "                    species_idx = int(species_batch)\n",
    "                \n",
    "                # Use dataset's idx_to_species mapping\n",
    "                if hasattr(dataset, \"idx_to_species\") and dataset.idx_to_species:\n",
    "                    species_val = dataset.idx_to_species.get(species_idx, None)\n",
    "                elif hasattr(dataset, \"species_to_idx\") and dataset.species_to_idx:\n",
    "                    idx_to_species = {v: k for k, v in dataset.species_to_idx.items()}\n",
    "                    species_val = idx_to_species.get(species_idx, None)\n",
    "                \n",
    "                logger.debug(f\"Row {i}: Mapped species_batch[{species_idx}] â†’ {species_val}\")\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Row {i}: Failed to map species_batch: {e}\")\n",
    "                species_val = None\n",
    "        \n",
    "        # Fallback to original train_df\n",
    "        if species_val is None:\n",
    "            species_val = original.get(\"Species\", None)\n",
    "        \n",
    "        # FINAL: Map to fixed species using map_to_fixed_species()\n",
    "        species_val = map_to_fixed_species(species_val) if species_val else \"Mixed\"\n",
    "\n",
    "        # STATE: cache -> original train_df -> lookups -> 'Tas'\n",
    "        # =======================================================\\\n",
    "        if state_val is None:\n",
    "            state_val = original.get(\"State\", None)\n",
    "        \n",
    "        try:\n",
    "            if isinstance(state_val, str):\n",
    "                s = state_val.strip()\n",
    "                REVERSE_STATE_MAP_INV = {'tas': 'Tas', 'nsw': 'NSW', 'wa': 'WA', 'vic': 'Vic'}\n",
    "                key = s.lower()\n",
    "                if key in REVERSE_STATE_MAP_INV:\n",
    "                    state_val = REVERSE_STATE_MAP_INV[key]\n",
    "                else:\n",
    "                    unique_states = lookups_dict.get('UNIQUE_STATES', [])\n",
    "                    if unique_states:\n",
    "                        for u in unique_states:\n",
    "                            if key == str(u).strip().lower() or key in str(u).strip().lower():\n",
    "                                state_val = u\n",
    "                                break\n",
    "            if not state_val:\n",
    "                state_val = lookups_dict.get('UNIQUE_STATES', ['Tas'])[0]\n",
    "        except Exception:\n",
    "            state_val = lookups_dict.get('UNIQUE_STATES', ['Tas'])[0]\n",
    "\n",
    "        # DOY / MONTH: cache -> original Sampling_Date -> 180 (mid-year)\n",
    "        # ============================================================================\n",
    "        # Priority 1: Use cached DOY\n",
    "        if doy_val is not None:\n",
    "            try:\n",
    "                doy_val = int(round(float(doy_val)))\n",
    "                doy_val = max(1, min(365, doy_val))\n",
    "            except Exception:\n",
    "                doy_val = None\n",
    "\n",
    "        # Priority 2: Use cached month and convert to DOY\n",
    "        if doy_val is None and month_val is not None:\n",
    "            try:\n",
    "                month_val = int(round(float(month_val)))\n",
    "                doy_val = _month_to_doy(month_val)\n",
    "            except Exception:\n",
    "                doy_val = None\n",
    "\n",
    "        # Priority 3: Parse original Sampling_Date\n",
    "        if doy_val is None:\n",
    "            sd = original.get(\"Sampling_Date\", None)\n",
    "            if sd is not None:\n",
    "                try:\n",
    "                    dt = pd.to_datetime(sd, dayfirst=False, errors='coerce')\n",
    "                    if pd.notna(dt):\n",
    "                        doy_val = int(dt.dayofyear)\n",
    "                except Exception:\n",
    "                    doy_val = None\n",
    "\n",
    "        # Compute final Sampling_Date\n",
    "        if doy_val is not None:\n",
    "            sampling_date = _doy_to_date_str(doy_val, year=2015)\n",
    "        else:\n",
    "            # Last resort: use original or mid-year default\n",
    "            sampling_date = original.get(\"Sampling_Date\", None)\n",
    "            if sampling_date is None or (isinstance(sampling_date, float) and np.isnan(sampling_date)):\n",
    "                sampling_date = _doy_to_date_str(180, year=2015)\n",
    "\n",
    "        # Build final row\n",
    "        row = {\n",
    "            \"sample_id\": original[\"sample_id\"],\n",
    "            \"image_path\": original[\"image_path\"],\n",
    "            \"Sampling_Date\": sampling_date,\n",
    "            \"State\": state_val,\n",
    "            \"Species\": species_val,\n",
    "            \"Pre_GSHH_NDVI\": ndvi_val,\n",
    "            \"Height_Ave_cm\": height_val,\n",
    "            \"target_name\": original[\"target_name\"],\n",
    "            \"target\": float(original[\"target\"]),\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    out_df = pd.DataFrame(rows)\n",
    "\n",
    "    try:\n",
    "        out_df = out_df[train_df.columns]\n",
    "    except Exception:\n",
    "        logger.warning(\"Generated synthetic DF columns differ from original train_df; returning generated column order\")\n",
    "\n",
    "    # Save to disk\n",
    "    out_path = OUTPUTS_DIR / 'train_synthetic_matching.csv'\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    logger.info(f\"Saved â†’ {out_path}\")\n",
    "    return out_df\n",
    "\n",
    "def _normalize_state_for_onehot(raw_state):\n",
    "    \"\"\"\n",
    "    Return canonical State string exactly as used by the one-hot columns.\n",
    "    E.g. 'Tas','NSW','Vic','WA' or '' for missing. Adjust to match training data.\n",
    "    \"\"\"\n",
    "    if raw_state is None:\n",
    "        return ''\n",
    "    s = str(raw_state).strip()\n",
    "    mappings = {\n",
    "        'tasmania': 'Tas',\n",
    "        'tas': 'Tas',\n",
    "        'new south wales': 'NSW',\n",
    "        'nsw': 'NSW',\n",
    "        'western australia': 'WA',\n",
    "        'wa': 'WA',\n",
    "        'victoria': 'Vic',\n",
    "        'vic': 'Vic'\n",
    "    }\n",
    "    low = s.lower()\n",
    "    for k,v in mappings.items():\n",
    "        if low == k:\n",
    "            return v\n",
    "    if len(s) <= 3:\n",
    "        return s.upper()\n",
    "    return s.title()\n",
    "\n",
    "def diagnose_submission(test_data, test_df=None, meta_learner=None, device=None,\n",
    "                        run_inference=False, batch_size_gpu=1024, batch_size_cpu=256,\n",
    "                        float_format=\"%.4f\"):\n",
    "    \"\"\"\n",
    "    Diagnostic checks for submission creation. Uses logger.info to print checks.\n",
    "    Returns a dict of diagnostics.\n",
    "    \n",
    "    Args:\n",
    "        test_data: dict produced by get_base_model_predictions (must contain\n",
    "                   'base_predictions', 'tabular', 'sample_ids' at minimum)\n",
    "        test_df: optional official test DataFrame (with 'sample_id' column) for comparison\n",
    "        meta_learner: optional trained model (will run inference if run_inference=True)\n",
    "        device: torch device or None\n",
    "        run_inference: bool - whether to run meta_learner inference to validate predictions\n",
    "        batch_size_gpu / batch_size_cpu: inference batch sizes for fallback\n",
    "    \"\"\"\n",
    "    diag = {\n",
    "        \"ok\": True,\n",
    "        \"errors\": [],\n",
    "        \"warnings\": [],\n",
    "        \"notes\": {},\n",
    "    }\n",
    "\n",
    "    # Basic presence checks\n",
    "    required_keys = (\"base_predictions\", \"tabular\", \"sample_ids\")\n",
    "    for k in required_keys:\n",
    "        if (test_data is None) or (k not in test_data):\n",
    "            msg = f\"Missing required key in test_data: {k}\"\n",
    "            logger.error(msg)\n",
    "            diag[\"errors\"].append(msg)\n",
    "            diag[\"ok\"] = False\n",
    "    if not diag[\"ok\"]:\n",
    "        return diag\n",
    "\n",
    "    # Convert arrays/lists safely\n",
    "    try:\n",
    "        base_preds = np.asarray(test_data[\"base_predictions\"])\n",
    "        tabular = np.asarray(test_data[\"tabular\"])\n",
    "        sample_ids = [str(s).strip() for s in test_data[\"sample_ids\"]]\n",
    "    except Exception as e:\n",
    "        msg = f\"Error converting test_data arrays -> {e}\"\n",
    "        logger.error(msg)\n",
    "        diag[\"errors\"].append(msg)\n",
    "        diag[\"ok\"] = False\n",
    "        return diag\n",
    "\n",
    "    logger.info(\"DIAG: shapes: base_predictions=%s, tabular=%s, sample_ids=%d\",\n",
    "                getattr(base_preds, \"shape\", None),\n",
    "                getattr(tabular, \"shape\", None),\n",
    "                len(sample_ids))\n",
    "\n",
    "    # Row-count consistency\n",
    "    n_preds = base_preds.shape[0] if hasattr(base_preds, \"shape\") else -1\n",
    "    n_tab = tabular.shape[0] if hasattr(tabular, \"shape\") else -1\n",
    "    n_ids = len(sample_ids)\n",
    "    logger.info(\"DIAG: rows => preds=%d, tabular=%d, sample_ids=%d\", n_preds, n_tab, n_ids)\n",
    "\n",
    "    if n_preds != n_tab:\n",
    "        w = f\"Row mismatch: base_predictions rows ({n_preds}) != tabular rows ({n_tab})\"\n",
    "        logger.warning(\"DIAG WARNING: %s\", w)\n",
    "        diag[\"warnings\"].append(w)\n",
    "\n",
    "    if n_preds != n_ids:\n",
    "        e = f\"Row mismatch: base_predictions rows ({n_preds}) != sample_ids ({n_ids})\"\n",
    "        logger.error(\"DIAG ERROR: %s\", e)\n",
    "        diag[\"errors\"].append(e)\n",
    "        diag[\"ok\"] = False\n",
    "\n",
    "    # Check for NaNs / inf / negative values in base preds\n",
    "    try:\n",
    "        preds_flat = base_preds.astype(np.float64).ravel()\n",
    "        n_nan = int(np.isnan(preds_flat).sum())\n",
    "        n_inf = int(np.isinf(preds_flat).sum())\n",
    "        n_neg = int((preds_flat < 0.0).sum())\n",
    "        logger.info(\"DIAG: base_predictions NaN=%d, Inf=%d, negative=%d\", n_nan, n_inf, n_neg)\n",
    "        diag[\"notes\"][\"pred_nan\"] = n_nan\n",
    "        diag[\"notes\"][\"pred_inf\"] = n_inf\n",
    "        diag[\"notes\"][\"pred_neg\"] = n_neg\n",
    "        if n_nan > 0 or n_inf > 0:\n",
    "            diag[\"warnings\"].append(\"base_predictions contains NaN or Inf values.\")\n",
    "        if n_neg > 0:\n",
    "            diag[\"warnings\"].append(\"base_predictions contains negative values (will be clipped in submission).\")\n",
    "    except Exception as e:\n",
    "        logger.warning(\"DIAG: could not inspect base_predictions numerics: %s\", e)\n",
    "        diag[\"warnings\"].append(f\"could not inspect base_predictions numerics: {e}\")\n",
    "\n",
    "    # Check tabular NaNs / shape\n",
    "    try:\n",
    "        n_nan_tab = int(np.isnan(tabular).sum())\n",
    "        logger.info(\"DIAG: tabular total NaNs=%d\", n_nan_tab)\n",
    "        diag[\"notes\"][\"tab_nan\"] = n_nan_tab\n",
    "        if n_nan_tab > 0:\n",
    "            diag[\"warnings\"].append(\"tabular contains NaNs\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Check sample_id uniqueness and ordering\n",
    "    try:\n",
    "        unique_ids = set(sample_ids)\n",
    "        n_unique = len(unique_ids)\n",
    "        logger.info(\"DIAG: sample_ids unique=%d / total=%d\", n_unique, n_ids)\n",
    "        if n_unique != n_ids:\n",
    "            logger.warning(\"DIAG WARNING: sample_ids are not unique (duplicates present).\")\n",
    "            # show example duplicates (up to 10)\n",
    "            from collections import Counter\n",
    "            c = Counter(sample_ids)\n",
    "            dups = [k for k, v in c.items() if v > 1][:10]\n",
    "            logger.info(\"DIAG: example duplicate ids (up to 10): %s\", dups)\n",
    "            diag[\"notes\"][\"sample_dup_examples\"] = dups\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Lexicographic sort check and compare to official test_df if provided\n",
    "    try:\n",
    "        sorted_sample_ids = sorted(sample_ids)\n",
    "        logger.info(\"DIAG: first 5 sample_ids (original): %s\", sample_ids[:5])\n",
    "        logger.info(\"DIAG: first 5 sample_ids (sorted):   %s\", sorted_sample_ids[:5])\n",
    "        if test_df is not None and \"sample_id\" in test_df.columns:\n",
    "            official_ids = test_df[\"sample_id\"].astype(str).tolist()\n",
    "            logger.info(\"DIAG: official test_df sample_id count=%d\", len(official_ids))\n",
    "            if len(official_ids) != len(sorted_sample_ids):\n",
    "                logger.warning(\"DIAG WARNING: official test_df length differs from submission candidate.\")\n",
    "                diag[\"warnings\"].append(\"official test_df length differs\")\n",
    "            set_sub = set(sorted_sample_ids)\n",
    "            set_off = set(official_ids)\n",
    "            missing = sorted(list(set_off - set_sub))[:10]\n",
    "            extra = sorted(list(set_sub - set_off))[:10]\n",
    "            if missing:\n",
    "                logger.error(\"DIAG ERROR: missing ids (up to 10): %s\", missing)\n",
    "                diag[\"errors\"].append(f\"missing_ids_example={missing}\")\n",
    "                diag[\"ok\"] = False\n",
    "            if extra:\n",
    "                logger.error(\"DIAG ERROR: extra ids (up to 10): %s\", extra)\n",
    "                diag[\"errors\"].append(f\"extra_ids_example={extra}\")\n",
    "                diag[\"ok\"] = False\n",
    "            if not missing and not extra:\n",
    "                logger.info(\"DIAG: sorted submission sample_ids match official test_df (set-wise).\")\n",
    "    except Exception as e:\n",
    "        logger.warning(\"DIAG: lexicographic checks failed: %s\", e)\n",
    "\n",
    "    # If requested run_inference = True -> run meta_learner to produce final_predictions and validate length/NaN\n",
    "    if run_inference:\n",
    "        if meta_learner is None:\n",
    "            msg = \"run_inference=True but no meta_learner provided â€” skipping inference.\"\n",
    "            logger.warning(\"DIAG: %s\", msg)\n",
    "            diag[\"warnings\"].append(msg)\n",
    "        else:\n",
    "            try:\n",
    "                # assume run_inference_in_batches available in scope\n",
    "                preds = run_inference_in_batches(meta_learner, base_preds, tabular, device=device, batch_size=batch_size_gpu)\n",
    "                preds = np.asarray(preds).ravel()\n",
    "                logger.info(\"DIAG: meta_learner produced %d predictions\", preds.shape[0])\n",
    "                if preds.shape[0] != n_ids:\n",
    "                    msg = f\"Prediction length ({preds.shape[0]}) != sample_ids ({n_ids})\"\n",
    "                    logger.error(\"DIAG ERROR: %s\", msg)\n",
    "                    diag[\"errors\"].append(msg)\n",
    "                    diag[\"ok\"] = False\n",
    "                # numeric checks\n",
    "                n_nan_p = int(np.isnan(preds).sum())\n",
    "                n_neg_p = int((preds < 0.0).sum())\n",
    "                logger.info(\"DIAG: final preds NaN=%d, negative=%d\", n_nan_p, n_neg_p)\n",
    "                diag[\"notes\"][\"final_pred_nan\"] = n_nan_p\n",
    "                diag[\"notes\"][\"final_pred_neg\"] = n_neg_p\n",
    "                if n_nan_p > 0:\n",
    "                    diag[\"warnings\"].append(\"final predictions contain NaN\")\n",
    "            except Exception as e:\n",
    "                logger.exception(\"DIAG: inference run failed: %s\", e)\n",
    "                diag[\"errors\"].append(f\"inference_failed: {e}\")\n",
    "                diag[\"ok\"] = False\n",
    "\n",
    "    # Final summary\n",
    "    if diag[\"ok\"]:\n",
    "        logger.info(\"DIAG: All checks passed (ok=True).\")\n",
    "    else:\n",
    "        logger.error(\"DIAG: Some checks failed. See diag['errors'] and logs for details.\")\n",
    "\n",
    "    return diag\n",
    "\n",
    "\n",
    "def diagnose_ensemble_batch(data_loader, num_patches=8):\n",
    "    \"\"\"\n",
    "    Run a single-batch diagnostic for ensemble pipeline.\n",
    "    This avoids spamming logs during full inference.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"ðŸ” ENSEMBLE PIPELINE DIAGNOSTICS (ONE BATCH)\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    batch = next(iter(data_loader))\n",
    "\n",
    "    # Robust unpack: new collate returns:\n",
    "    # - with targets: (images, tabular, species_batch, targets_batch, sample_ids, target_names) -> len==6\n",
    "    # - without targets: (images, tabular, species_batch, sample_ids, target_names) -> len==5\n",
    "    if isinstance(batch, (tuple, list)):\n",
    "        ln = len(batch)\n",
    "    else:\n",
    "        ln = 0\n",
    "\n",
    "    if ln == 7:\n",
    "        images, tabular, species_batch, target_idx_batch, targets, sample_ids, target_names = batch\n",
    "    elif ln == 5:\n",
    "        images, tabular, species_batch, sample_ids, target_names = batch\n",
    "        targets = None\n",
    "    else:\n",
    "        # best-effort fallback (older/different signatures)\n",
    "        try:\n",
    "            # try to find sample_ids in last two items\n",
    "            if ln >= 2:\n",
    "                sample_ids = batch[-2]\n",
    "                target_names = batch[-1]\n",
    "            else:\n",
    "                sample_ids = []\n",
    "                target_names = []\n",
    "            images = batch[0] if ln > 0 else None\n",
    "            tabular = batch[1] if ln > 1 else None\n",
    "        except Exception:\n",
    "            logger.warning(\"diagnose_ensemble_batch: unexpected batch signature; aborting\")\n",
    "            return\n",
    "\n",
    "    # ensure lists of strs\n",
    "    try:\n",
    "        sample_ids = [str(s) for s in sample_ids]\n",
    "    except Exception:\n",
    "        sample_ids = list(sample_ids)\n",
    "\n",
    "    try:\n",
    "        target_names = [str(t) for t in target_names]\n",
    "    except Exception:\n",
    "        target_names = list(target_names)\n",
    "\n",
    "    total_patches = images.shape[0]\n",
    "    unique_ids = list(dict.fromkeys(sample_ids))\n",
    "    num_images = len(unique_ids)\n",
    "\n",
    "    logger.info(f\"Total patches:        {total_patches}\")\n",
    "    logger.info(f\"Unique images:        {num_images}\")\n",
    "    logger.info(f\"Expected patches/img: {num_patches}\")\n",
    "\n",
    "    # Check grouping\n",
    "    grouped_ids = get_unique_sample_id(sample_ids, patches_per_image=num_patches)\n",
    "    logger.info(f\"Grouped sample_ids:   {grouped_ids}\")\n",
    "    logger.info(f\"Grouped len:          {len(grouped_ids)}\")\n",
    "\n",
    "    # Patch grouping check\n",
    "    rep_ok = all(sample_ids.count(uid) == num_patches for uid in unique_ids)\n",
    "    if rep_ok:\n",
    "        logger.info(\"âœ“ Perfect patch repetition detected per image\")\n",
    "    else:\n",
    "        logger.warning(\"âš  Patch repetition inconsistent!\")\n",
    "\n",
    "    # Target name grouping (take first of each image block)\n",
    "    tn_grouped = []\n",
    "    for i in range(0, total_patches, num_patches):\n",
    "        if i < len(target_names):\n",
    "            tn_grouped.append(target_names[i])\n",
    "    logger.info(f\"Grouped target_names: {tn_grouped}\")\n",
    "\n",
    "    # shapes\n",
    "    logger.info(f\"images.shape:   {images.shape}\")\n",
    "    logger.info(f\"tabular.shape:  {tabular.shape}\")\n",
    "    if targets is not None:\n",
    "        logger.info(f\"targets.shape:  {targets.shape}\")\n",
    "\n",
    "    logger.info(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "def run_dataloader_diagnostics(data_loader, num_patches=8, device=device):\n",
    "    \"\"\"\n",
    "    Runs a single-batch diagnostic on the dataloader to ensure that\n",
    "    sample_ids, patch grouping, and shapes match the expected pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"ðŸ” RUNNING DATA LOADER DIAGNOSTICS\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    batch = next(iter(data_loader))\n",
    "    logger.info(\"âœ“ Pulled one batch from loader\")\n",
    "\n",
    "    # Robust unpacking - handle new collate return signatures\n",
    "    if isinstance(batch, (tuple, list)):\n",
    "        ln = len(batch)\n",
    "    else:\n",
    "        ln = 0\n",
    "\n",
    "    if ln == 6:\n",
    "        images, tabular, species_batch, targets, sample_ids, target_names = batch\n",
    "    elif ln == 5:\n",
    "        images, tabular, species_batch, sample_ids, target_names = batch\n",
    "        targets = None\n",
    "    else:\n",
    "        # fallback best-effort\n",
    "        try:\n",
    "            images = batch[0] if ln > 0 else None\n",
    "            tabular = batch[1] if ln > 1 else None\n",
    "            sample_ids = batch[-2] if ln >= 2 else []\n",
    "            target_names = batch[-1] if ln >= 1 else []\n",
    "            targets = None\n",
    "        except Exception:\n",
    "            logger.warning(\"run_dataloader_diagnostics: unexpected batch signature; aborting\")\n",
    "            return\n",
    "\n",
    "    # Convert to lists\n",
    "    try:\n",
    "        sample_ids_list = [str(s) for s in sample_ids]\n",
    "    except Exception:\n",
    "        sample_ids_list = list(sample_ids)\n",
    "\n",
    "    # Basic counts\n",
    "    total_patches = images.shape[0]\n",
    "    unique_ids = list(dict.fromkeys(sample_ids_list))\n",
    "    num_unique = len(unique_ids)\n",
    "\n",
    "    logger.info(f\"Total patches in batch      : {total_patches}\")\n",
    "    logger.info(f\"Unique sample_ids           : {num_unique}\")\n",
    "    logger.info(f\"Unique IDs (first 10)       : {unique_ids[:10]}\")\n",
    "\n",
    "    # Infer patches per image\n",
    "    inferred_ppr = None\n",
    "    if num_unique > 0:\n",
    "        inferred_ppr = total_patches // num_unique\n",
    "\n",
    "    logger.info(f\"Inferred patches_per_image  : {inferred_ppr}\")\n",
    "    logger.info(f\"Expected patches_per_image  : {num_patches}\")\n",
    "\n",
    "    # Check repetition pattern\n",
    "    rep_ok = True\n",
    "    for img_id in unique_ids:\n",
    "        count = sample_ids_list.count(img_id)\n",
    "        if count != num_patches:\n",
    "            rep_ok = False\n",
    "            break\n",
    "\n",
    "    if rep_ok:\n",
    "        logger.info(\"âœ“ Repetition pattern OK â€” each sample_id appears exactly num_patches times.\")\n",
    "    else:\n",
    "        logger.warning(\"âš  WARNING: Some sample_ids do NOT appear exactly num_patches times!\")\n",
    "\n",
    "    # Test grouping using your function\n",
    "    grouped_ids = get_unique_sample_id(sample_ids_list, patches_per_image=num_patches)\n",
    "    logger.info(f\"Sample IDs after grouping   : {grouped_ids[:10]}\")\n",
    "    logger.info(f\"Grouped count (num images)  : {len(grouped_ids)}\")\n",
    "\n",
    "    # Validate shapes of images/tabular/targets\n",
    "    logger.info(f\"images.shape                : {images.shape}\")\n",
    "    logger.info(f\"tabular.shape               : {tabular.shape}\")\n",
    "    if targets is not None:\n",
    "        logger.info(f\"targets.shape               : {targets.shape}\")\n",
    "\n",
    "    # Check if reshaping will be valid\n",
    "    if num_unique > 0 and (total_patches % num_unique == 0):\n",
    "        logger.info(\"âœ“ Patch counts allow clean reshape to (num_images, num_patches)\")\n",
    "    else:\n",
    "        logger.warning(\"âš  Patch count NOT divisible by number of unique IDs â€” fallback grouping required!\")\n",
    "\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"Diagnostic complete.\\n\")\n",
    "\n",
    "\n",
    "def cleanup_memory(model=None):\n",
    "    \"\"\"Aggressive GPU memory cleanup\"\"\"\n",
    "    \n",
    "    if model is not None:\n",
    "        try:\n",
    "            model = model.cpu()  \n",
    "            logger.debug(f\"âœ“ Model moved to CPU\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš  Error moving model to CPU: {e}\")\n",
    "        del model\n",
    "    # Clear caches\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    # Log freed memory\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            free_gb, total_gb = torch.cuda.mem_get_info()\n",
    "            free_gb = free_gb / 1e9\n",
    "            total_gb = total_gb / 1e9\n",
    "            logger.info(f\"âœ“ GPU Memory: {free_gb:.2f}GB / {total_gb:.2f}GB free\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "def get_default_device():\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "def create_weights_zip_for_download_flexible(models_dir, output_dir, zip_name='trained_weights.zip'):\n",
    "    \"\"\"\n",
    "    Create zip file with ONLY AVAILABLE weights.\n",
    "    Skip missing files - you can add them later by re-running this function.\n",
    "    Args:\n",
    "        models_dir (Path): Directory containing trained model files\n",
    "        output_dir (Path): Directory where zip file will be saved\n",
    "        zip_name (str): Name of the zip file\n",
    "    Returns:\n",
    "        Path: Path to created zip file, or None if no files found\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(\"CREATING WEIGHTS ZIP FILE FOR DOWNLOAD\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    models_dir = Path(models_dir)\n",
    "    output_dir = Path('/kaggle/working')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    zip_path = output_dir / zip_name\n",
    "    \n",
    "    # Model files to include \n",
    "    model_files = [\n",
    "        ('vit_best.pth', 'Vision Transformer (ViT-Base)'),\n",
    "        ('resnet_best.pth', 'ResNet-50'),\n",
    "        ('densenet_best.pth', 'DenseNet-121'),\n",
    "        ('xgboost_best.pkl', 'XGBoost'),\n",
    "        ('species_best.pth', 'Species Model'),\n",
    "        ('metalearner_best.pth', 'Meta-Learner')\n",
    "    ]\n",
    "    logger.info(f\"\\nScanning for model files in: {models_dir}\")\n",
    "    \n",
    "    # Find available files\n",
    "    available_files = []\n",
    "    missing_files = []\n",
    "    total_available_size = 0\n",
    "    \n",
    "    for file_name, description in model_files:\n",
    "        file_path = models_dir / file_name\n",
    "        if file_path.exists():\n",
    "            file_size = file_path.stat().st_size / (1024**2)\n",
    "            logger.info(f\"âœ“ Found: {file_name} ({file_size:.2f} MB) - {description}\")\n",
    "            available_files.append((file_name, file_path, description))\n",
    "            total_available_size += file_size\n",
    "        else:\n",
    "            logger.warning(f\"âš  Missing: {file_name} - {description}\")\n",
    "            missing_files.append(file_name)\n",
    "\n",
    "    # Check if any files available   \n",
    "    if not available_files:\n",
    "        logger.error(\"âœ— No model files found!\")\n",
    "        logger.error(f\"  Searched in: {models_dir}\")\n",
    "        logger.error(\"  Please save model files to this directory first.\")\n",
    "        return None\n",
    "    \n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(f\"AVAILABLE: {len(available_files)}/{len(model_files)} models ({total_available_size:.2f} MB)\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        logger.warning(f\"\\nMissing {len(missing_files)} file(s) (will add when ready):\")\n",
    "        for file_name in missing_files:\n",
    "            logger.warning(f\"  - {file_name}\")\n",
    "    \n",
    "    # Create zip with available files\n",
    "    logger.info(f\"\\nCreating zip file: {zip_path}\")\n",
    "    \n",
    "    try:\n",
    "        # âœ“ If zip already exists, remove it \n",
    "        if zip_path.exists():\n",
    "            logger.info(f\"  Removing old zip file: {zip_path}\")\n",
    "            zip_path.unlink()\n",
    "        \n",
    "        # Create zip with available files\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for file_name, file_path, description in available_files:\n",
    "                zipf.write(file_path, arcname=file_name)\n",
    "                logger.info(f\"  âœ“ Added {file_name}\")\n",
    "        \n",
    "        # Verify zip creation\n",
    "        zip_size = zip_path.stat().st_size / (1024**2)\n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"âœ“ ZIP FILE CREATED SUCCESSFULLY!\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "        logger.info(f\"\\nZip file: {zip_path}\")\n",
    "        logger.info(f\"Size: {zip_size:.2f} MB\")\n",
    "        logger.info(f\"Contains: {len(available_files)} model(s)\")\n",
    "        \n",
    "        # List zip contents\n",
    "        logger.info(f\"\\nZip contents:\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "            for info in zipf.filelist:\n",
    "                size_mb = info.file_size / (1024**2)\n",
    "                logger.info(f\"  - {info.filename} ({size_mb:.2f} MB)\")\n",
    "        \n",
    "        # Show next steps\n",
    "        if missing_files:\n",
    "            logger.warning(f\"\\n{'='*80}\")\n",
    "            logger.warning(\"âš  NEXT STEPS:\")\n",
    "            logger.warning(f\"{'='*80}\")\n",
    "            logger.warning(f\"\\nStill missing {len(missing_files)} file(s):\")\n",
    "            for file_name in missing_files:\n",
    "                logger.warning(f\"  - {file_name}\")\n",
    "            logger.warning(f\"\\nOnce you have these files, re-run this function to update the zip!\")\n",
    "            logger.warning(f\"The zip will be automatically recreated with all available files.\")\n",
    "        \n",
    "        return zip_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âœ— Error creating zip file: {e}\")\n",
    "        import traceback\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def copy_weights_to_output_for_download(models_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Copy all AVAILABLE weights to /kaggle/output directory for easy download.\n",
    "    Skips missing files.\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(\"COPYING AVAILABLE WEIGHTS TO OUTPUT DIRECTORY\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    models_dir = Path(models_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    model_files = [\n",
    "        'vit_best.pth',\n",
    "        'resnet_best.pth',\n",
    "        'densenet_best.pth',\n",
    "        'xgboost_best.pkl',\n",
    "        'metalearner_best.pth',\n",
    "        'species_best.pth'\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"Copying weights to: {output_dir}\")\n",
    "    \n",
    "    copied_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    for file_name in model_files:\n",
    "        src = models_dir / file_name\n",
    "        dst = output_dir / file_name\n",
    "        \n",
    "        if src.exists():\n",
    "            shutil.copy(src, dst)\n",
    "            file_size = dst.stat().st_size / (1024**2)\n",
    "            logger.info(f\"âœ“ Copied {file_name} ({file_size:.2f} MB)\")\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            logger.warning(f\"âš  Skipping (not found): {file_name}\")\n",
    "            missing_count += 1\n",
    "    \n",
    "    logger.info(f\"\\nâœ“ Copied {copied_count} file(s) to /kaggle/output/\")\n",
    "    if missing_count > 0:\n",
    "        logger.warning(f\"âš  Skipped {missing_count} missing file(s)\")\n",
    "    logger.info(\"  You can download them from Kaggle UI\")\n",
    "    \n",
    "    return output_dir, copied_count, missing_count\n",
    "\n",
    "def create_weights_manifest(models_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Create a JSON manifest describing available weights.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    manifest = {\n",
    "        'created': str(datetime.now()),\n",
    "        'models': {},\n",
    "        'total_size_mb': 0,\n",
    "        'status': 'partial'\n",
    "    }\n",
    "    \n",
    "    model_files = [\n",
    "        ('vit_best.pth', 'Vision Transformer (ViT-Base) - ImageNet pretrained'),\n",
    "        ('resnet_best.pth', 'ResNet-50 - ImageNet pretrained'),\n",
    "        ('densenet_best.pth', 'DenseNet-121 - ImageNet pretrained'),\n",
    "        ('xgboost_best.pkl', 'XGBoost - Trained on NDVI + height (5 models)'),\n",
    "        ('metalearner_best.pth', 'Meta-Learner - Trained on base predictions'),\n",
    "        ('species_best.pth', 'Species Prediction Model')\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    models_dir = Path(models_dir)\n",
    "    \n",
    "    available_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    for file_name, description in model_files:\n",
    "        file_path = models_dir / file_name\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / (1024**2)\n",
    "            manifest['models'][file_name] = {\n",
    "                'description': description,\n",
    "                'size_mb': round(size_mb, 2),\n",
    "                'format': 'PyTorch (.pth)' if file_name.endswith('.pth') else 'Pickle (.pkl)',\n",
    "                'status': 'available'\n",
    "            }\n",
    "            manifest['total_size_mb'] += size_mb\n",
    "            available_count += 1\n",
    "        else:\n",
    "            manifest['models'][file_name] = {\n",
    "                'description': description,\n",
    "                'status': 'missing (will be added later)'\n",
    "            }\n",
    "            missing_count += 1\n",
    "    \n",
    "    manifest['total_size_mb'] = round(manifest['total_size_mb'], 2)\n",
    "    manifest['summary'] = f\"{available_count}/{len(model_files)} models available\"\n",
    "    \n",
    "    # Update status\n",
    "    if missing_count == 0:\n",
    "        manifest['status'] = 'complete'\n",
    "    elif available_count > 0:\n",
    "        manifest['status'] = 'partial'\n",
    "    else:\n",
    "        manifest['status'] = 'empty'\n",
    "    \n",
    "    # Save manifest\n",
    "    manifest_path = output_dir / 'manifest.json'\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"âœ“ Manifest created: {manifest_path}\")\n",
    "    return manifest\n",
    "\n",
    "def prepare_and_download_weights(models_dir=None, output_dir=None):\n",
    "    \"\"\"\n",
    "    Complete workflow to prepare weights for download.\n",
    "    \n",
    "    Handles:\n",
    "    - Missing files (skips them)\n",
    "    - Partial zips (creates with available files)\n",
    "    - Future additions (re-run to update zip)\n",
    "    \n",
    "    Args:\n",
    "        models_dir (Path): Directory with trained weights\n",
    "        output_dir (Path): Directory for output files\n",
    "    \"\"\"\n",
    "    if models_dir is None:\n",
    "        models_dir = Path('/kaggle/working/models')\n",
    "    if output_dir is None:\n",
    "        output_dir = Path('/kaggle/output')\n",
    "    \n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"PREPARING WEIGHTS FOR DOWNLOAD (FLEXIBLE MODE)\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"\\nThis will:\")\n",
    "    logger.info(\"  âœ“ Create zip with AVAILABLE files\")\n",
    "    logger.info(\"  âœ“ Skip missing files\")\n",
    "    logger.info(\"  âœ“ Can be re-run to add new files\")\n",
    "    \n",
    "    # Step 1: Create manifest\n",
    "    logger.info(\"\\n[Step 1/3] Creating manifest...\")\n",
    "    manifest = create_weights_manifest(models_dir, output_dir)\n",
    "    \n",
    "    # Step 2: Copy to output\n",
    "    logger.info(\"\\n[Step 2/3] Copying weights to output...\")\n",
    "    output_dir_result, copied, missing = copy_weights_to_output_for_download(models_dir, output_dir)\n",
    "    \n",
    "    # Step 3: Create zip file\n",
    "    logger.info(\"\\n[Step 3/3] Creating zip file...\")\n",
    "    zip_path = create_weights_zip_for_download_flexible(models_dir, output_dir)\n",
    "    \n",
    "    # Final summary\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"âœ“ DOWNLOAD PREPARATION COMPLETE!\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"\\nFiles ready in {output_dir}:\")\n",
    "    logger.info(f\"  - manifest.json (metadata)\")\n",
    "    \n",
    "    if copied > 0:\n",
    "        logger.info(f\"  - {copied} model file(s) ready for download\")\n",
    "    \n",
    "    if zip_path:\n",
    "        logger.info(f\"  - trained_weights.zip ({copied} models)\")\n",
    "    \n",
    "    if missing > 0:\n",
    "        logger.warning(f\"\\nâš  Note: {missing} model(s) still missing\")\n",
    "    create_file()\n",
    "    \n",
    "    return zip_path\n",
    "    \n",
    "def offload_model_to_disk(model, model_name, save_dir):\n",
    "    \"\"\"\n",
    "    Save model to disk and move to CPU to free GPU memory.\n",
    "    Args:\n",
    "        model: PyTorch model on GPU\n",
    "        model_name: Name for checkpoint (e.g., 'vit', 'resnet')\n",
    "        save_dir: Directory to save checkpoint\n",
    "    \n",
    "    Returns:\n",
    "        Path to saved checkpoint\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Move model to CPU\n",
    "    model = model.cpu()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    checkpoint_path = save_dir / f'{model_name}_best.pth'\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    file_size_mb = checkpoint_path.stat().st_size / (1024**2)\n",
    "    logger.info(f\"âœ“ Saved {model_name} to disk ({file_size_mb:.2f} MB)\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "    cleanup_memory()\n",
    "    \n",
    "    return checkpoint_path\n",
    "\n",
    "# INTERNET CONNECTIVITY CHECK\n",
    "def check_internet_connection(timeout=5):\n",
    "    \"\"\"\n",
    "    Check if internet connection is available.\n",
    "    \n",
    "    Args:\n",
    "        timeout (int): Timeout in seconds\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if internet available, False otherwise\n",
    "    \"\"\"\n",
    "    import socket\n",
    "    \n",
    "    try:\n",
    "        # Try to connect to Google DNS \n",
    "        socket.create_connection((\"8.8.8.8\", 53), timeout=timeout)\n",
    "        logger.info(\"âœ“ Internet connection detected\")\n",
    "        return True\n",
    "    except (socket.timeout, socket.error):\n",
    "        logger.warning(\"âš  No internet connection detected\")\n",
    "        return False\n",
    "\n",
    "def verify_pretrained_weights_exist(weights_dir):\n",
    "    \"\"\"\n",
    "    Verify all required pretrained weights are cached locally.\n",
    "    \n",
    "    Args:\n",
    "        weights_dir (Path): Directory with cached weights\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if all weights exist, False otherwise\n",
    "    \"\"\"\n",
    "    weights_dir = Path(weights_dir)\n",
    "    required_weights = {\n",
    "        'vit': weights_dir / 'vit_best.pth',\n",
    "        'resnet': weights_dir / 'resnet_best.pth',\n",
    "        'densenet': weights_dir / 'densenet_best.pth', \n",
    "        'species': weights_dir / 'species_best.pth'\n",
    "    }\n",
    "    \n",
    "    logger.info(\"\\nVerifying cached pretrained weights...\")\n",
    "    all_exist = True\n",
    "    \n",
    "    for model_name, weight_path in required_weights.items():\n",
    "        if weight_path.exists():\n",
    "            size_mb = weight_path.stat().st_size / (1024**2)\n",
    "            logger.info(f\"  âœ“ {model_name}: {size_mb:.2f} MB\")\n",
    "        else:\n",
    "            logger.warning(f\"  âœ— {model_name}: NOT FOUND\")\n",
    "            all_exist = False\n",
    "    \n",
    "    return all_exist\n",
    "\n",
    "def load_from_offline_dataset(offline_path, model_name):\n",
    "    \"\"\"\n",
    "    Load pretrained/fine-tuned weights from offline Kaggle dataset.\n",
    "    \n",
    "    UPDATED: Now includes species model support!\n",
    "    \n",
    "    Checks for BOTH _best.pth (fine-tuned) AND _pretrained.pth (ImageNet)\n",
    "    \n",
    "    Priority:\n",
    "    1. _best.pth (fine-tuned models from previous run)\n",
    "    2. _pretrained.pth (ImageNet pretrained)\n",
    "    3. Return None if neither found\n",
    "    \n",
    "    Args:\n",
    "        offline_path (Path): Path to offline dataset\n",
    "        model_name (str): Model identifier ('vit', 'resnet', 'densenet', 'species', 'xgboost', 'metalearner')\n",
    "    \n",
    "    Returns:\n",
    "        Path: Path to weights file if exists, None otherwise\n",
    "    \"\"\"\n",
    "    offline_path = Path(offline_path)\n",
    "    \n",
    "    # Priority 1: Try _best.pth (fine-tuned models) \n",
    "    weight_file_best = offline_path / f'{model_name}_best.pth'\n",
    "    if weight_file_best.exists():\n",
    "        size_mb = weight_file_best.stat().st_size / (1024**2)\n",
    "        logger.info(f\"âœ“ Found fine-tuned weights: {weight_file_best.name} ({size_mb:.2f} MB)\")\n",
    "        return weight_file_best\n",
    "    \n",
    "    # Priority 2: Try _pretrained.pth (ImageNet pretrained) \n",
    "    weight_file_pretrained = offline_path / f'{model_name}_pretrained.pth'\n",
    "    if weight_file_pretrained.exists():\n",
    "        size_mb = weight_file_pretrained.stat().st_size / (1024**2)\n",
    "        logger.info(f\"âœ“ Found pretrained weights: {weight_file_pretrained.name} ({size_mb:.2f} MB)\")\n",
    "        return weight_file_pretrained\n",
    "    \n",
    "    logger.warning(f\"âš  Offline weights not found for {model_name}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def prepare_pretrained_weights_with_internet_check(weights_cache_dir, offline_dataset_path=None):\n",
    "    \"\"\"\n",
    "    Prepare pretrained weights with internet check and offline fallback.\n",
    "\n",
    "    Priority:\n",
    "    1. Check cache \n",
    "    2. Download if internet available\n",
    "    3. Load from offline dataset if no internet\n",
    "    4. Train from scratch if all else fails\n",
    "    \n",
    "    Args:\n",
    "        weights_cache_dir (Path): Directory to cache weights\n",
    "        offline_dataset_path (Path): Path to /kaggle/input/csiro-biomass-offline-assets\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if pretrained available, False otherwise\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"STEP 0: PREPARING PRETRAINED WEIGHTS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    weights_cache_dir = Path(weights_cache_dir)\n",
    "    \n",
    "    # STEP 0a: CHECK IF ALL WEIGHTS ALREADY CACHED  \n",
    "    logger.info(\"\\nStep 0a: Checking for cached pretrained weights...\")\n",
    "    if verify_pretrained_weights_exist(weights_cache_dir):\n",
    "        logger.info(\"\\nâœ“ All pretrained weights found in cache!\")\n",
    "        logger.info(\"  Using cached weights (fastest)\")\n",
    "        cleanup_memory()\n",
    "        return True\n",
    "    \n",
    "    # STEP 0b: CHECK INTERNET CONNECTION   \n",
    "    logger.info(\"\\nStep 0b: Checking internet connection...\")\n",
    "    has_internet = check_internet_connection()\n",
    "    \n",
    "    if has_internet:\n",
    "        logger.info(\"\\nâœ“ Internet available - downloading pretrained weights\")\n",
    "        logger.info(\"(This happens only once - weights are cached for future runs)\\n\")\n",
    "        try:\n",
    "            # Download and cache all pretrained weights\n",
    "            vit_pretrained_path = download_and_cache_pretrained_weights('vit', weights_cache_dir)\n",
    "            resnet_pretrained_path = download_and_cache_pretrained_weights('resnet', weights_cache_dir)\n",
    "            densenet_pretrained_path = download_and_cache_pretrained_weights('densenet', weights_cache_dir)\n",
    "            species_pretrained_path = download_and_cache_pretrained_weights('species', weights_cache_dir) \n",
    "            \n",
    "            cleanup_memory()\n",
    "            logger.info(\"\\nâœ“ All pretrained weights downloaded and cached successfully!\\n\")\n",
    "            logger.info(\"Attempting to load from offline Kaggle dataset...\\n\")\n",
    "            \n",
    "            if offline_dataset_path is None:\n",
    "                offline_dataset_path = Path('/kaggle/input/csiro-biomass-offline-assets')\n",
    "            \n",
    "            offline_dataset_path = Path(offline_dataset_path)\n",
    "            \n",
    "            # Check if offline dataset exists\n",
    "            if not offline_dataset_path.exists():\n",
    "                logger.warning(f\"âš  Offline dataset not found: {offline_dataset_path}\")\n",
    "                logger.warning(\"\\nNo pretrained weights available!\")\n",
    "                logger.warning(\"Options:\")\n",
    "                logger.warning(\"  1. Upload to Kaggle: /kaggle/input/csiro-biomass-offline-assets/\")\n",
    "            \n",
    "            # Try to load from offline dataset\n",
    "            logger.info(f\"Checking offline dataset: {offline_dataset_path}\\n\")\n",
    "            \n",
    "            #  Load species model too!\n",
    "            vit_offline = load_from_offline_dataset(offline_dataset_path, 'vit')\n",
    "            resnet_offline = load_from_offline_dataset(offline_dataset_path, 'resnet')\n",
    "            densenet_offline = load_from_offline_dataset(offline_dataset_path, 'densenet')\n",
    "            species_offline = load_from_offline_dataset(offline_dataset_path, 'species')\n",
    "            xgb_offline = load_from_offline_dataset(offline_dataset_path, 'xgboost')\n",
    "            metalearner_offline = load_from_offline_dataset(offline_dataset_path, 'metalearner')\n",
    "            \n",
    "            # If found, copy to cache\n",
    "            if vit_offline and resnet_offline and densenet_offline:\n",
    "                logger.info(\"\\nâœ“ Core weights found in offline dataset!\")\n",
    "                \n",
    "                #  Check species model too\n",
    "                if species_offline:\n",
    "                    logger.info(\"âœ“ Species model weights found!\")\n",
    "                else:\n",
    "                    logger.warning(\"âš  Species model weights not found (will train)\")\n",
    "    \n",
    "                if xgb_offline:\n",
    "                    logger.info(\"âœ“ xgb_offline model weights found!\")\n",
    "                else:\n",
    "                    logger.warning(\"âš  xgb_offline model weights not found (will train)\")\n",
    "                \n",
    "                logger.info(\"Copying to cache directory for faster access...\\n\")\n",
    "                \n",
    "                try:\n",
    "                    weights_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.copy(vit_offline, weights_cache_dir / 'vit_best.pth')\n",
    "                    shutil.copy(resnet_offline, weights_cache_dir / 'resnet_best.pth')\n",
    "                    shutil.copy(densenet_offline, weights_cache_dir / 'densenet_best.pth')\n",
    "                    #  Copy species model if found\n",
    "                    if species_offline:\n",
    "                        shutil.copy(species_offline, weights_cache_dir / 'species_best.pth')\n",
    "                        logger.info(\"âœ“ Species model copied to cache\")\n",
    "                    \n",
    "                    if xgb_offline:\n",
    "                        shutil.copy(xgb_offline, weights_cache_dir / 'xgboost_best.pkl')\n",
    "    \n",
    "                    if metalearner_offline:\n",
    "                        shutil.copy(metalearner_offline, weights_cache_dir / 'metalearner_best.pth')\n",
    "                    \n",
    "                    logger.info(\"âœ“ Weights copied to cache\")\n",
    "                    logger.info(\"âœ“ Next run will use cached weights (no copy needed)\\n\")\n",
    "                    cleanup_memory()\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"âœ— Error copying weights from offline dataset: {e}\")\n",
    "            return True                    \n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"\\nâœ— Error downloading pretrained weights: {e}\")\n",
    "            logger.warning(\"Falling back to offline dataset...\\n\")\n",
    "            # Fall through to offline check\n",
    "    \n",
    "\n",
    "    # STEP 0c: NO INTERNET - TRY OFFLINE DATASET   \n",
    "    if not has_internet:\n",
    "        logger.warning(\"\\nâš  No internet connection detected\")\n",
    "        logger.info(\"Attempting to load from offline Kaggle dataset...\\n\")\n",
    "        \n",
    "        if offline_dataset_path is None:\n",
    "            offline_dataset_path = Path('/kaggle/input/csiro-biomass-offline-assets')\n",
    "        \n",
    "        offline_dataset_path = Path(offline_dataset_path)\n",
    "        \n",
    "        # Check if offline dataset exists\n",
    "        if not offline_dataset_path.exists():\n",
    "            logger.warning(f\"âš  Offline dataset not found: {offline_dataset_path}\")\n",
    "            logger.warning(\"\\nNo pretrained weights available!\")\n",
    "            logger.warning(\"Options:\")\n",
    "            logger.warning(\"  1. Upload to Kaggle: /kaggle/input/csiro-biomass-offline-assets/\")\n",
    "        \n",
    "        # Try to load from offline dataset\n",
    "        logger.info(f\"Checking offline dataset: {offline_dataset_path}\\n\")\n",
    "        \n",
    "        #  Load species model too!\n",
    "        vit_offline = load_from_offline_dataset(offline_dataset_path, 'vit')\n",
    "        resnet_offline = load_from_offline_dataset(offline_dataset_path, 'resnet')\n",
    "        densenet_offline = load_from_offline_dataset(offline_dataset_path, 'densenet')\n",
    "        species_offline = load_from_offline_dataset(offline_dataset_path, 'species')\n",
    "        xgb_offline = load_from_offline_dataset(offline_dataset_path, 'xgboost')\n",
    "        metalearner_offline = load_from_offline_dataset(offline_dataset_path, 'metalearner')\n",
    "        \n",
    "        # If found, copy to cache\n",
    "        if vit_offline and resnet_offline and densenet_offline:\n",
    "            logger.info(\"\\nâœ“ Core weights found in offline dataset!\")\n",
    "            \n",
    "            #  Check species model too\n",
    "            if species_offline:\n",
    "                logger.info(\"âœ“ Species model weights found!\")\n",
    "            else:\n",
    "                logger.warning(\"âš  Species model weights not found (will train)\")\n",
    "\n",
    "            if xgb_offline:\n",
    "                logger.info(\"âœ“ xgb_offline model weights found!\")\n",
    "            else:\n",
    "                logger.warning(\"âš  xgb_offline model weights not found (will train)\")\n",
    "            \n",
    "            logger.info(\"Copying to cache directory for faster access...\\n\")\n",
    "\n",
    "            \n",
    "            try:\n",
    "                weights_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy(vit_offline, weights_cache_dir / 'vit_best.pth')\n",
    "                shutil.copy(resnet_offline, weights_cache_dir / 'resnet_best.pth')\n",
    "                shutil.copy(densenet_offline, weights_cache_dir / 'densenet_best.pth')\n",
    "                #  Copy species model if found\n",
    "                if species_offline:\n",
    "                    shutil.copy(species_offline, weights_cache_dir / 'species_best.pth')\n",
    "                    logger.info(\"âœ“ Species model copied to cache\")\n",
    "                \n",
    "                if xgb_offline:\n",
    "                    shutil.copy(xgb_offline, weights_cache_dir / 'xgboost_best.pkl')\n",
    "\n",
    "                if metalearner_offline:\n",
    "                    shutil.copy(metalearner_offline, weights_cache_dir / 'metalearner_best.pth')\n",
    "                \n",
    "                logger.info(\"âœ“ Weights copied to cache\")\n",
    "                logger.info(\"âœ“ Next run will use cached weights (no copy needed)\\n\")\n",
    "                cleanup_memory()\n",
    "                return True\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"âœ— Error copying weights: {e}\")\n",
    "                return False\n",
    "        else:\n",
    "            logger.warning(\"âœ— Some weights missing from offline dataset\")\n",
    "            missing = []\n",
    "            if not vit_offline: missing.append(\"ViT\")\n",
    "            if not resnet_offline: missing.append(\"ResNet\")\n",
    "            if not densenet_offline: missing.append(\"DenseNet\")\n",
    "            if not xgb_offline: missing.append(\"xgboost\")\n",
    "            if not metalearner_offline: missing.append(\"metalearner\")\n",
    "            if not species_offline: \n",
    "                logger.warning(\"  âš  Species model not found (optional)\")\n",
    "            \n",
    "            logger.warning(f\"  Missing core models: {', '.join(missing)}\\n\")\n",
    "            return False\n",
    "    \n",
    "    # FALLBACK: NO PRETRAINED AVAILABLE\n",
    "    logger.warning(\"\\n\" + \"!\"*80)\n",
    "    logger.warning(\"âš  NO PRETRAINED WEIGHTS AVAILABLE\")\n",
    "    logger.warning(\"!\"*80)\n",
    "    logger.warning(\"\\nWill train models from SCRATCH\")  \n",
    "    return False\n",
    "\n",
    "\n",
    "def create_file(name=\"Ashmin Dhungana\"):\n",
    "    \"\"\"\n",
    "    Create a Art describing my Name.\n",
    "    \"\"\"\n",
    "    logger.info(\"\")\n",
    "    logger.info(\"â•”\" + \"â•\" * 78 + \"â•—\")\n",
    "    logger.info(\"â•‘\" + \" \" * 78 + \"â•‘\")\n",
    "    logger.info(\"â•‘\" + f\"Prepared by: {name}\".center(78) + \"â•‘\")\n",
    "    logger.info(\"â•‘\" + \" \" * 78 + \"â•‘\")\n",
    "    logger.info(\"â•š\" + \"â•\" * 78 + \"â•\")\n",
    "    logger.info(\"\")\n",
    "\n",
    "def download_and_cache_pretrained_weights(model_name, weights_dir):\n",
    "    \"\"\"\n",
    "    Download pretrained weights from ImageNet and cache to disk.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Model identifier ('vit', 'resnet', 'densenet')\n",
    "        weights_dir (Path): Directory to cache weights\n",
    "    \n",
    "    Returns:\n",
    "        Path: Path to cached weights file\n",
    "    \"\"\"\n",
    "    weights_dir = Path(weights_dir)\n",
    "    weights_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cache_file = weights_dir / f'{model_name}_pretrained.pth'\n",
    "    \n",
    "    # Check if already cached\n",
    "    if cache_file.exists():\n",
    "        try:\n",
    "            size_bytes = cache_file.stat().st_size\n",
    "            size_mb = float(size_bytes) / (1024 * 1024)\n",
    "            logger.info(f\"âœ“ Using cached {model_name} pretrained weights ({size_mb:.2f} MB)\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš  Could not read cache file size: {e}\")\n",
    "            logger.info(f\"âœ“ Using cached {model_name} pretrained weights\")\n",
    "        return cache_file\n",
    "    \n",
    "    logger.info(f\"\\nðŸ“¥ Downloading {model_name} pretrained weights...\")\n",
    "    \n",
    "    try:\n",
    "        # Create temporary model to download weights\n",
    "        if model_name.lower() == 'vit':\n",
    "            logger.info(\"  Loading ViT-Base from ImageNet...\")\n",
    "            model = create_model('vit_base_patch16_224', pretrained=True)\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, cache_file)\n",
    "            logger.info(f\"âœ“ ViT-Base weights downloaded and cached\")\n",
    "\n",
    "        elif model_name.lower() == 'species':\n",
    "            logger.info(\"  Loading ViT-Base from ImageNet...\")\n",
    "            model = create_model('vit_base_patch16_224', pretrained=True)\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, cache_file)\n",
    "            logger.info(f\"âœ“ Species ViT-Base weights downloaded and cached\")\n",
    "            \n",
    "        elif model_name.lower() == 'resnet':\n",
    "            logger.info(\"  Loading ResNet-50 from ImageNet...\")\n",
    "            model = resnet50(pretrained=True)\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, cache_file)\n",
    "            logger.info(f\"âœ“ ResNet-50 weights downloaded and cached\")\n",
    "            \n",
    "        elif model_name.lower() == 'densenet':\n",
    "            logger.info(\"  Loading DenseNet-121 from ImageNet...\")\n",
    "            model = densenet121(pretrained=True)\n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, cache_file)\n",
    "            logger.info(f\"âœ“ DenseNet-121 weights downloaded and cached\")\n",
    "        del model\n",
    "        del state_dict\n",
    "        cleanup_memory()\n",
    "\n",
    "        try:\n",
    "            size_bytes = cache_file.stat().st_size\n",
    "            size_mb = float(size_bytes) / (1024 * 1024)\n",
    "            logger.info(f\"  Size: {size_mb:.2f} MB\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"âš  Could not calculate file size: {e}\")\n",
    "        \n",
    "        return cache_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"âœ— Error downloading {model_name} weights: {e}\")\n",
    "        import traceback\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        raise\n",
    "\n",
    "def load_from_offline_dataset(offline_path, model_name):\n",
    "    \"\"\"\n",
    "    Load pretrained/fine-tuned weights from offline Kaggle dataset.\n",
    "    \n",
    "    Checks for BOTH _best.pth (fine-tuned) AND _pretrained.pth (ImageNet)\n",
    "    \n",
    "    Priority:\n",
    "    1. _best.pth (fine-tuned models from previous run)\n",
    "    2. _pretrained.pth (ImageNet pretrained)\n",
    "    3. Return None if neither found\n",
    "    \n",
    "    Args:\n",
    "        offline_path (Path): Path to offline dataset\n",
    "        model_name (str): Model identifier ('vit', 'resnet', 'densenet')\n",
    "    \n",
    "    Returns:\n",
    "        Path: Path to weights file if exists, None otherwise\n",
    "    \"\"\"\n",
    "    offline_path = Path(offline_path)\n",
    "\n",
    "    # Priority 0: Try _best.pkl \n",
    "    weight_file_best = offline_path / f'{model_name}_best.pkl'\n",
    "    if weight_file_best.exists():\n",
    "        size_mb = weight_file_best.stat().st_size / (1024**2)\n",
    "        logger.info(f\"âœ“ Found fine-tuned weights: {weight_file_best.name} ({size_mb:.2f} MB)\")\n",
    "        return weight_file_best\n",
    "    \n",
    "    # Priority 1: Try _best.pth (fine-tuned models) \n",
    "    weight_file_best = offline_path / f'{model_name}_best.pth'\n",
    "    if weight_file_best.exists():\n",
    "        size_mb = weight_file_best.stat().st_size / (1024**2)\n",
    "        logger.info(f\"âœ“ Found fine-tuned weights: {weight_file_best.name} ({size_mb:.2f} MB)\")\n",
    "        return weight_file_best\n",
    "    \n",
    "    # Priority 2: Try _pretrained.pth (ImageNet pretrained) \n",
    "    weight_file_pretrained = offline_path / f'{model_name}_pretrained.pth'\n",
    "    if weight_file_pretrained.exists():\n",
    "        size_mb = weight_file_pretrained.stat().st_size / (1024**2)\n",
    "        logger.info(f\"âœ“ Found pretrained weights: {weight_file_pretrained.name} ({size_mb:.2f} MB)\")\n",
    "        return weight_file_pretrained\n",
    "    \n",
    "    logger.warning(f\"âš  Offline weights not found for {model_name}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_model_with_pretrained(model_class, model_name, weights_dir, device, use_mil=CONFIG[\"use_mil\"]):\n",
    "    \"\"\"\n",
    "    SMART loading with PRIORITY:\n",
    "    1. Check _best.pth FIRST (resume/fine-tune from saved weights)\n",
    "    2. Check _pretrained.pth (first run with ImageNet)\n",
    "    3. Train from scratch\n",
    "    \"\"\"\n",
    "    logger.info(f\"\\nLoading {model_name}...\")\n",
    "    if use_mil == True and model_name in ['vit', 'densenet', 'resnet', 'species']:\n",
    "        model = model_class(pretrained=False, use_mil=CONFIG[\"use_mil\"])\n",
    "    else:\n",
    "        model = model_class(pretrained=False)\n",
    "    best_path = Path(weights_dir) / f'{model_name}_best.pth'\n",
    "    pretrained_path = Path(weights_dir) / f'{model_name}_pretrained.pth'\n",
    "    \n",
    "    # PRIORITY 1: _best.pth from saved dataset\n",
    "    if best_path.exists():\n",
    "        logger.info(f\"âœ“ Found: {best_path.name} (FROM SAVED DATASET)\")\n",
    "        logger.info(f\"  [Mode: FULL-LOAD]\")\n",
    "        logger.info(f\"  Both backbone AND regression head already trained!\")\n",
    "        state = torch.load(best_path, map_location='cpu')\n",
    "        model.load_state_dict(state, strict=False)\n",
    "        logger.info(f\"âœ“ Loaded successfully - ready for fine-tuning!\\n\")\n",
    "    \n",
    "    # PRIORITY 2: _pretrained.pth from download\n",
    "    elif pretrained_path.exists():\n",
    "        logger.info(f\"âœ“ Found: {pretrained_path.name} (FROM IMAGENET)\")\n",
    "        logger.info(f\"  [Mode: BACKBONE-ONLY]\")\n",
    "        logger.info(f\"  Only backbone loaded, regression head random!\")\n",
    "        logger.info(f\"  Loading for: First-time training with new architecture\")\n",
    "        state = torch.load(pretrained_path, map_location='cpu')\n",
    "        incompatible = model.load_state_dict(state, strict=False)\n",
    "        if incompatible.missing_keys:\n",
    "            logger.info(f\"âœ“ Backbone loaded\")\n",
    "            logger.info(f\"  Skipped: {len(incompatible.missing_keys)} regression head layers\")\n",
    "    \n",
    "    # PRIORITY 3: Train from scratch\n",
    "    else:\n",
    "        logger.warning(f\"âš  No weights found - training from scratch\\n\")\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "weights_cache_dir = MODELS_DIR \n",
    "offline_dataset_path = ASSETS\n",
    "    \n",
    "has_pretrained = prepare_pretrained_weights_with_internet_check(\n",
    "        weights_cache_dir,\n",
    "        offline_dataset_path)\n",
    "\n",
    "\n",
    "# STEP 0: Load data\n",
    "(train_df_org, test_df_org, STATE_COLS_org, SPECIES_COLS_org, TARGET_TYPE_COLS_org, \n",
    "    TOTAL_TABULAR_DIM_org, lookups_dict_org, original_test_df_org) = load_and_explore_data()\n",
    "\n",
    "# Check for pretrained species weights first\n",
    "if has_pretrained:\n",
    "    logger.info(\"  âœ“ Attempting to load pretrained species weights\")\n",
    "    species_model = load_model_with_pretrained(\n",
    "    SpeciesClassificationViT, 'species', weights_cache_dir, device, use_mil=CONFIG[\"use_mil\"]\n",
    "    )\n",
    "else:\n",
    "    logger.info(\"  Training from scratch (no pretrained weights)\")\n",
    "    species_model = SpeciesClassificationViT(pretrained=False, use_mil=CONFIG[\"use_mil\"])\n",
    "    species_model = species_model.to(device)\n",
    "\n",
    "# STEP 2.0: For Training Specis Model\n",
    "train_loader_old, val_loader_old, test_loader_old, train_images_old, val_images_old = \\\n",
    "    create_data_loaders(train_df_org, test_df_org, lookups_dict_org, TOTAL_TABULAR_DIM_org, model=species_model)\n",
    "\n",
    "agg = compute_and_save_ndvi_stats_with_sklearn(\n",
    "    train_df_org,\n",
    "    base_dir= RAW_DATA_DIR,  \n",
    "    image_path_col=\"image_path\",\n",
    "    species_col=\"Species\",\n",
    "    ndvi_col_candidates=('Pre_GSHH_NDVI','ndvi','NDVI','vndvi'), \n",
    "    out_path= OUTPUTS_DIR / 'ndvidata.csv',\n",
    "    resize_to=(512,512),\n",
    "    max_images=None,        \n",
    "    min_samples_for_ml=20,   \n",
    "    force_recompute=True\n",
    ")\n",
    "\n",
    "\n",
    "# Train the species model\n",
    "species_history = train_species_model(\n",
    "        train_loader_old, val_loader_old,\n",
    "        train_df=train_df_org, \n",
    "        num_epochs=CONFIG.get('species_vit_epochs', 50),\n",
    "        device=device,\n",
    "        model= species_model\n",
    "    )\n",
    "\n",
    "logger.info(\"\\nOffloading Species Model to disk...\")\n",
    "offload_model_to_disk(species_model, 'species', MODELS_DIR)\n",
    "logger.info(\"âœ“ Species model training completed\\n\")  \n",
    "\n",
    "species_model = SpeciesClassificationViT(pretrained=False, use_mil=CONFIG[\"use_mil\"])\n",
    "species_model.load_state_dict(torch.load(MODELS_DIR / 'species_best.pth', map_location=device))\n",
    "species_model = species_model.to(device)\n",
    "logger.info(\"âœ“ ViT loaded\")\n",
    "\n",
    "\n",
    "synthetic_df = generate_synthetic_train_df_matching_schema(\n",
    "    train_df=train_df_org,\n",
    "    species_model=species_model,\n",
    "    lookups_dict=lookups_dict_org,\n",
    "    raw_dir=RAW_DATA_DIR,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "try:\n",
    "    (train_df, test_df, STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS, \n",
    "        TOTAL_TABULAR_DIM, lookups_dict, original_test_df) = load_and_explore_data(TRAINDATA=SYN_CSV)\n",
    "\n",
    "except Exception as e:\n",
    "    (train_df, test_df, STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS, \n",
    "        TOTAL_TABULAR_DIM, lookups_dict, original_test_df) = load_and_explore_data()\n",
    "    logger.info(f\"Synthetic_df Load Failed: {e}\")\n",
    "                   \n",
    "\n",
    "# STEP 1.2: Create loaders synthetic\n",
    "train_loader, val_loader, test_loader, train_images, val_images = \\\n",
    "    create_data_loaders(train_df, test_df, lookups_dict, TOTAL_TABULAR_DIM, model=species_model)\n",
    "\n",
    "\n",
    "\n",
    "train_split_df, val_split_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.15,  \n",
    "        random_state=42,\n",
    "        stratify=train_df['target_name'] \n",
    "        )\n",
    "\n",
    "\n",
    "#_____________________________________________________\n",
    "# Comment Out Later During Submition\n",
    "#______________________________________________________\n",
    "#Dataloder Diagnostics\n",
    "run_dataloader_diagnostics(train_loader, num_patches=8)\n",
    "run_dataloader_diagnostics(test_loader, num_patches=8)\n",
    "diagnose_ensemble_batch(test_loader, num_patches=8)\n",
    "diagnose_ensemble_batch(train_loader, num_patches=8)\n",
    "#_____________________________________________________\n",
    "\n",
    "logger.info(\"âœ“ Helper Function Defined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
