{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e548bd",
   "metadata": {},
   "source": [
    "# ðŸŒ¾ Image2Biomass Prediction\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements a **6-model ensemble learning system** which is used to predict dry biomass  by combining  imagery and environmental tabular features, which is  **Cheap, affordable and better** then other large models.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "- **Vision Models** (3): ViT-Base, ResNet-50, DenseNet-121 for image patch processing  \n",
    "- **Species Classification Model**: ViT-Base (16-class classifier) for predicting pasture species from imagery\n",
    "- **Tabular Model**: XGBoost trained on environmental and spectral features  \n",
    "- **Meta-Learner**: Fully connected neural network that fuses base model predictions and tabular features  \n",
    "\n",
    "```\n",
    "                            System Parameter Breakdown:\n",
    "                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                            1. ViT-Base (Biomass):      86.6M\n",
    "                            2. ResNet-50 (Biomass):     25.6M\n",
    "                            3. DenseNet-121 (Biomass):  8.0M\n",
    "                            4. Species Classifier:      86.6M\n",
    "                            5. Meta-Learner:            5.1K\n",
    "                            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                            Total Parameters:          ~207M\n",
    "\n",
    "```\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "- **Input images**: 2000Ã—1000 pixel  images  \n",
    "- **Patch extraction**: Splits each image into 8 patches (500Ã—500 pixels), resized to 224Ã—224 for model inputs  \n",
    "- **Tabular features**: 29-dimensional vector combining:\n",
    "  - Numeric features: NDVI, height, month, day of year, quarter (normalized)\n",
    "  - Categorical features: state (4 dims), species (15 dims), target type (5 dims)\n",
    "- **Targets**: Predicts 5 biomass target types â€” Dry_Green_g, Dry_Dead_g, Dry_Clover_g, Dry_Total_g, GDM_g  \n",
    "\n",
    "### Species Classification Model\n",
    "\n",
    "The **Species ViT** is a ViT-Base model trained for 15-class species classification:\n",
    "\n",
    "- **Input**: Same 8 image patches as biomass models (224Ã—224 each)\n",
    "- **Output**: Species class prediction (15 unique species)\n",
    "- **Purpose**: Predicts pasture species from satellite imagery for intelligent feature fallback\n",
    "- **Usage**: During test inference with missing features, species prediction improves fallback feature generation accuracy (Level 1 , 2 & 3 fallback levels)\n",
    "- **Training**: Trained on training set species labels, achieves high accuracy to ensure reliable predictions\n",
    "\n",
    "### Key Features\n",
    "\n",
    "âœ… **6-model ensemble** (3 vision + 1 species + 1 tabular + 1 meta-learner)  \n",
    "âœ… **Intelligent multi-level fallback** for missing test features using species prediction and statistical inference  \n",
    "âœ… **Species-informed feature generation** â€” Uses predicted species to improve tabular feature accuracy in test data  \n",
    "âœ… **Patch-level image processing** to capture spatial detail and improve robustness  \n",
    "âœ… **GPU memory optimization and model offloading** for efficient training  \n",
    "âœ… **Comprehensive logging** for detailed training and evaluation tracking  \n",
    "âœ… **Weighted RÂ² loss** optimized per competition evaluation metrics (0.5 for Dry_Total_g, 0.2 for GDM, 0.1 for others)  \n",
    "âœ… **Cross-validation on 85/15 train/val split** to monitor generalization  \n",
    "âœ… **Robust ensemble averaging and meta-learning** for final biomass prediction  \n",
    "\n",
    "### Data Pipeline\n",
    "\n",
    "```\n",
    "    \n",
    "                                            Test Image\n",
    "                                                â†“\n",
    "                            Load Image â†’ Crop 8 Patches (500Ã—500 â†’ 224Ã—224)\n",
    "                                                â†“\n",
    "                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                â”‚ Species Model Prediction        â”‚\n",
    "                                â”‚ (15 classes: pasture species)   â”‚\n",
    "                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â†“ (species label)\n",
    "                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                â”‚ Intelligent Feature Fallback    â”‚\n",
    "                                â”‚ Level 1: Random state + species â”‚\n",
    "                                â”‚ Level 2: Exact sample ID match  â”‚\n",
    "                                â”‚ Level 3: Image ID + species     â”‚\n",
    "                                â”‚ Level 4: Statistical generation â”‚\n",
    "                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â†“ (tabular features)\n",
    "                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                            â”‚ Base Models                             â”‚\n",
    "                            â”‚ - Vision: ViT, ResNet, DenseNet (X pred)â”‚\n",
    "                            â”‚ - Tabular: XGBoost (1 pred)             â”‚\n",
    "                            â”‚ Outputs: 1 predictions per model        â”‚\n",
    "                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                         â†“ (X base predictions)\n",
    "                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                            â”‚ Meta-Learner                            â”‚\n",
    "                            â”‚ Input: X predictions + 29 features      â”‚\n",
    "                            â”‚ Output: 1 final prediction              â”‚\n",
    "                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                             â†“\n",
    "                                Final Biomass Prediction (grams)\n",
    "\n",
    "```\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "- Optimizes globally weighted RÂ² metric reflecting competition's scoring  \n",
    "- Species model improves test feature fallback accuracy by providing accurate species labels\n",
    "- Ensemble diversity (vision + tabular + species) provides robustness  \n",
    "- Meta-learner learns optimal combination of base model predictions  \n",
    "- Comprehensive validation monitoring with early stopping prevents overfitting  \n",
    "\n",
    "### Output Format\n",
    "\n",
    "- **File**: CSV with `sample_id` and `target` columns\n",
    "- **Rows**: 5 rows (one per target type: Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g)\n",
    "- **Values**: Biomass predictions in grams (float, non-negative, rounded to 3 decimal places)\n",
    "- **Evaluation**: Weighted RÂ² computed globally across all rows combined\n",
    "\n",
    "---\n",
    "\n",
    "**Status**: âœ… Ready | **Models**: 6 | **Features**: 29 | **Targets**: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bdab4d",
   "metadata": {},
   "source": [
    "##  1: IMPORTS & CONFIGURATION\n",
    "\n",
    "This cell initializes all required dependencies for the complete pipeline.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "#### Data Processing & ML\n",
    "- `pandas`, `numpy`: Data manipulation\n",
    "- `scikit-learn`: Preprocessing, metrics, splitting\n",
    "- `xgboost`: Tree-based ensemble model\n",
    "\n",
    "#### Deep Learning\n",
    "- `torch`, `torchvision`: PyTorch framework\n",
    "- `timm`: Vision model library (ViT, ResNet, DenseNet)\n",
    "- `torch.nn.functional`: Neural network operations\n",
    "\n",
    "#### Visualization & Logging\n",
    "- `matplotlib`, `seaborn`: Data visualization\n",
    "- `PIL`: Image processing\n",
    "- `logging`, `tqdm`: Progress tracking\n",
    "- `cv2`: Computer vision operations\n",
    "\n",
    "#### Utilities\n",
    "- `pathlib`: File path management\n",
    "- `json`, `pickle`: Serialization\n",
    "- `shutil`, `gc`: System utilities\n",
    "- `datetime`: Timestamps\n",
    "- `socket`: Network connectivity checks\n",
    "\n",
    "### Environment Detection\n",
    "\n",
    "- GPU availability check\n",
    "- Device assignment (CUDA/CPU)\n",
    "- Random seed initialization for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import socket\n",
    "import pickle\n",
    "import joblib\n",
    "import shutil\n",
    "import random \n",
    "import zipfile\n",
    "import logging\n",
    "import warnings\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['OPENCV_LOG_LEVEL'] = 'OFF'\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from timm import create_model\n",
    "import torch.nn.functional as FF\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50, densenet121\n",
    "\n",
    "# Progress tracking\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats import trim_mean\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.ndimage import laplace, gaussian_filter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logger = logging.getLogger(__name__)\n",
    "for h in logger.handlers[:]:\n",
    "    logger.removeHandler(h)\n",
    "\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "log_file_path = \"/kaggle/working/pipeline.log\" \n",
    "file_handler = logging.FileHandler(log_file_path, mode=\"w\", encoding=\"utf-8\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"PASTURE BIOMASS PREDICTION - 6 MODEL ENSEMBLE PIPELINE\")\n",
    "logger.info(\"=\" * 80)\n",
    "start_time = datetime.now()\n",
    "logger.info(f\"Execution started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "logger.info(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4aaebd",
   "metadata": {},
   "source": [
    "## 2: PATHS AND CONFIGURATION\n",
    "\n",
    "**Purpose**: Define directory structure, file paths, and all hyperparameters.\n",
    "\n",
    "\n",
    "**Image Configuration**:\n",
    "\n",
    "| Parameter | Value | Purpose |\n",
    "|-----------|-------|---------|\n",
    "| Image Size | 2000Ã—1000 px | Raw  image |\n",
    "| Patch Size | 500Ã—500 px | Crop dimensions |\n",
    "| Grid Layout | 4 horizontal Ã— 2 vertical | Total 8 patches per image |\n",
    "| Model Input | 224Ã—224 px | Vision model standard |\n",
    "| Total Patches Per Image | 8 | Spatial diversity |\n",
    "\n",
    "**Training Hyperparameters**:\n",
    "\n",
    "| Setting | Value | Notes |\n",
    "|---------|-------|-------|\n",
    "| Batch Size | 2 images | = 16 patches per batch |\n",
    "| Learning Rate | 1e-4 to 5e-4 | Model-specific |\n",
    "| Epochs | 50 (ViT/ResNet/DenseNet), 100 (XGBoost/Meta) | Training iterations |\n",
    "| Dropout | 0.1-0.3 | Regularization |\n",
    "| Weight Decay | 0.05 | L2 regularization in AdamW |\n",
    "| Early Stopping | patience=20 | Stop if no improvement |\n",
    "| Gradient Clipping | 1.0 | Stability |\n",
    "| Optimizer | AdamW | Weight decay support |\n",
    "\n",
    "**Target Importance Weighting** (Weighted RÂ²):\n",
    "```\n",
    "Dry_Total_g:   0.5  â† Primary metric (50%)\n",
    "GDM_g:         0.2  â† Secondary (20%)\n",
    "Dry_Green_g:   0.1  â† Supporting (10%)\n",
    "Dry_Dead_g:    0.1  â† Supporting (10%)\n",
    "Dry_Clover_g:  0.1  â† Supporting (10%)\n",
    "```\n",
    "\n",
    "**Output**: Configuration dictionary logged with all settings, device detected, paths created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4279056",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define directory structure\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m BASE_DIR = \u001b[43mPath\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m./\u001b[39m\u001b[33m'\u001b[39m).resolve()\n\u001b[32m      3\u001b[39m DATA_DIR = BASE_DIR / \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m MODELS_DIR = BASE_DIR / \u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Define directory structure\n",
    "BASE_DIR = Path('./').resolve()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "OUTPUTS_DIR = BASE_DIR / 'outputs'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "RAW_DATA_DIR = Path('input_data/')\n",
    "ASSETS = Path('assets/')\n",
    "\n",
    "# Data file paths\n",
    "TRAIN_CSV = RAW_DATA_DIR / 'train.csv'\n",
    "TEST_CSV = RAW_DATA_DIR / 'test.csv'\n",
    "SYN_CSV = OUTPUTS_DIR / 'train_synthetic_matching.csv'\n",
    "SAMPLE_SUBMISSION = RAW_DATA_DIR / 'sample_submission.csv'\n",
    "\n",
    "# Model checkpoint paths\n",
    "VIT_CHECKPOINT = MODELS_DIR / 'vit_best.pth'\n",
    "RESNET_CHECKPOINT = MODELS_DIR / 'resnet_best.pth'\n",
    "DENSENET_CHECKPOINT = MODELS_DIR / 'densenet_best.pth'\n",
    "XGBOOST_CHECKPOINT = MODELS_DIR / 'xgboost_best.pkl'\n",
    "METALEARNER_CHECKPOINT = MODELS_DIR / 'metalearner_best.pth'\n",
    "SPECIES_VIT_CHECKPOINT = MODELS_DIR / 'species_best.pth'\n",
    "\n",
    "# Output paths\n",
    "SUBMISSION_PATH = BASE_DIR / 'submission.csv'\n",
    "METRICS_PATH = OUTPUTS_DIR / 'metrics.json'\n",
    "\n",
    "TOTAL_TABULAR_DIM = 30\n",
    "MAX_TARGET = 200.0\n",
    "\n",
    "# Configuration constants\n",
    "CONFIG = {\n",
    "  \n",
    "    'image_width': 2000,          \n",
    "    'image_height': 1000,         \n",
    "    'patch_size': 500,            \n",
    "    'patches_horizontal': 4,      \n",
    "    'patches_vertical': 2,        \n",
    "    'num_patches': 8,             \n",
    "\n",
    "    'random_seed': 42,\n",
    "    'numpy_seed': 42,\n",
    "    'torch_seed': 42,\n",
    "    'tensorflow_seed': 42,\n",
    "    \n",
    "    # Deep Learning hyperparameters\n",
    "    'model_input_size': 224,     \n",
    "    'batch_size': 8,              \n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "    \n",
    "    # Training parameters\n",
    "    'vit_epochs': 15,  #15-15 Total 30   \n",
    "    'resnet_epochs': 15, #15-15 Total 30 \n",
    "    'densenet_epochs': 15, #15-15 Total 30\n",
    "    'metalearner_epochs': 8, #8\n",
    "    'metalearner_repeat' : 10, #10\n",
    "\n",
    "    #  Species Model Configuration\n",
    "    'species_vit_epochs': 15,  #15-15 Total 30\n",
    "    'species_vit_lr': 2e-4,\n",
    "    'num_species_classes': 16,  \n",
    "    'meta_weight_decay': 0.01,    \n",
    "    'meta_dropout_rate': 0.15,  \n",
    "    \n",
    "    \"use_mil\": True,   # Toggle MIL \n",
    "    \"mil_dropout\": 0.25,         \n",
    "    \n",
    "    'vit_lr': 2e-4,\n",
    "    'resnet_lr': 2e-4,\n",
    "    'densenet_lr': 2e-4,\n",
    "    'metalearner_lr': 1e-3,\n",
    "    \n",
    "    'weight_decay': 0.03,\n",
    "    'gradient_clip': 1.0,\n",
    "    'early_stopping_patience': 5,\n",
    "\n",
    "    # XGBoost parameters\n",
    "    'xgb_n_estimators': 1000,            \n",
    "    'xgb_max_depth': 4,                   \n",
    "    'xgb_learning_rate': 0.05,             \n",
    "    'xgb_subsample': 0.75,                 \n",
    "    'xgb_colsample_bytree': 0.75,          \n",
    "    'xgb_min_child_weight': 5,             \n",
    "    'xgb_reg_alpha': 0.5,                  \n",
    "    'xgb_reg_lambda': 1.5,                 \n",
    "    'xgb_gamma': 1.0,                      \n",
    "    'xgb_early_stopping_rounds': 50,       \n",
    "     \n",
    "\n",
    "    # Data split\n",
    "    'val_split': 0.15,\n",
    "    'test_size_for_split': 0.15,\n",
    "    \n",
    "    # Weighted RÂ² weights\n",
    "    'r2_weights': {\n",
    "        'Dry_Green_g': 0.1,\n",
    "        'Dry_Dead_g': 0.1,\n",
    "        'Dry_Clover_g': 0.1,\n",
    "        'GDM_g': 0.2,\n",
    "        'Dry_Total_g': 0.5,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR, OUTPUTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"âœ“ Directory ready: {directory}\")\n",
    "    \n",
    "# Device detection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    logger.info(f\"âœ“ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    logger.info(\"âš  GPU not available, using CPU\")\n",
    "\n",
    "CONFIG['xgb_noise_scale'] = 0.05      \n",
    "CONFIG['xgb_augment_rounds'] = 2\n",
    "CONFIG['dry_total_tolerance'] = 0.1\n",
    "CONFIG['device'] = device\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(CONFIG['numpy_seed'])\n",
    "torch.manual_seed(CONFIG['torch_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(CONFIG['torch_seed'])\n",
    "\n",
    "logger.info(\"âœ“ Paths and configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c707e",
   "metadata": {},
   "source": [
    "## 3: EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "**Purpose**: Load, explore, analyze data, and build intelligent lookup tables for test feature fetching.\n",
    "\n",
    "**Dataset Statistics**:\n",
    "\n",
    "| Aspect | Training | Test |\n",
    "|--------|----------|------|\n",
    "| Rows | 1,785 | 5 |\n",
    "| Features | 30 total | 3 (ID, path, target) |\n",
    "| Targets | 5 types | TBD |\n",
    "| Per Target | 357 samples | 1 sample |\n",
    "\n",
    "**Numeric Features (5)**:\n",
    "- `Pre_GSHH_NDVI`: Vegetation greenness [0.0, 1.0]\n",
    "- `Height_Ave_cm`: Pasture height [0, 100] cm\n",
    "- `Month`: Sampling month [1, 12]\n",
    "- `DayOfYear`: Day since Jan 1 [1, 365]\n",
    "- `Quarter`: Season [1, 4]\n",
    "\n",
    "**Categorical Features** (One-Hot Encoded):\n",
    "- `State` (4): NSW, WA, Tasmania, Victoria\n",
    "- `Species` (16): Ryegrass, Clover, Phalaris, Lucerne, etc.\n",
    "- `Target Type` (5): Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g\n",
    "\n",
    "**Total Feature Dimension**: 5 + 4 + 16 + 5 = **30 features**\n",
    "\n",
    "**Target Variables** (5 Biomass Types):\n",
    "\n",
    "| Target | Description | Weight | Typical Range |\n",
    "|--------|-------------|--------|---------------|\n",
    "| Dry_Green_g | Green leaf dry matter | 0.1 | 0-500g |\n",
    "| Dry_Dead_g | Dead plant material | 0.1 | 0-300g |\n",
    "| Dry_Clover_g | Clover dry matter | 0.1 | 0-200g |\n",
    "| GDM_g | Green dry matter | 0.2 | 100-1000g |\n",
    "| Dry_Total_g | Total dry matter | 0.5 | 100-1500g |\n",
    "\n",
    "**Test Data Challenge**:\n",
    "- Test CSV contains only 5 rows with minimal features\n",
    "- Missing: Sampling_Date, State, Species, Pre_GSHH_NDVI, Height_Ave_cm\n",
    "- Solution: Intelligent 4-level fallback feature fetching\n",
    "\n",
    "\n",
    "**Output**: \n",
    "- Data loaded and explored\n",
    "- Lookup tables built for all 4 levels\n",
    "- EDA visualizations saved\n",
    "- Summary statistics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_SPECIES_LIST = [\n",
    "    'Ryegrass_Clover', 'Lucerne', 'SubcloverDalkeith', 'Ryegrass',\n",
    "    'Phalaris_Clover', 'SubcloverLosa', 'Clover', 'Fescue_CrumbWeed',\n",
    "    'Phalaris_Ryegrass_Clover', 'Phalaris', 'WhiteClover', 'Fescue',\n",
    "    'Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed',\n",
    "    'Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass', 'Mixed', 'Nothing']\n",
    "\n",
    "def _normalize_for_vocab(s):\n",
    "    if s is None:\n",
    "        return ''\n",
    "    s = str(s).strip()\n",
    "    if s == '' or s.lower() in ('nan', 'none', 'null'):\n",
    "        return ''\n",
    "    return s\n",
    "\n",
    "def map_to_fixed_species(raw):\n",
    "    \"\"\"\n",
    "    Map arbitrary raw species text to one of FIXED_SPECIES_LIST (returning the exact list item),\n",
    "    or 'Mixed' if no reasonable mapping. Blanks/NA -> 'Nothing'.\n",
    "    \"\"\"\n",
    "    r = _normalize_for_vocab(raw)\n",
    "    if r == '':\n",
    "        return 'Nothing'\n",
    "\n",
    "    # normalized comparable form\n",
    "    rl = re.sub(r'[\\s\\-_\\.]+', ' ', r.strip().lower())\n",
    "\n",
    "    for fs in FIXED_SPECIES_LIST:\n",
    "        fs_norm = re.sub(r'[\\s\\-_\\.]+', ' ', fs.strip().lower())\n",
    "        if rl == fs_norm:\n",
    "            return fs\n",
    "    rl_tokens = set(rl.split())\n",
    "    best = None\n",
    "    best_score = 0\n",
    "    for fs in FIXED_SPECIES_LIST:\n",
    "        fs_norm = re.sub(r'[\\s\\-_\\.]+', ' ', fs.strip().lower())\n",
    "        fs_tokens = set(fs_norm.split())\n",
    "        overlap = len(rl_tokens & fs_tokens)\n",
    "        contain = 1 if (rl in fs_norm or fs_norm in rl) else 0\n",
    "        score = overlap * 10 + contain\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = fs\n",
    "    if best_score > 0:\n",
    "        return best\n",
    "    return 'Mixed'\n",
    "\n",
    "def create_species_lookup_tables(train_df):\n",
    "    \"\"\"\n",
    "    Create species-based lookup tables for Level 2 fallbacks.\n",
    "\n",
    "    Returns a tuple (rows_map, stats_map) where:\n",
    "      - rows_map:  { target_name_norm: { (image_id_norm, species_norm): [row_dict, ...] } }\n",
    "      - stats_map: { target_name_norm: { (image_id_norm, species_norm): {count, mean, std, median} } }\n",
    "    \"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"CREATING SPECIES-BASED LOOKUP TABLES\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    if train_df is None or train_df.shape[0] == 0:\n",
    "        logger.warning(\"create_species_lookup_tables: empty or None train_df provided; returning empty lookups\")\n",
    "        return {}, {}\n",
    "\n",
    "    required_cols = ['sample_id', 'Species', 'target_name', 'target']\n",
    "    for c in required_cols:\n",
    "        if c not in train_df.columns:\n",
    "            logger.warning(f\"create_species_lookup_tables: missing column {c}; filling with defaults\")\n",
    "            if c == 'target':\n",
    "                train_df[c] = pd.to_numeric(train_df.get(c, np.nan), errors='coerce')\n",
    "            else:\n",
    "                train_df[c] = train_df.get(c, '').astype(str)\n",
    "\n",
    "    def _norm_str(x):\n",
    "        s = str(x).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = s.replace('.', '')\n",
    "        return s\n",
    "\n",
    "    def _norm_image_id(sample_id):\n",
    "        try:\n",
    "            return str(sample_id).split('__')[0].strip().lower()\n",
    "        except Exception:\n",
    "            return str(sample_id).strip().lower()\n",
    "            \n",
    "    tmp = train_df.copy()\n",
    "    tmp['_image_id'] = tmp['sample_id'].apply(_norm_image_id).fillna('').astype(str)\n",
    "    if 'Species_canon' in tmp.columns:\n",
    "        tmp['_species_n'] = tmp['Species_canon'].astype(str).fillna('').apply(lambda x: re.sub(r\"[\\s\\-]+\", \"_\", str(x).strip().lower()).replace('.', ''))\n",
    "    else:\n",
    "        tmp['_species_n'] = tmp['Species'].astype(str).fillna('').apply(_norm_str)\n",
    "    \n",
    "    tmp['_target_n'] = tmp['target_name'].astype(str).fillna('').apply(_norm_str)\n",
    "\n",
    "    TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS = {}\n",
    "    for idx, row in tmp.iterrows():\n",
    "        t = row['_target_n']\n",
    "        key = (row['_image_id'], row['_species_n'])\n",
    "        TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS.setdefault(t, {}).setdefault(key, []).append(row.to_dict())\n",
    "\n",
    "    TRAIN_BY_IMAGE_SPECIES_TARGET_STATS = {}\n",
    "    grouped = tmp.groupby(['_target_n', '_image_id', '_species_n'])['target']\n",
    "    for (t, img, sp), ser in grouped:\n",
    "        TRAIN_BY_IMAGE_SPECIES_TARGET_STATS.setdefault(t, {})[(img, sp)] = {\n",
    "            'count': int(ser.count()),\n",
    "            'mean': float(ser.mean()) if ser.count() > 0 else 0.0,\n",
    "            'std': float(ser.std()) if ser.count() > 1 else 0.0,\n",
    "            'median': float(ser.median()) if ser.count() > 0 else 0.0}\n",
    "        \n",
    "    total_keys = sum(len(d) for d in TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS.values())\n",
    "    logger.debug(f\"âœ“ Level 2 species lookup (rows) built: targets={len(TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS)} total_keys={total_keys}\")\n",
    "    for t, combos in TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS.items():\n",
    "        logger.info(f\"  {t}: {len(combos)} (image,species) combos\")\n",
    "\n",
    "    return TRAIN_BY_IMAGE_SPECIES_TARGET_ROWS, TRAIN_BY_IMAGE_SPECIES_TARGET_STATS\n",
    "\n",
    "\n",
    "def load_and_explore_data(TRAINDATA=TRAIN_CSV):\n",
    "    \"\"\"\n",
    "    Load and perform comprehensive EDA on training and test datasets.\n",
    "    Creates intelligent lookup tables for test data feature fetching.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_df, test_df, STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS,\n",
    "                TOTAL_TABULAR_DIM, lookups_dict, original_test_df)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"LOADING DATA WITH INTELLIGENT TEST FEATURE FETCHING\")\n",
    "    logger.info(\"=\"*80)\n",
    "    lookups_dict = {}\n",
    "    \n",
    "    # LOAD DATA\n",
    "    try:\n",
    "        train_df = pd.read_csv(TRAINDATA)\n",
    "        test_df = pd.read_csv(TEST_CSV)\n",
    "        original_test_df = test_df.copy()\n",
    "        logger.debug(f\"âœ“ Training data loaded: {len(train_df)} rows, {len(train_df.columns)} columns\")\n",
    "        logger.info(f\"âœ“ Test data loaded: {len(test_df)} rows, {len(test_df.columns)} columns\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"âœ— Error loading data: {e}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    try:\n",
    "        HEIGHT_MAX = float(train_df['Height_Ave_cm'].max())\n",
    "        if not np.isfinite(HEIGHT_MAX) or HEIGHT_MAX <= 0:\n",
    "            HEIGHT_MAX = 100\n",
    "    except Exception:\n",
    "        HEIGHT_MAX = 100\n",
    "    \n",
    "    # safety margin \n",
    "    HEIGHT_MAX = float(min(max(HEIGHT_MAX, 1.0), 150.0))\n",
    "    \n",
    "    logger.debug(f\"âœ“ Using dynamic HEIGHT_MAX = {HEIGHT_MAX:.2f} cm\")\n",
    "    lookups_dict[\"HEIGHT_MAX\"] = HEIGHT_MAX\n",
    "\n",
    "    # Required train columns\n",
    "    expected_train_cols = ['sample_id','target_name','target','Pre_GSHH_NDVI','Height_Ave_cm','Sampling_Date','State','Species']\n",
    "    for c in expected_train_cols:\n",
    "        if c not in train_df.columns:\n",
    "            logger.warning(f\"Train CSV missing column: {c} â€” filling with default/NA\")\n",
    "            if c in ['Pre_GSHH_NDVI','Height_Ave_cm','target']:\n",
    "                train_df[c] = pd.to_numeric(train_df.get(c, np.nan), errors='coerce')\n",
    "            else:\n",
    "                train_df[c] = train_df.get(c, '').astype(str)\n",
    "\n",
    "    # Expected test columns - fill if missing \n",
    "    expected_test_cols = ['sample_id','image_path','target_name','Sampling_Date','State','Species','Pre_GSHH_NDVI','Height_Ave_cm']\n",
    "    for c in expected_test_cols:\n",
    "        if c not in test_df.columns:\n",
    "            logger.warning(f\"Test CSV missing column: {c}. Will rely on fallback stats.\")\n",
    "            test_df[c] = None\n",
    "\n",
    "    # SHOW CSV STRUCTURE\n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"CSV STRUCTURE ANALYSIS\")\n",
    "    logger.debug(\"=\"*80)\n",
    "    logger.debug(\"\\n[TRAIN CSV]\")\n",
    "    logger.debug(f\"Columns: {list(train_df.columns)}\")\n",
    "    logger.debug(\"\\n[TEST CSV]\")\n",
    "    logger.debug(f\"Columns: {list(test_df.columns)}\")\n",
    "\n",
    "    # EXTRACT TEMPORAL FEATURES (TRAIN ONLY) \n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"EXTRACT TEMPORAL FEATURES (TRAIN ONLY)\")\n",
    "    logger.debug(\"=\"*80)\n",
    "\n",
    "    train_df['Sampling_Date'] = pd.to_datetime(train_df['Sampling_Date'], errors='coerce')\n",
    "    # create Month/DayOfYear/Quarter only if datetime parsed\n",
    "    train_df['Month'] = train_df['Sampling_Date'].dt.month.fillna(1).astype(int)\n",
    "    train_df['DayOfYear'] = train_df['Sampling_Date'].dt.dayofyear.fillna(1).astype(int)\n",
    "    train_df['Quarter'] = train_df['Sampling_Date'].dt.quarter.fillna(1).astype(int)\n",
    "\n",
    "    logger.debug(\"âœ“ Temporal features extracted from TRAIN \")\n",
    "\n",
    "    # Ensure State and Species and target_name exist and normalize (safe)\n",
    "    train_df['State'] = train_df['State'].astype(str).fillna('').str.strip()\n",
    "    train_df['Species'] = train_df['Species'].astype(str).fillna('').str.strip()\n",
    "    train_df['target_name'] = train_df['target_name'].astype(str).fillna('').str.strip()\n",
    "\n",
    "    def _state_canon_or_unknown(x):\n",
    "        s = str(x).strip()\n",
    "        if s == \"\":\n",
    "            return \"unknown\"\n",
    "        return _normalize_state_for_onehot(x)\n",
    "    \n",
    "    train_df['State_canon'] = train_df['State'].apply(_state_canon_or_unknown)\n",
    "    state_cols_train = pd.get_dummies(train_df['State_canon'], prefix='State')\n",
    "    train_df = pd.concat([train_df, state_cols_train], axis=1)\n",
    "    logger.debug(f\"âœ“ State encoded: {len(state_cols_train.columns)} categories\")\n",
    "    logger.debug(f\" Unique states in train: {train_df['State_canon'].nunique()}\")\n",
    "    \n",
    "    train_df['Species_mapped'] = train_df['Species'].apply(map_to_fixed_species)\n",
    "    train_df['Species_canon'] = pd.Categorical(train_df['Species_mapped'], categories=FIXED_SPECIES_LIST)\n",
    "    species_cols_train = pd.get_dummies(train_df['Species_canon'], prefix='Species').reindex(\n",
    "        columns=[f\"Species_{s}\" for s in FIXED_SPECIES_LIST], fill_value=0)\n",
    "    train_df = pd.concat([train_df, species_cols_train], axis=1)\n",
    "\n",
    "    # ONE-HOT ENCODE TARGET TYPE (TRAIN ONLY)\n",
    "    target_onehot = pd.get_dummies(train_df['target_name'], prefix='target_type')\n",
    "    train_df = pd.concat([train_df, target_onehot], axis=1)\n",
    "    logger.debug(f\"âœ“ Target types encoded: {len(target_onehot.columns)} categories\")\n",
    "\n",
    "\n",
    "    STATE_COLS = [\n",
    "        col for col in train_df.columns\n",
    "        if col.startswith('State_') and col not in ('State_canon', 'State_') and re.match(r'^State_[A-Za-z0-9]', col)]\n",
    "\n",
    "    if len(STATE_COLS) < 4:\n",
    "        for i in range(len(STATE_COLS), 4):\n",
    "            col_name = f\"State_extra_{i}\"\n",
    "            train_df[col_name] = 0\n",
    "            STATE_COLS.append(col_name)\n",
    "    \n",
    "    SPECIES_COLS = [\n",
    "        col for col in train_df.columns\n",
    "        if col.startswith('Species_') and col not in ('Species_mapped','Species_canon', 'Species_') and re.match(r'^Species_[A-Za-z0-9]', col)]\n",
    "    \n",
    "    TARGET_TYPE_COLS = [\n",
    "        col for col in train_df.columns\n",
    "        if col.startswith('target_type_') and re.match(r'^target_type_[A-Za-z0-9]', col)]\n",
    "\n",
    "    numeric_cols = []\n",
    "    if 'Pre_GSHH_NDVI' in train_df.columns:\n",
    "        numeric_cols.append('Pre_GSHH_NDVI')\n",
    "    if 'Height_Ave_cm' in train_df.columns:\n",
    "        numeric_cols.append('Height_Ave_cm')\n",
    "    for col in ['Month', 'DayOfYear', 'Quarter']:\n",
    "        if col in train_df.columns:\n",
    "            numeric_cols.append(col)\n",
    "    \n",
    "    TOTAL_TABULAR_DIM = len(numeric_cols) + len(STATE_COLS) + len(SPECIES_COLS) + len(TARGET_TYPE_COLS)\n",
    "\n",
    "    #sanity check for tabular dimension \n",
    "    calc = len(numeric_cols) + len(STATE_COLS) + len(SPECIES_COLS) + len(TARGET_TYPE_COLS)\n",
    "    if calc != TOTAL_TABULAR_DIM:\n",
    "        logger.warning(\n",
    "            f\"TOTAL_TABULAR_DIM mismatch: computed={calc}, declared={TOTAL_TABULAR_DIM}\")\n",
    "    else:\n",
    "        logger.info(f\"TOTAL_TABULAR_DIM consistent {TOTAL_TABULAR_DIM}\")\n",
    "\n",
    "    scaler = None\n",
    "    if len(numeric_cols) > 0:\n",
    "        df_num = train_df[numeric_cols].copy()\n",
    "        if 'Height_Ave_cm' in df_num.columns:\n",
    "            df_num['Height_Ave_cm'] = df_num['Height_Ave_cm'].astype(float).fillna(10.0)\n",
    "            df_num['Height_Ave_cm'] = np.clip(df_num['Height_Ave_cm'], 0.0, 100.0)\n",
    "            \n",
    "        if 'Month' in df_num.columns:\n",
    "            df_num['Month'] = df_num['Month'].astype(float).fillna(6)\n",
    "            df_num['Month'] = np.clip(df_num['Month'], 1.0, 12.0)\n",
    "            \n",
    "        if 'DayOfYear' in df_num.columns:\n",
    "            df_num['DayOfYear'] = df_num['DayOfYear'].astype(float).fillna(1)\n",
    "            df_num['DayOfYear'] = np.clip(df_num['DayOfYear'], 1.0, 365.0)\n",
    "            \n",
    "        if 'Quarter' in df_num.columns:\n",
    "            df_num['Quarter'] = df_num['Quarter'].astype(float).fillna(1)\n",
    "            df_num['Quarter'] = np.clip(df_num['Quarter'], 1.0, 4.0)\n",
    "            \n",
    "        if 'Pre_GSHH_NDVI' in df_num.columns:\n",
    "            df_num['Pre_GSHH_NDVI'] = df_num['Pre_GSHH_NDVI'].astype(float).fillna(0.5)\n",
    "            df_num['Pre_GSHH_NDVI'] = np.clip(df_num['Pre_GSHH_NDVI'], 0.0, 1.0)\n",
    "    \n",
    "        scaler = RobustScaler()\n",
    "        scaler.fit(df_num.values) \n",
    "        \n",
    "        try:\n",
    "            joblib.dump(scaler, OUTPUTS_DIR / \"tabular_scaler.joblib\")\n",
    "            logger.debug(\"âœ“ Saved tabular scaler to outputs/tabular_scaler.joblib\")\n",
    "        except Exception:\n",
    "            logger.debug(\"Could not persist tabular scaler to disk (continuing).\")\n",
    "            \n",
    "        # store scaler in lookups dict \n",
    "        lookups_dict['TAB_SCALER'] = scaler\n",
    "        lookups_dict['TAB_NUMERIC_COLS'] = numeric_cols\n",
    "        lookups_dict['STATE_COLS'] = STATE_COLS\n",
    "        lookups_dict['UNIQUE_SPECIES'] = [s.lower().replace('.', '').replace(' ', '_') for s in FIXED_SPECIES_LIST]\n",
    "        SPECIES_COLS = list(species_cols_train.columns)\n",
    "        lookups_dict['SPECIES_COLS'] = SPECIES_COLS\n",
    "        lookups_dict['TARGET_TYPE_COLS'] = TARGET_TYPE_COLS\n",
    "        lookups_dict['TOTAL_TABULAR_DIM'] = TOTAL_TABULAR_DIM  \n",
    "        \n",
    "    else:\n",
    "        lookups_dict['TAB_SCALER'] = None\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TABULAR FEATURE DIMENSIONS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"âœ“ Feature dimensions:\")\n",
    "    logger.info(f\" Numeric base count: {len(numeric_cols)}\")\n",
    "    logger.info(f\" State one-hot: {len(STATE_COLS)}\")\n",
    "    logger.info(f\" Species one-hot: {len(SPECIES_COLS)}\")\n",
    "    logger.info(f\" Target Type one-hot: {len(TARGET_TYPE_COLS)}\")\n",
    "    logger.info(f\" TOTAL_TABULAR_DIM: {TOTAL_TABULAR_DIM}\")\n",
    "\n",
    "    # CREATE TARGET-SPECIFIC LOOKUP INDEXES FOR ALL LEVELS\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"BUILDING TARGET-SPECIFIC LOOKUP INDEXES\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    # LEVEL 1: By STATE + SPECIES + TARGET \n",
    "    TRAIN_BY_TARGET_STATE_SPECIES = {}\n",
    "    \n",
    "    def _norm_key(x):\n",
    "        if pd.isna(x):\n",
    "            return 'unknown'\n",
    "        s = str(x).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)  \n",
    "        s = s.replace('.', '')\n",
    "        return s\n",
    "    \n",
    "    for target in train_df['target_name'].astype(str).unique():\n",
    "        target_name = str(target).strip().lower()\n",
    "        TRAIN_BY_TARGET_STATE_SPECIES[target_name] = {}\n",
    "        target_df_filtered = train_df[train_df['target_name'].astype(str).str.strip().str.lower() == target_name]\n",
    "    \n",
    "        for idx, row in target_df_filtered.iterrows():\n",
    "            raw_state = row.get('State', '')\n",
    "            state_norm_onehot = _normalize_state_for_onehot(raw_state)   \n",
    "            state_lookup_key = _norm_key(raw_state)\n",
    "            species_lookup = _norm_key(row.get('Species', 'mixed'))\n",
    "            rd = row.to_dict()\n",
    "            rd['_state_onehot_repr'] = state_norm_onehot\n",
    "            rd['_state_lookup'] = state_lookup_key\n",
    "        \n",
    "            TRAIN_BY_TARGET_STATE_SPECIES[target_name] \\\n",
    "                .setdefault(state_lookup_key, {}) \\\n",
    "                .setdefault(species_lookup, []) \\\n",
    "                .append(rd)\n",
    "\n",
    "    \n",
    "    # Diagnostics: log counts and examples\n",
    "    logger.debug(f\"\\nâœ“ LEVEL 1 INDEX: By (Target, State, Species) â€” normalized keys\")\n",
    "    total_row_count = 0\n",
    "    for target_name, state_dict in TRAIN_BY_TARGET_STATE_SPECIES.items():\n",
    "        unique_combos = sum(len(species_dict) for species_dict in state_dict.values())\n",
    "        rows_for_target = sum(sum(len(species_dict[k]) for k in species_dict) for species_dict in state_dict.values())\n",
    "        total_row_count += rows_for_target\n",
    "        logger.info(f\" {target_name}: {unique_combos} unique (State,Species) combos â€” {rows_for_target} rows indexed\")\n",
    "    \n",
    "    logger.debug(f\"Total rows indexed in LEVEL 1: {total_row_count} (train_df rows: {len(train_df)})\")\n",
    "\n",
    "    # LEVEL 2: By SAMPLE_ID + TARGET\n",
    "    TRAIN_BY_SAMPLE_ID_TARGET = {}\n",
    "    for idx, row in train_df.iterrows():\n",
    "        target_name = str(row.get('target_name', '')).strip().lower()\n",
    "        sample_id_key = str(row.get('sample_id', '')).strip().lower()\n",
    "        TRAIN_BY_SAMPLE_ID_TARGET.setdefault(target_name, {}).setdefault(sample_id_key, []).append(row.to_dict())\n",
    "\n",
    "    logger.debug(f\"\\nâœ“ LEVEL 2 INDEX: By (Target, sample_id)\")\n",
    "    logger.info(f\" Size: {sum(len(samples) for samples in TRAIN_BY_SAMPLE_ID_TARGET.values())} total entries\")\n",
    "\n",
    "    # LEVEL 3: By IMAGE_ID + TARGET \n",
    "    TRAIN_BY_IMAGE_ID_TARGET = {}\n",
    "    for idx, row in train_df.iterrows():\n",
    "        target_name = str(row.get('target_name', '')).strip().lower()\n",
    "        image_id = str(row.get('sample_id', '')).strip().lower().split('__')[0]\n",
    "        TRAIN_BY_IMAGE_ID_TARGET.setdefault(target_name, {}).setdefault(image_id, []).append(row.to_dict())\n",
    "    \n",
    "    logger.debug(f\"\\nâœ“ LEVEL 3: By (Target, image_id)\")\n",
    "    logger.debug(f\" Size: {sum(len(images) for images in TRAIN_BY_IMAGE_ID_TARGET.values())} total entries\")\n",
    "\n",
    "    # LEVEL 4: STATISTICS BY TARGET\n",
    "    logger.info(f\"\\nâœ“ LEVEL 4 INDEX: By Target (Statistics)\")\n",
    "    TABULAR_STATS = {\n",
    "        'height_mean': float(train_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'height_std': float(train_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'ndvi_mean': float(train_df['Pre_GSHH_NDVI'].mean()) if 'Pre_GSHH_NDVI' in train_df.columns else 0.0,\n",
    "        'ndvi_std': float(train_df['Pre_GSHH_NDVI'].std()) if 'Pre_GSHH_NDVI' in train_df.columns else 0.0,\n",
    "        'height_mean_cm': float(train_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'height_std_cm': float(train_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        # normalized versions \n",
    "        'height_mean_norm': (float(train_df['Height_Ave_cm'].mean())) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'height_std_norm': (float(train_df['Height_Ave_cm'].std())) if 'Height_Ave_cm' in train_df.columns else 0.0,\n",
    "        'sampling_date_mean': float(train_df['DayOfYear'].mean()) if 'DayOfYear' in train_df.columns else 0.0,\n",
    "    }\n",
    "\n",
    "    TABULAR_STATS_BY_TARGET = {}\n",
    "    for target_name in ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']:\n",
    "        tkey = str(target_name).strip().lower()\n",
    "        target_df = train_df[train_df['target_name'].astype(str).str.strip().str.lower() == tkey]\n",
    "\n",
    "        TABULAR_STATS_BY_TARGET[tkey] = {\n",
    "            'ndvi_mean': float(target_df['Pre_GSHH_NDVI'].mean()) if 'Pre_GSHH_NDVI' in target_df.columns else 0.0,\n",
    "            'ndvi_std': float(target_df['Pre_GSHH_NDVI'].std()) if 'Pre_GSHH_NDVI' in target_df.columns else 0.0,\n",
    "        \n",
    "            # original cm values\n",
    "            'height_mean_cm': float(target_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'height_std_cm': float(target_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "        \n",
    "            # canonical names used elsewhere\n",
    "            'height_mean': float(target_df['Height_Ave_cm'].mean()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'height_std': float(target_df['Height_Ave_cm'].std()) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "        \n",
    "            # normalized \n",
    "            'height_mean_norm': (float(target_df['Height_Ave_cm'].mean())) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'height_std_norm': (float(target_df['Height_Ave_cm'].std())) if 'Height_Ave_cm' in target_df.columns else 0.0,\n",
    "            'sampling_date_mean': float(target_df['DayOfYear'].mean()) if 'DayOfYear' in target_df.columns else 0.0,\n",
    "            'count': int(len(target_df)),\n",
    "        }\n",
    "\n",
    "    for target_name, stats in TABULAR_STATS_BY_TARGET.items():\n",
    "        logger.info(f\" {target_name}:\")\n",
    "        logger.info(f\" NDVI: {stats['ndvi_mean']:.3f} Â± {stats['ndvi_std']:.3f}\")\n",
    "        logger.info(f\" Height: {stats['height_mean']:.1f} Â± {stats['height_std']:.3f}\")\n",
    "        logger.info(f\" Count: {stats['count']} samples\")\n",
    "\n",
    "    try:\n",
    "        raw_states = train_df.get('State_canon')\n",
    "        if raw_states is None:\n",
    "            UNIQUE_STATES = []\n",
    "        else:\n",
    "            # If categorical, use categories \n",
    "            if pd.api.types.is_categorical_dtype(raw_states):\n",
    "                states_list = list(raw_states.cat.categories)\n",
    "            else:\n",
    "                states_list = raw_states.astype(str).str.strip().replace({'nan': ''}).loc[lambda x: x != ''].unique().tolist()\n",
    "            UNIQUE_STATES = [str(s).strip() for s in states_list if str(s).strip() != '']\n",
    "        UNIQUE_STATES = sorted(list(dict.fromkeys(UNIQUE_STATES))) \n",
    "    except Exception:\n",
    "        UNIQUE_STATES = []\n",
    "    \n",
    "    try:\n",
    "        if 'FIXED_SPECIES_LIST' in globals():\n",
    "            UNIQUE_SPECIES = [\n",
    "                re.sub(r\"[\\s\\-]+\", \"_\", s.strip()).replace('.', '')\n",
    "                for s in FIXED_SPECIES_LIST]\n",
    "        else:\n",
    "            sp = train_df.get('Species_canon')\n",
    "            if sp is None:\n",
    "                UNIQUE_SPECIES = []\n",
    "            else:\n",
    "                if pd.api.types.is_categorical_dtype(sp):\n",
    "                    raw_list = list(sp.cat.categories)\n",
    "                else:\n",
    "                    raw_list = sp.astype(str).str.strip().replace({'nan': ''}).loc[lambda x: x != ''].unique().tolist()\n",
    "                UNIQUE_SPECIES = [re.sub(r\"[\\s\\-]+\", \"_\", str(s).strip()).replace('.', '') for s in raw_list if str(s).strip() != '']\n",
    "        UNIQUE_SPECIES = list(dict.fromkeys(UNIQUE_SPECIES))\n",
    "    except Exception:\n",
    "        UNIQUE_SPECIES = []\n",
    "    \n",
    "    try:\n",
    "        if 'TARGET_TYPE_COLS' in locals() or 'TARGET_TYPE_COLS' in globals():\n",
    "            cols = TARGET_TYPE_COLS if 'TARGET_TYPE_COLS' in locals() else globals().get('TARGET_TYPE_COLS', [])\n",
    "            UNIQUE_TARGET_TYPES = [c.replace('target_type_', '') for c in cols]\n",
    "        else:\n",
    "            UNIQUE_TARGET_TYPES = train_df['target_name'].astype(str).str.strip().replace({'nan': ''}).loc[lambda x: x != ''].unique().tolist()\n",
    "        UNIQUE_TARGET_TYPES = [str(t).strip() for t in UNIQUE_TARGET_TYPES if str(t).strip() != '']\n",
    "    except Exception:\n",
    "        UNIQUE_TARGET_TYPES = []\n",
    "\n",
    "    logger.info(f\"\\nâœ“ Unique values (for fallback logic):\")\n",
    "    logger.info(f\" States: {UNIQUE_STATES}\")\n",
    "    logger.info(f\" Species: {UNIQUE_SPECIES}\")\n",
    "    logger.info(f\" Target Types: {UNIQUE_TARGET_TYPES}\")\n",
    "\n",
    "    rows_map, stats_map = create_species_lookup_tables(train_df)\n",
    "    \n",
    "    # CREATE LOOKUPS DICTIONARY \n",
    "    lookups_dict_target = {\n",
    "        # Target-specific indexes\n",
    "        'TRAIN_BY_SAMPLE_ID_TARGET': TRAIN_BY_SAMPLE_ID_TARGET,\n",
    "        'TRAIN_BY_IMAGE_ID_TARGET': TRAIN_BY_IMAGE_ID_TARGET,\n",
    "        'TRAIN_BY_TARGET_STATE_SPECIES': TRAIN_BY_TARGET_STATE_SPECIES,\n",
    "        'TABULAR_STATS_BY_TARGET': TABULAR_STATS_BY_TARGET,\n",
    "    \n",
    "        # Global stats\n",
    "        'TABULAR_STATS': TABULAR_STATS,\n",
    "    \n",
    "        # Utility data\n",
    "        'UNIQUE_STATES': UNIQUE_STATES,\n",
    "        'UNIQUE_SPECIES': UNIQUE_SPECIES,\n",
    "        'UNIQUE_TARGET_TYPES': UNIQUE_TARGET_TYPES,\n",
    "        'STATE_COLS': STATE_COLS,\n",
    "        'SPECIES_COLS': SPECIES_COLS,\n",
    "        'TARGET_TYPE_COLS': TARGET_TYPE_COLS,\n",
    "        'TRAIN_DF': train_df,\n",
    "    \n",
    "        # Species lookup \n",
    "        'TRAIN_BY_IMAGE_SPECIES_TARGET': rows_map,\n",
    "        'TRAIN_BY_IMAGE_SPECIES_TARGET_STATS': stats_map,\n",
    "    \n",
    "        # numeric / scaler for dataset pipeline \n",
    "        'TAB_NUMERIC_COLS': numeric_cols,\n",
    "        'TAB_SCALER': lookups_dict.get('TAB_SCALER', None) if isinstance(lookups_dict, dict) else None,\n",
    "        'TOTAL_TABULAR_DIM': TOTAL_TABULAR_DIM,\n",
    "    }\n",
    "\n",
    "    if isinstance(lookups_dict, dict):\n",
    "        lookups_dict.update(lookups_dict_target)\n",
    "    else:\n",
    "        lookups_dict = lookups_dict_target\n",
    "        \n",
    "    # DISPLAY DATASET OVERVIEW\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"DATASET OVERVIEW\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"\\n[TRAIN SET]\")\n",
    "    logger.info(f\"Shape: {train_df.shape}\")\n",
    "    logger.info(f\"Columns: {len(train_df.columns)} total\")\n",
    "    logger.info(f\"Missing values: {train_df.isnull().sum().sum()} total\")\n",
    "   \n",
    "    logger.info(\"\\n[TEST SET]\")\n",
    "    logger.info(f\"Shape: {test_df.shape}\")\n",
    "    logger.info(f\"Columns: {len(test_df.columns)} total\")\n",
    "    logger.info(f\" Columns present: sample_id, image_path, target_name\")\n",
    "    logger.info(f\" Columns missing: Sampling_Date, State, Species, Pre_GSHH_NDVI, Height_Ave_cm\")\n",
    "    logger.info(f\"Missing values: {test_df.isnull().sum().sum()} total\")\n",
    "   \n",
    "    # STATISTICAL SUMMARIES\n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"STATISTICAL SUMMARY (TRAINING SET)\")\n",
    "    logger.debug(\"=\"*80)\n",
    "   \n",
    "    logger.debug(\"\\n[Target Variable Statistics]\")\n",
    "    logger.debug(f\" Count: {train_df['target'].count()}\")\n",
    "    logger.debug(f\" Mean: {train_df['target'].mean():.4f}\")\n",
    "    logger.debug(f\" Std: {train_df['target'].std():.4f}\")\n",
    "    logger.debug(f\" Min: {train_df['target'].min():.4f}\")\n",
    "    logger.debug(f\" Max: {train_df['target'].max():.4f}\")\n",
    "   \n",
    "    logger.info(\"\\n[NDVI Statistics]\")\n",
    "    if 'Pre_GSHH_NDVI' in train_df.columns:\n",
    "        logger.info(f\" Range: [{train_df['Pre_GSHH_NDVI'].min():.3f}, {train_df['Pre_GSHH_NDVI'].max():.3f}]\")\n",
    "        logger.info(f\" Mean: {train_df['Pre_GSHH_NDVI'].mean():.3f}\")\n",
    "        logger.info(f\" Std: {train_df['Pre_GSHH_NDVI'].std():.3f}\")\n",
    "    else:\n",
    "        logger.info(\" Pre_GSHH_NDVI: not available\")\n",
    "   \n",
    "    logger.info(\"\\n[Height Statistics]\")\n",
    "    if 'Height_Ave_cm' in train_df.columns:\n",
    "        logger.info(f\" Range: [{train_df['Height_Ave_cm'].min():.2f}, {train_df['Height_Ave_cm'].max():.2f}] cm\")\n",
    "        logger.info(f\" Mean: {train_df['Height_Ave_cm'].mean():.2f} cm\")\n",
    "        logger.info(f\" Std: {train_df['Height_Ave_cm'].std():.2f} cm\")\n",
    "    else:\n",
    "        logger.info(\" Height_Ave_cm: not available\")\n",
    "   \n",
    "    # TARGET DISTRIBUTION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TARGET DISTRIBUTION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    target_counts = train_df['target_name'].value_counts()\n",
    "    for target, count in target_counts.items():\n",
    "        logger.info(f\" {target}: {count} samples\")\n",
    "   \n",
    "    # STATE DISTRIBUTION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"STATE DISTRIBUTION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    state_counts = train_df['State'].value_counts()\n",
    "    for state, count in state_counts.items():\n",
    "        logger.info(f\" {state}: {count} samples\")\n",
    "   \n",
    "    # VISUALIZATIONS\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"CREATING VISUALIZATIONS\")\n",
    "    logger.info(\"=\"*80)\n",
    "   \n",
    "    try:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "       \n",
    "        # Target distribution by type\n",
    "        target_means = train_df.groupby('target_name')['target'].mean()\n",
    "        target_means.plot(kind='bar', ax=axes[0, 0])\n",
    "        axes[0, 0].set_title('Average Target Value by Type', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_ylabel('Target Value (g)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "       \n",
    "        # NDVI distribution\n",
    "        if 'Pre_GSHH_NDVI' in train_df.columns:\n",
    "            axes[0, 1].hist(train_df['Pre_GSHH_NDVI'].dropna(), bins=30)\n",
    "            axes[0, 1].set_title('NDVI Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[0, 1].set_xlabel('NDVI Value')\n",
    "            axes[0, 1].set_ylabel('Frequency')\n",
    "       \n",
    "        # Height distribution\n",
    "        if 'Height_Ave_cm' in train_df.columns:\n",
    "            axes[1, 0].hist(train_df['Height_Ave_cm'].dropna(), bins=30)\n",
    "            axes[1, 0].set_title('Height Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[1, 0].set_xlabel('Height (cm)')\n",
    "            axes[1, 0].set_ylabel('Frequency')\n",
    "       \n",
    "        # Target value distribution by type (box plot)\n",
    "        train_df.boxplot(column='target', by='target_name', ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Target Distribution by Type', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Target Value (g)')\n",
    "       \n",
    "        plt.tight_layout()\n",
    "        try:\n",
    "            plt.savefig(OUTPUTS_DIR / 'eda_visualizations.png', dpi=100, bbox_inches='tight')\n",
    "            logger.info(f\"âœ“ EDA visualizations saved to {OUTPUTS_DIR / 'eda_visualizations.png'}\")\n",
    "        except Exception:\n",
    "            # Fallback: save locally if OUTPUTS_DIR not available\n",
    "            plt.savefig('eda_visualizations.png', dpi=100, bbox_inches='tight')\n",
    "            logger.info(\"âœ“ EDA visualizations saved to eda_visualizations.png\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"âš  Could not save visualizations: {e}\")\n",
    "   \n",
    "    # CORRELATION ANALYSIS\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"CORRELATION ANALYSIS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    numeric_cols = [c for c in ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'target'] if c in train_df.columns]\n",
    "    if len(numeric_cols) >= 2:\n",
    "        corr_matrix = train_df[numeric_cols].corr()\n",
    "        logger.info(\"\\nCorrelation Matrix:\")\n",
    "        logger.info(corr_matrix.to_string())\n",
    "    else:\n",
    "        logger.info(\"Not enough numeric columns for correlation analysis\")\n",
    "   \n",
    "    # DATA QUALITY CHECK\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"DATA QUALITY CHECK\")\n",
    "    logger.info(\"=\"*80)\n",
    "   \n",
    "    duplicates = train_df.duplicated(subset=['image_path','target_name']).sum() if 'image_path' in train_df.columns else 0\n",
    "    logger.info(f\"Duplicate (image, target) pairs: {duplicates}\")\n",
    "   \n",
    "    if 'target' in train_df.columns and train_df['target'].std() > 0:\n",
    "        z_scores = np.abs((train_df['target'] - train_df['target'].mean()) / train_df['target'].std())\n",
    "        outliers = (z_scores > 3).sum()\n",
    "    else:\n",
    "        outliers = 0\n",
    "    logger.info(f\"Potential outliers (|Z-score| > 3): {outliers}\")\n",
    "   \n",
    "    logger.info(\"\\nâœ“ EDA completed successfully\")\n",
    "    logger.debug(\"=\"*80 + \"\\n\")\n",
    "    # MEMORY USAGE TRACKING\n",
    "    logger.debug(\"\\n\" + \"=\"*80)\n",
    "    logger.debug(\"MEMORY USAGE\")\n",
    "    logger.debug(\"=\"*80)\n",
    "    logger.debug(f\"Train DataFrame: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    logger.debug(f\"Test DataFrame: {test_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "   \n",
    "    # LOOKUP INTEGRITY VALIDATION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"LOOKUP VALIDATION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    total_level1 = sum(sum(len(rows) for rows in target_dict.values())\n",
    "                       for target_dict in TRAIN_BY_SAMPLE_ID_TARGET.values())\n",
    "    total_level2 = sum(sum(1 for _ in target_dict.keys())\n",
    "                       for target_dict in TRAIN_BY_IMAGE_ID_TARGET.values())\n",
    "    total_level3 = sum(sum(sum(len(rows) for rows in species_dict.values()) for species_dict in state_dict.values())\n",
    "                       for state_dict in TRAIN_BY_TARGET_STATE_SPECIES.values())\n",
    "    logger.info(f\"âœ“ LEVEL 1: {total_level1} rows indexed (expected: {len(train_df)})\")\n",
    "    logger.info(f\"âœ“ LEVEL 2: {total_level2} rows indexed (expected: {len(train_df)})\")\n",
    "    logger.info(f\"âœ“ LEVEL 3: {total_level3} rows indexed (expected: {len(train_df)})\")\n",
    "   \n",
    "    # FEATURE ENCODING VALIDATION\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"FEATURE ENCODING VALIDATION\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    def _safe_row_sum(row, cols):\n",
    "        \"\"\"\n",
    "        Given a pandas Series row and a list-like cols (may be empty),\n",
    "        return numeric sum of those columns coercing non-numeric -> 0.0.\n",
    "        \"\"\"\n",
    "        if not cols:\n",
    "            return 0.0\n",
    "        if isinstance(cols, str):\n",
    "            cols = [cols]\n",
    "        vals = row.loc[cols] if hasattr(row, 'loc') else pd.Series(dtype=float)\n",
    "        numeric_vals = pd.to_numeric(vals, errors='coerce').fillna(0.0)\n",
    "        return float(numeric_vals.sum())\n",
    "    \n",
    "    try:\n",
    "        sample_row = train_df.iloc[0]\n",
    "    except Exception:\n",
    "        sample_row = pd.Series(dtype=float)\n",
    "\n",
    "    if isinstance(STATE_COLS, str):\n",
    "        STATE_COLS = [STATE_COLS]\n",
    "    if isinstance(SPECIES_COLS, str):\n",
    "        SPECIES_COLS = [SPECIES_COLS]\n",
    "    if isinstance(TARGET_TYPE_COLS, str):\n",
    "        TARGET_TYPE_COLS = [TARGET_TYPE_COLS]\n",
    "    \n",
    "    state_sum = _safe_row_sum(sample_row, STATE_COLS)\n",
    "    species_sum = _safe_row_sum(sample_row, SPECIES_COLS)\n",
    "    target_sum = _safe_row_sum(sample_row, TARGET_TYPE_COLS)\n",
    "    \n",
    "    tol = 1e-6\n",
    "    logger.info(f\"âœ“ State one-hot sum: {state_sum} (expected: ~1.0)\")\n",
    "    logger.info(f\"âœ“ Species one-hot sum: {species_sum} (expected: ~1.0)\")\n",
    "    logger.info(f\"âœ“ Target one-hot sum: {target_sum} (expected: ~1.0)\")\n",
    "    if abs(state_sum - 1.0) < tol and abs(species_sum - 1.0) < tol and abs(target_sum - 1.0) < tol:\n",
    "        logger.info(f\"âœ“ All encodings valid!\")\n",
    "    else:\n",
    "        logger.warning(\"One-hot encoding sums deviate from 1.0 within tolerance; check categories and missing values.\")\n",
    "\n",
    "    return train_df, test_df, STATE_COLS, SPECIES_COLS, TARGET_TYPE_COLS, TOTAL_TABULAR_DIM, lookups_dict, original_test_df\n",
    "\n",
    "logger.info(\"âœ“ Exploratory Data Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3c8a",
   "metadata": {},
   "source": [
    "## 4: DATA AUGMENTATION AND PREPARATION\n",
    "\n",
    "**Purpose**: Create dataset classes and data loaders with patch-based processing, improved feature estimation, and intelligent fallback.\n",
    "\n",
    "### BiomassDataset Class\n",
    "\n",
    "**Modes**:\n",
    "- `train`: Augmentation enabled, extract from training data\n",
    "- `val`: No augmentation, extract from training data\n",
    "- `test`: No augmentation, intelligent feature fetching with 4-level fallback\n",
    "\n",
    "**Image Processing Pipeline**:\n",
    "```\n",
    "2000Ã—1000 Image\n",
    "    â†“\n",
    "Extract 8 patches (500Ã—500 each)\n",
    "â”œâ”€ Patches 1-4: Top half (y: 0-500)\n",
    "â””â”€ Patches 5-8: Bottom half (y: 500-1000)\n",
    "    â†“\n",
    "Resize each to 224Ã—224\n",
    "    â†“\n",
    "Stack into [8, 3, 224, 224] tensor\n",
    "    â†“\n",
    "Normalize (ImageNet mean/std)\n",
    "```\n",
    "\n",
    "**Data Augmentation** (Training Only):\n",
    "- Horizontal flip: 50% probability\n",
    "- Vertical flip: 50% probability\n",
    "- Random rotation: Â±15Â°\n",
    "- Color jitter: brightness, contrast, saturation variation\n",
    "- Affine transform: Â±10% translation\n",
    "\n",
    "**Validation/Test**: Deterministic (no augmentation)\n",
    "\n",
    "**Feature Extraction** (IMPROVED):\n",
    "\n",
    "For each sample, extract/estimate tabular features:\n",
    "\n",
    "| Feature | Train/Val | Test Strategy |\n",
    "|---------|-----------|---|\n",
    "| NDVI | From training data | Level 1-3: training data lookup, Level 3a: estimated from image |\n",
    "| Height | From training data | Level 1-3: training data lookup, Level 3a: **estimated from image (4-factor: texture+green+NDVI+brightness)** |\n",
    "| Month | From training date | Level 1-3: training data lookup, Level 3a: **data-driven from NDVI (Gaussian likelihood, not random)** |\n",
    "| Species | From training data | Level 1-3: training data lookup, Level 2a-3a: **predicted from image via species model** |\n",
    "| State | From training data | Level 1-3: training data lookup, Level 4: random from available states |\n",
    "\n",
    "**Intelligent Fallback (4 Levels)**:\n",
    "\n",
    "| Level | Trigger | Features From | Quality |\n",
    "|-------|---------|---|---|\n",
    "| **1** | State + predicted species | Hybrid (lookup + image estimate) | â­â­â­ Medium |\n",
    "| **2** | Exact match (sample_id + target) | Training data | â­â­â­â­â­ Highest |\n",
    "| **3** | Image ID + species | Training data lookup | â­â­â­â­ High |\n",
    "| **4** | Not found (guaranteed to succeed) |  Statistics | â­â­ Low |\n",
    "\n",
    "\n",
    "**Success Rates**:\n",
    "- Level 1: ~50-70% (hybrid match)\n",
    "- Level 2: ~5-10% (exact match rare)\n",
    "- Level 3: ~20-30% (image+species match)\n",
    "- Level 4: 100% (always succeeds)\n",
    "\n",
    "**Key Improvements**:- \n",
    "- âœ… **Better NDVI calculation:** Proper NIR channel (RGBN) with smart RGB fallback. Eliminates negative RÂ² in vegetation areas.\n",
    "- âœ… **Better height (4-factor):** Combines NDVI proxy, texture features, species scaling, and seasonal context.  more realistic across species.\n",
    "- âœ… **Better month (data-driven):** Bayesian inference from training NDVI distribution. Prediction accuracy +45%, captures seasonal growth patterns.\n",
    "- âœ… **Species integration:** ViT image classifier with 4-patch majority voting. Enables species-specific ensemble routing.\n",
    "- âœ… **Robust fallback:** 5-level cascading fallbacks (full â†’ minimal â†’ constants). 100% pipeline success rate, never fails on edge cases.\n",
    "\n",
    "```\n",
    "\n",
    "                TEST SAMPLE (Missing: NDVI, Height, Month, Species, State)\n",
    "                                            â†“\n",
    "\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚      LEVEL 1a v1: STATE + PREDICTED SPECIES (PRIMARY)           â”‚\n",
    "                â”‚         Uses Estimated Features from Image                      â”‚\n",
    "                â”‚              85% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_TARGET_STATE_SPECIES[state][pred_species]\n",
    "                    Hit rate: ~35% (624/1,785)\n",
    "                    \n",
    "                    IF FOUND (any state):\n",
    "                    âœ… Use any state with matching predicted species\n",
    "                    â”œâ”€ NDVI (estimated from image via multi-factor)\n",
    "                    â”œâ”€ Height (estimated from image texture/color/NDVI)\n",
    "                    â”œâ”€ Month (estimated via Gaussian likelihood on NDVI)\n",
    "                    â”œâ”€ DayOfYear, Quarter (derived from month)\n",
    "                    â”œâ”€ Species (predicted from ViT)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                    IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚      LEVEL 1a v2: STATE + PREDICTED SPECIES (RETRY)             â”‚\n",
    "                â”‚        Uses Training Data Features (Fallback Features)          â”‚\n",
    "                â”‚              75% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_TARGET_STATE_SPECIES[state][pred_species]\n",
    "                \n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use any state with matching predicted species\n",
    "                    â”œâ”€ NDVI (from training data)\n",
    "                    â”œâ”€ Height (from training data)\n",
    "                    â”œâ”€ Month (from training data)\n",
    "                    â”œâ”€ DayOfYear, Quarter (from training data)\n",
    "                    â”œâ”€ Species (predicted from ViT)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                    IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚       LEVEL 1b: RANDOM STATE + SPECIES                          â”‚\n",
    "                â”‚         Guaranteed Hit (Safety Net)                             â”‚\n",
    "                â”‚              70% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_TARGET_STATE_SPECIES (any entry)\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Random state + random species from this target\n",
    "                    â”œâ”€ NDVI (from training data)\n",
    "                    â”œâ”€ Height (from training data)\n",
    "                    â”œâ”€ Month (from training data)\n",
    "                    â”œâ”€ DayOfYear, Quarter (from training data)\n",
    "                    â”œâ”€ Species (random from training)\n",
    "                    â””â”€ State (random from training)\n",
    "                    \n",
    "                                    IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚           LEVEL 2: EXACT (sample_id + target)                   â”‚\n",
    "                â”‚                    100% Accuracy Fallback                       â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_SAMPLE_ID_TARGET[sample_id]\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use exact training row\n",
    "                    â””â”€ NDVI, Height, Month, Species, State (all from training)\n",
    "                    \n",
    "                                        IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚       LEVEL 3a: IMAGE + PREDICTED SPECIES                       â”‚\n",
    "                â”‚              95% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_IMAGE_SPECIES_TARGET[image_id][pred_species]\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use same image with matching predicted species\n",
    "                    â”œâ”€ NDVI, Height, Month (from training data)\n",
    "                    â”œâ”€ Species (predicted from ViT)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                        IF NOT FOUND â†“\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚          LEVEL 3b: IMAGE ONLY FALLBACK                          â”‚\n",
    "                â”‚              85% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    Check: TRAIN_BY_IMAGE_ID_TARGET[image_id]\n",
    "                    Hit rate: ~12% (214/1,785)\n",
    "                    \n",
    "                    IF FOUND:\n",
    "                    âœ… Use same image (any species)\n",
    "                    â”œâ”€ NDVI, Height, Month (from training data)\n",
    "                    â”œâ”€ Species (from training data)\n",
    "                    â””â”€ State (from matched training row)\n",
    "                    \n",
    "                                 IF NOT FOUND â†“\n",
    "\n",
    "                    \n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚          LEVEL 4: STATISTICAL GENERATION                        â”‚\n",
    "                â”‚     Data-Driven Synthetic Features (GUARANTEED 100%)            â”‚\n",
    "                â”‚              60% Accuracy Fallback                              â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            Check: TABULAR_STATS[target_name]\n",
    "                                       ALWAYS WORKS\n",
    "                    \n",
    "                    âœ… ALWAYS SUCCEEDS - Generates synthetic features\n",
    "                    \n",
    "                    \n",
    "                    GUARANTEES:\n",
    "                    âœ… Zero NaN values\n",
    "                    âœ… Valid ranges (NDVI âˆˆ [0, 1], Height âˆˆ [1, 70])\n",
    "                    âœ… Statistically consistent with training data\n",
    "                    âœ… Reproducible (seeded random)\n",
    "                    âœ… Always returns 29-dim feature vector\n",
    "                \n",
    "                                    â†“ GUARANTEED SUCCESS\n",
    "                \n",
    "                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                            COMPLETE FEATURE VECTOR [29 dims]\n",
    "                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                [NDVI, Height, Month, DayOfYear, Quarter] + [State_OH, Species_OH]\n",
    "                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "                                              â†“\n",
    "                                        MODEL INFERENCE\n",
    "                                              â†“\n",
    "                                          PREDICTION \n",
    "                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**Feature Replication** (Critical Design):\n",
    "- 8 patches from one image â†’ 8 identical tabular features\n",
    "- 8 patches â†’ 8 identical targets\n",
    "- Result: Consistent training signal with spatial diversity\n",
    "\n",
    "**Custom Collate Function**:\n",
    "```\n",
    "Input: 8 image items from DataLoader\n",
    "    â†“\n",
    "Each image: 8 patches + 29 tabular features + 1 target\n",
    "    â†“\n",
    "Concatenate across batch:\n",
    "- images: [64, 3, 224, 224]    (8 images Ã— 8 patches)\n",
    "- tabular: [64, 29]             (replicated features)\n",
    "- targets: [64]                 (replicated targets)\n",
    "```\n",
    "\n",
    "**Data Loaders Created**:\n",
    "\n",
    "| Loader | Size | Batches | Purpose |\n",
    "|--------|------|---------|---------|\n",
    "| Training | 1,520 rows | 190 batches | Training (85% split) + augmentation |\n",
    "| Validation | 265 rows | 34 batches | Validation (15% split) + no augmentation |\n",
    "| Test | 5 rows | 1 batch | Prediction + intelligent fallback |\n",
    "\n",
    "**Output**: \n",
    "- BiomassDataset class ready with improved feature extraction\n",
    "- Train/val/test loaders created\n",
    "- Collate function verified for patch batching\n",
    "- Species model integrated for fallback matching\n",
    "- Feature caching enabled for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9672b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for pasture biomass prediction with intelligent test feature fetching.\n",
    "    \n",
    "    Features:\n",
    "    - Crops each 2000Ã—1000 image into 8 patches of 500Ã—500 pixels (4Ã—2 grid)\n",
    "    - Resizes patches to 224Ã—224 for model input\n",
    "    - Intelligent test data feature fetching with multi-level fallback \n",
    "    - Handles training, validation, and test modes\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, image_dir, transform=None, mode='train',\n",
    "                 train_df=None,lookups_dict=None, species_model=None, device=None ):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Input dataframe with image paths and targets\n",
    "            image_dir (str): Directory containing images\n",
    "            transform: Image augmentation transforms\n",
    "            mode (str): 'train', 'val', or 'test'\n",
    "            train_df (pd.DataFrame): Training dataframe (for test feature fetching)\n",
    "            lookups_dict (dict): Lookup tables (for test feature fetching)\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.species_model = species_model\n",
    "        try:\n",
    "            if device is None:\n",
    "                self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            else:\n",
    "                self.device = device if isinstance(device, torch.device) else torch.device(device)\n",
    "        except Exception:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.species_cache = {}\n",
    "        self.test_features_cache = {}\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.train_df = train_df\n",
    "        self.lookups_dict = {} if lookups_dict is None else lookups_dict\n",
    "        self.image_width = CONFIG['image_width']\n",
    "        self.image_height = CONFIG['image_height']\n",
    "        self.patch_size = CONFIG['patch_size']\n",
    "        self.patches_horizontal = CONFIG['patches_horizontal']\n",
    "        self.patches_vertical = CONFIG['patches_vertical']\n",
    "        self.num_patches = CONFIG['num_patches']\n",
    "        self.model_input_size = (CONFIG['model_input_size'], CONFIG['model_input_size'])\n",
    "        self.df = dataframe.reset_index(drop=True).copy()\n",
    "        self.mark_missing_images()\n",
    "        if self.mode == 'test':\n",
    "            logger.info(f\"âœ“ Test data: {len(self.df)} rows (one per target type)\")\n",
    "            self.test_features_cache = {}\n",
    "        try:\n",
    "            hmax = self.lookups_dict.get(\"HEIGHT_MAX\", None) \n",
    "            if hmax is None and self.train_df is not None and 'Height_Ave_cm' in self.train_df.columns:\n",
    "                try:\n",
    "                    hmax = float(self.train_df['Height_Ave_cm'].dropna().astype(float).max())\n",
    "                except Exception:\n",
    "                    hmax = None\n",
    "            if hmax is None or (not np.isfinite(hmax)) or (hmax <= 0):\n",
    "                hmax = 80.0\n",
    "            hmax = float(min(max(hmax, 1.0), 150.0))\n",
    "    \n",
    "        except Exception:\n",
    "            hmax = 80.0\n",
    "        self.HEIGHT_MAX = hmax\n",
    "        self.lookups_dict['HEIGHT_MAX'] = hmax\n",
    "        logger.debug(f\"âœ“ Using dynamic HEIGHT_MAX = {self.HEIGHT_MAX:.2f} cm\")\n",
    "        try:\n",
    "            if getattr(self, 'train_df', None) is not None and 'Species' in self.train_df.columns:\n",
    "                uniq_species = sorted(self.train_df['Species'].dropna().unique().tolist())\n",
    "                self.species_to_idx = {s: i for i, s in enumerate(uniq_species)}\n",
    "            else:\n",
    "                self.species_to_idx = {}\n",
    "        except Exception:\n",
    "            self.species_to_idx = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    # Sentinel color for missing/corrupt images (magenta)\n",
    "    SENTINEL_COLOR = (255, 0, 255)\n",
    "    SENTINEL_THRESHOLD = 0.90  # 90%+ magenta â†’ invalid image\n",
    "\n",
    "    \n",
    "    def _is_sentinel_image(self, img_pil):\n",
    "        try:\n",
    "            if not isinstance(img_pil, Image.Image):\n",
    "                return False\n",
    "            arr = np.asarray(img_pil.convert(\"RGB\")).astype(np.int16)\n",
    "            r_ok = (arr[:, :, 0] >= 240)\n",
    "            g_ok = (arr[:, :, 1] <= 15)\n",
    "            b_ok = (arr[:, :, 2] >= 240)\n",
    "            mask = r_ok & g_ok & b_ok\n",
    "            frac = mask.sum() / mask.size\n",
    "            return float(frac) >= float(self.SENTINEL_THRESHOLD)\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    \n",
    "    def _resolve_image_path(self, img_path_str):\n",
    "        if img_path_str is None or (isinstance(img_path_str, str) and str(img_path_str).strip() == \"\"):\n",
    "            return Path(\"\")  # empty Path => .exists() is False, handled downstream as missing\n",
    "        s = str(img_path_str).strip().lstrip(\"/\")\n",
    "        # remove repeated leading train/ or test/\n",
    "        s_clean = re.sub(r'^(?:train/|test/)+', '', s, flags=re.IGNORECASE)\n",
    "        candidates = [\n",
    "            Path(s),                                 \n",
    "            Path(self.image_dir) / s,                 \n",
    "            Path(self.image_dir) / s_clean,           \n",
    "            Path(self.image_dir) / Path(s).name,      \n",
    "            Path(self.image_dir) / \"train\" / Path(s).name,\n",
    "            Path(self.image_dir) / \"test\" / Path(s).name,]\n",
    "        for p in candidates:\n",
    "            if p.exists():\n",
    "                return p.resolve()\n",
    "        try:\n",
    "            return (Path(self.image_dir) / s).resolve()\n",
    "        except Exception:\n",
    "            return Path(self.image_dir)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_state_for_onehot(s):\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r'[^a-z0-9_]', '_', s)\n",
    "        s = re.sub(r'^state_', '', s)\n",
    "        return s\n",
    "\n",
    "    \n",
    "    def mark_missing_images(self):\n",
    "        missing_count = 0\n",
    "        missing_indices = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_path_raw = row.get('image_path', '')\n",
    "            img_path = self._resolve_image_path(img_path_raw)\n",
    "            \n",
    "            # CASE 1: file missing\n",
    "            file_missing = not img_path.exists()\n",
    "    \n",
    "            # CASE 2: file exists but unreadable (cv2 returns None)\n",
    "            unreadable = False\n",
    "            if not file_missing:\n",
    "                try:\n",
    "                    test_img = cv2.imread(str(img_path))\n",
    "                    if test_img is None:\n",
    "                        unreadable = True\n",
    "                except:\n",
    "                    unreadable = True\n",
    "    \n",
    "            # If missing or unreadable â†’ set species = Nothing\n",
    "            if file_missing or unreadable:\n",
    "                self.df.at[idx, 'is_missing'] = True\n",
    "    \n",
    "                # Set target 0.0 for training only \n",
    "                if 'target' in self.df.columns and self.mode != 'test':\n",
    "                    self.df.at[idx, 'target'] = 0.0\n",
    "    \n",
    "                # Set SPECIES = \"Nothing\"\n",
    "                if 'Species' in self.df.columns:\n",
    "                    self.df.at[idx, 'Species'] = \"Nothing\"\n",
    "                missing_count += 1\n",
    "                missing_indices.append(idx)\n",
    "            else:\n",
    "                self.df.at[idx, 'is_missing'] = False\n",
    "        if missing_count > 0:\n",
    "            logger.debug(f\"âœ“ Marked {missing_count} missing/unreadable images\")\n",
    "            if missing_count <= 10:\n",
    "                logger.debug(f\"  Missing indices: {missing_indices}\")\n",
    "        else:\n",
    "            logger.info(\"âœ“ All images found & readable!\")\n",
    "\n",
    "    \n",
    "    def _extract_train_tabular(self, row):\n",
    "        \"\"\"\n",
    "        Build tabular feature tensor for training/validation rows.\n",
    "        Numeric columns are scaled using lookups_dict['TAB_SCALER'].\n",
    "        One-hot columns are appended unchanged (0/1).\n",
    "        \"\"\"\n",
    "        numeric_cols = self.lookups_dict.get('TAB_NUMERIC_COLS', [])\n",
    "        scaler = self.lookups_dict.get('TAB_SCALER', None)\n",
    "    \n",
    "        # build raw numeric vector in same order as numeric_cols\n",
    "        raw_vals = []\n",
    "        for c in numeric_cols:\n",
    "            if c == 'Pre_GSHH_NDVI':\n",
    "                raw_vals.append(float(row.get('Pre_GSHH_NDVI', 0.5)))\n",
    "            elif c == 'Height_Ave_cm':\n",
    "                raw_vals.append(float(row.get('Height_Ave_cm', 10.0)))  \n",
    "            elif c == 'Month':\n",
    "                raw_vals.append(float(row.get('Month', 6)))  \n",
    "            elif c == 'DayOfYear':\n",
    "                raw_vals.append(float(row.get('DayOfYear', 1)))  \n",
    "            elif c == 'Quarter':\n",
    "                raw_vals.append(float(row.get('Quarter', 1)))  \n",
    "            else:\n",
    "                raw_vals.append(float(row.get(c, 0.0)))\n",
    "        \n",
    "        # Step 2: Clip to REALISTIC ranges \n",
    "        clipped = []\n",
    "        for c, v in zip(numeric_cols, raw_vals):\n",
    "            if c == \"Pre_GSHH_NDVI\":\n",
    "                # NDVI ranges from -1 to 1, \n",
    "                clipped.append(np.clip(v, 0.0, 1.0))\n",
    "            elif c == \"Height_Ave_cm\":\n",
    "                # Height in cm: realistic range 0-100 cm\n",
    "                clipped.append(np.clip(v, 0.0,100.0))\n",
    "            elif c == \"Month\":\n",
    "                # Month: 1-12\n",
    "                clipped.append(np.clip(v, 1.0, 12.0))\n",
    "            elif c == \"DayOfYear\":\n",
    "                # Day of year: 1-365\n",
    "                clipped.append(np.clip(v, 1.0, 365.0))\n",
    "            elif c == \"Quarter\":\n",
    "                # Quarter: 1-4\n",
    "                clipped.append(np.clip(v, 1.0, 4.0))\n",
    "            else:\n",
    "                clipped.append(v)\n",
    "        raw_vals = clipped\n",
    "\n",
    "        # scale numeric fields if scaler available\n",
    "        if scaler is not None and len(raw_vals) == len(numeric_cols):\n",
    "            try:\n",
    "                scaled_nums = scaler.transform([np.nan_to_num(raw_vals, nan=0.0)])[0].tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"_extract_train_tabular: scaler transform failed: {e}\")\n",
    "                scaled_nums = raw_vals\n",
    "        else:\n",
    "            scaled_nums = raw_vals\n",
    "        features = list(scaled_nums)\n",
    "    \n",
    "        # helper: safe numeric conversion\n",
    "        def _safe_to_float(x):\n",
    "            if isinstance(x, (bool, np.bool_)):\n",
    "                return 1.0 if x else 0.0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except Exception:\n",
    "                v = pd.to_numeric(x, errors='coerce')\n",
    "                return float(0.0 if pd.isna(v) else v)\n",
    "        \n",
    "        # get lists from lookups \n",
    "        STATE_COLS = self.lookups_dict.get('STATE_COLS', []) or []\n",
    "        SPECIES_COLS = self.lookups_dict.get('SPECIES_COLS', []) or []\n",
    "        TARGET_TYPE_COLS = self.lookups_dict.get('TARGET_TYPE_COLS', []) or []\n",
    "        \n",
    "        # LOG for debugging \n",
    "        logger.debug(f\"Using STATE_COLS: {STATE_COLS}\")\n",
    "        logger.debug(f\"Using SPECIES_COLS: {SPECIES_COLS}\")\n",
    "        logger.debug(f\"Using TARGET_TYPE_COLS: {TARGET_TYPE_COLS}\")\n",
    "        \n",
    "        # 1) Try to use numeric dummy columns directly \n",
    "        for col in STATE_COLS:\n",
    "            features.append(_safe_to_float(row.get(col, 0)))\n",
    "        \n",
    "        for col in SPECIES_COLS:\n",
    "            features.append(_safe_to_float(row.get(col, 0)))\n",
    "        \n",
    "        for col in TARGET_TYPE_COLS:\n",
    "            features.append(_safe_to_float(row.get(col, 0)))\n",
    "        \n",
    "        # 2) If the dummy lists are empty OR all zeros (i.e. missing), optionally fallback:\n",
    "        # convert categorical 'State' / 'Species' / 'target_name' into one-hot matching the dummy columns.\n",
    "        def _maybe_onehot_fallback(row, cols, cat_candidates):\n",
    "            \"\"\"\n",
    "            If all values from `cols` are zeros and we have a categorical col present (e.g. 'State' or 'Species'),\n",
    "            return a one-hot vector aligned to `cols`. Otherwise return None (meaning no fallback needed).\n",
    "            \"\"\"\n",
    "            if not cols:\n",
    "                return None\n",
    "            vals = [row.get(c, 0) for c in cols]\n",
    "            # if there exists any numeric non-zero -> no fallback\n",
    "            numeric_vals = pd.to_numeric(pd.Series(vals), errors='coerce').fillna(0.0)\n",
    "            if numeric_vals.sum() > 0:\n",
    "                return None\n",
    "        \n",
    "            # try to find a categorical column among candidates\n",
    "            cat_val = None\n",
    "            for cand in cat_candidates:\n",
    "                if cand in row.index:\n",
    "                    raw = row.get(cand)\n",
    "                    if pd.isna(raw) or raw == '':\n",
    "                        continue\n",
    "                    cat_val = str(raw).strip().lower()\n",
    "                    break\n",
    "            if cat_val is None:\n",
    "                return None\n",
    "        \n",
    "            # build one-hot by tolerant matching between column names and cat_val\n",
    "            onehot = []\n",
    "            for c in cols:\n",
    "                c_norm = c.lower()\n",
    "                score = 0\n",
    "                if c_norm.endswith(cat_val) or c_norm.endswith(cat_val.replace(' ', '_')):\n",
    "                    score = 2\n",
    "                elif cat_val in c_norm or c_norm in cat_val:\n",
    "                    score = 1\n",
    "                elif c_norm.split('_')[-1][:3] == cat_val[:3]:\n",
    "                    score = 1\n",
    "                onehot.append(1.0 if score > 0 else 0.0)\n",
    "        \n",
    "            logger.debug(f\"Fallback one-hot for {cat_candidates}='{cat_val}' => {onehot}\")\n",
    "            return onehot\n",
    "        \n",
    "        # apply fallbacks only if initial dummy columns were all zeros / absent\n",
    "        state_fallback = _maybe_onehot_fallback(row, STATE_COLS, ['State', 'state', 'State_canon', 'state_name'])\n",
    "        if state_fallback is not None:\n",
    "            if STATE_COLS:\n",
    "                features[-len(STATE_COLS):] = state_fallback\n",
    "        \n",
    "        species_fallback = _maybe_onehot_fallback(row, SPECIES_COLS, ['Species', 'species', 'Species_canon'])\n",
    "        if species_fallback is not None:\n",
    "            if SPECIES_COLS:\n",
    "                features[-len(SPECIES_COLS):] = species_fallback\n",
    "        \n",
    "        target_fallback = _maybe_onehot_fallback(row, TARGET_TYPE_COLS, ['target_name', 'Target', 'target'])\n",
    "        if target_fallback is not None:\n",
    "            if TARGET_TYPE_COLS:\n",
    "                features[-len(TARGET_TYPE_COLS):] = target_fallback\n",
    "        return torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    def predicting_species(self, test_row, species_model=None, device=None):\n",
    "        \"\"\"\n",
    "        Predict species for a single test_row.\n",
    "    \n",
    "        Supports:\n",
    "          - per-patch outputs (one logits row per patch) -> argmax per patch -> majority vote\n",
    "          - MIL-style: image-level logits (one logits row for the image) -> single prediction\n",
    "          - outputs as tensor, (tensor, ...) tuple, or dict with \"logits\" or \"pred\"\n",
    "          - dict outputs like {'pred': '<name>'} are handled\n",
    "    \n",
    "        Returns canonical species string (via map_to_fixed_species) or None.\n",
    "        \n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = getattr(self, \"device\", None)\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if species_model is None:\n",
    "            logger.debug(\"predicting_species: species_model is None -> returning None\")\n",
    "            return None\n",
    "    \n",
    "        sample_id = test_row.get(\"sample_id\")\n",
    "        image_id = str(sample_id).split(\"__\")[0] if sample_id is not None else None\n",
    "        cache_key = image_id.lower() if image_id is not None else None\n",
    "        if cache_key is not None and cache_key in getattr(self, \"species_cache\", {}):\n",
    "            return self.species_cache[cache_key]\n",
    "    \n",
    "        img_path = self._resolve_image_path(test_row.get('image_path', ''))\n",
    "        try:\n",
    "            if not img_path.exists():\n",
    "                logger.info(f\"predicting_species: image not found: {img_path}\")\n",
    "                return None\n",
    "            image = self._load_image(img_path)\n",
    "            if not isinstance(image, Image.Image):\n",
    "                image = Image.fromarray(np.asarray(image))\n",
    "    \n",
    "            patches = self._crop_patches(image)\n",
    "            if not patches:\n",
    "                logger.debug(f\"predicting_species: no patches for {img_path}\")\n",
    "                return None\n",
    "    \n",
    "            # Prepare device and remember original device\n",
    "            try:\n",
    "                orig_device = next(species_model.parameters()).device\n",
    "            except Exception:\n",
    "                orig_device = getattr(species_model, \"device\", None)\n",
    "    \n",
    "            target_device = device\n",
    "            moved_model = False\n",
    "            try:\n",
    "                if orig_device is None or orig_device != target_device:\n",
    "                    species_model.to(target_device)\n",
    "                    moved_model = True\n",
    "            except Exception:\n",
    "                logger.info(\"predicting_species: could not move species_model to target device; continuing\")\n",
    "    \n",
    "            species_model.eval()\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "            patch_tensors = []\n",
    "            for p in patches:\n",
    "                if not isinstance(p, Image.Image):\n",
    "                    p = Image.fromarray(np.asarray(p))\n",
    "                patch_tensors.append(transform(p))\n",
    "    \n",
    "            batch = torch.stack(patch_tensors, dim=0).to(target_device)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = species_model(batch, return_features=False)\n",
    "    \n",
    "            logits = None\n",
    "            if isinstance(outputs, dict):\n",
    "                if 'pred' in outputs:\n",
    "                    raw_pred = outputs.get('pred')\n",
    "                    if isinstance(raw_pred, (list, tuple, np.ndarray)):\n",
    "                        raw_pred = raw_pred[0] if len(raw_pred) > 0 else None\n",
    "                    if raw_pred is not None:\n",
    "                        raw_pred = str(raw_pred).strip()\n",
    "                    mapped = map_to_fixed_species(raw_pred) if raw_pred else None\n",
    "                    if cache_key is not None:\n",
    "                        self.species_cache[cache_key] = mapped\n",
    "                    return mapped\n",
    "                if 'species' in outputs and isinstance(outputs['species'], str):\n",
    "                    raw_pred = outputs['species']\n",
    "                    mapped = map_to_fixed_species(raw_pred)\n",
    "                    if cache_key is not None:\n",
    "                        self.species_cache[cache_key] = mapped\n",
    "                    return mapped\n",
    "                logits = outputs.get('logits', None)\n",
    "                if logits is None:\n",
    "                    for v in outputs.values():\n",
    "                        if torch.is_tensor(v):\n",
    "                            logits = v\n",
    "                            break\n",
    "    \n",
    "            elif isinstance(outputs, (list, tuple)):\n",
    "                first = outputs[0] if len(outputs) > 0 else None\n",
    "                if isinstance(first, dict):\n",
    "                    if 'pred' in first:\n",
    "                        raw_pred = first.get('pred')\n",
    "                        if isinstance(raw_pred, (list, tuple, np.ndarray)):\n",
    "                            raw_pred = raw_pred[0] if len(raw_pred) > 0 else None\n",
    "                        if raw_pred is not None:\n",
    "                            raw_pred = str(raw_pred).strip()\n",
    "                        mapped = map_to_fixed_species(raw_pred) if raw_pred else None\n",
    "                        if cache_key is not None:\n",
    "                            self.species_cache[cache_key] = mapped\n",
    "                        return mapped\n",
    "                    logits = first.get('logits', None)\n",
    "                else:\n",
    "                    logits = first\n",
    "            else:\n",
    "                logits = outputs\n",
    "    \n",
    "            if logits is None or not torch.is_tensor(logits):\n",
    "                logger.info(\"predicting_species: could not interpret model outputs -> returning None\")\n",
    "                return None\n",
    "    \n",
    "            # detach to CPU for analysis\n",
    "            logits_detached = logits.detach().cpu()\n",
    "    \n",
    "            # Determine per-patch vs image-level\n",
    "            per_patch_mode = False\n",
    "            img_level_logits = None\n",
    "            per_patch_logits = None\n",
    "    \n",
    "            if logits_detached.dim() == 1:\n",
    "                # single-vector -> image-level\n",
    "                img_level_logits = logits_detached.unsqueeze(0)\n",
    "            elif logits_detached.dim() == 2:\n",
    "                n_rows = logits_detached.shape[0]\n",
    "                n_patches = len(patches)\n",
    "                if n_rows == n_patches:\n",
    "                    per_patch_mode = True\n",
    "                    per_patch_logits = logits_detached\n",
    "                elif n_rows == 1:\n",
    "                    img_level_logits = logits_detached\n",
    "                else:\n",
    "                    img_level_logits = logits_detached.mean(dim=0, keepdim=True)\n",
    "            else:\n",
    "                try:\n",
    "                    flat = logits_detached.view(logits_detached.shape[0], -1)\n",
    "                    if flat.dim() == 2 and flat.shape[0] == len(patches):\n",
    "                        per_patch_mode = True\n",
    "                        per_patch_logits = flat\n",
    "                    else:\n",
    "                        img_level_logits = flat.mean(dim=0, keepdim=True)\n",
    "                except Exception:\n",
    "                    logger.info(\"predicting_species: unexpected logits shape; returning None\")\n",
    "                    return None\n",
    "    \n",
    "            predicted_species = None\n",
    "    \n",
    "            if per_patch_mode:\n",
    "                preds = torch.argmax(per_patch_logits, dim=1).cpu().numpy().tolist()\n",
    "                # Map indices -> species names\n",
    "                predicted_list = []\n",
    "                \n",
    "                for idx_val in preds:\n",
    "                    idx_val = int(idx_val)\n",
    "                    species_name = None\n",
    "                    \n",
    "                    # Try model's species_list first\n",
    "                    if hasattr(species_model, \"species_list\") and isinstance(species_model.species_list, (list, tuple)):\n",
    "                        if 0 <= idx_val < len(species_model.species_list):\n",
    "                            species_name = species_model.species_list[idx_val]\n",
    "                        else:\n",
    "                            logger.warning(f\"Per-patch: Index {idx_val} out of range for species_list (len={len(species_model.species_list)})\")\n",
    "                    \n",
    "                    # Try idx_to_species dict if species_list didn't work\n",
    "                    if species_name is None:\n",
    "                        idx_to_species = getattr(species_model, \"idx_to_species\", None) or getattr(species_model, \"idx_to_class\", None)\n",
    "                        if isinstance(idx_to_species, dict):\n",
    "                            if idx_val in idx_to_species:\n",
    "                                species_name = idx_to_species[idx_val]\n",
    "                            else:\n",
    "                                logger.warning(f\"Per-patch: Index {idx_val} not in idx_to_species. Available: {list(idx_to_species.keys())}\")\n",
    "                        else:\n",
    "                            logger.warning(\"Per-patch: No species_list or idx_to_species available!\")\n",
    "                    \n",
    "                    # Fallback: if still None, use \"Unknown\" marker\n",
    "                    if species_name is None:\n",
    "                        species_name = \"Unknown\"\n",
    "                    \n",
    "                    predicted_list.append(str(species_name).strip())\n",
    "    \n",
    "                predicted_list_mapped = [map_to_fixed_species(p) for p in predicted_list]\n",
    "                predicted_species = max(set(predicted_list_mapped), key=predicted_list_mapped.count) if predicted_list_mapped else None\n",
    "    \n",
    "            else:\n",
    "                # single-image logits -> take argmax\n",
    "                try:\n",
    "                    probs = torch.nn.functional.softmax(img_level_logits, dim=1)\n",
    "                    idx = int(torch.argmax(probs, dim=1).cpu().item())\n",
    "                except Exception:\n",
    "                    idx = int(torch.argmax(img_level_logits, dim=1).cpu().item())\n",
    "                \n",
    "                raw_name = None\n",
    "                if hasattr(species_model, \"species_list\") and isinstance(species_model.species_list, (list, tuple)):\n",
    "                    if 0 <= idx < len(species_model.species_list):\n",
    "                        raw_name = species_model.species_list[idx]\n",
    "                    else:\n",
    "                        logger.warning(f\"Image-level: Index {idx} out of range for species_list (len={len(species_model.species_list)})\")\n",
    "                \n",
    "                if raw_name is None:\n",
    "                    idx_to_species = getattr(species_model, \"idx_to_species\", None) or getattr(species_model, \"idx_to_class\", None)\n",
    "                    if isinstance(idx_to_species, dict):\n",
    "                        if idx in idx_to_species:\n",
    "                            raw_name = idx_to_species[idx]\n",
    "                        else:\n",
    "                            logger.warning(f\"Image-level: Index {idx} not in idx_to_species. Available: {list(idx_to_species.keys())}\")\n",
    "                    else:\n",
    "                        logger.warning(\"Image-level: No species mapping available!\")\n",
    "                \n",
    "                if raw_name is None:\n",
    "                    raw_name = \"Unknown\"\n",
    "                \n",
    "                predicted_species = map_to_fixed_species(str(raw_name).strip())\n",
    "            \n",
    "            logger.debug(f\"âœ“ Predicted species: {predicted_species}\")\n",
    "            if cache_key is not None:\n",
    "                if not hasattr(self, \"species_cache\"):\n",
    "                    self.species_cache = {}\n",
    "                self.species_cache[cache_key] = predicted_species\n",
    "            return predicted_species\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"âš  predicting_species failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "        finally:\n",
    "            # ensure model moved back to original device when possible\n",
    "            try:\n",
    "                if 'moved_model' in locals() and moved_model and orig_device is not None:\n",
    "                    species_model.to(orig_device)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    def estimate_height_final(self, image):\n",
    "        try:\n",
    "            try:\n",
    "                if not getattr(self, \"height_model\", None):\n",
    "                    try:\n",
    "                        out_dir = OUTPUTS_DIR if isinstance(OUTPUTS_DIR, Path) else Path(OUTPUTS_DIR)\n",
    "                        ridge_path = out_dir / \"height_ridge.joblib\"\n",
    "                        pl_path = out_dir / \"height_powerlaw.json\"\n",
    "    \n",
    "                        if ridge_path.exists():\n",
    "                            try:\n",
    "                                ridge_model = joblib.load(str(ridge_path))\n",
    "                                self.height_model = ridge_model\n",
    "                                self.height_model_type = getattr(ridge_model, \"height_model_type\", \"log1p\")\n",
    "                                logger.info(f\"Loaded ridge height_model from {ridge_path}\")\n",
    "                            except Exception as e:\n",
    "                                logger.info(f\"Failed to load ridge model: {e}\")\n",
    "    \n",
    "                        # Load powerlaw params if available \n",
    "                        if (not hasattr(self, \"height_a\") or not hasattr(self, \"height_b\")) and pl_path.exists():\n",
    "                            try:\n",
    "                                js = json.loads(pl_path.read_text())\n",
    "                                self.height_a = float(js.get(\"a\", getattr(self, \"height_a\", None) or 0.0))\n",
    "                                self.height_b = float(js.get(\"b\", getattr(self, \"height_b\", None) or 1.0))\n",
    "                                # set sensible model type for powerlaw fallback\n",
    "                                if not hasattr(self, \"height_model_type\"):\n",
    "                                    self.height_model_type = \"log1p_powerlaw\"\n",
    "                                logger.info(f\"Loaded powerlaw params from {pl_path}\")\n",
    "                            except Exception as e:\n",
    "                                logger.debug(f\"Failed to read powerlaw json: {e}\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "            # Convert to PIL for sentinel detection\n",
    "            if isinstance(image, Image.Image):\n",
    "                img_pil = image\n",
    "            else:\n",
    "                img_pil = Image.fromarray(np.uint8(image))\n",
    "            if self._is_sentinel_image(img_pil):\n",
    "                return 0.0\n",
    "    \n",
    "            # Extract features\n",
    "            feats = self.compute_features_from_image(image)\n",
    "            ndvi = float(np.clip(feats.get('ndvi', 0.5), 0.0, 1.0))\n",
    "            texture_norm = float(np.clip(feats.get('texture', 0.02), 0.0, 1.0))\n",
    "            green_intensity = float(np.clip(feats.get('green', 0.4), 0.0, 1.0))\n",
    "            brightness = float(np.clip(feats.get('brightness', 0.5), 0.0, 1.0))\n",
    "            height_proxy = float(np.clip(feats.get('height_proxy', 0.4), 0.0, 1.0))\n",
    "            veg_frac = float(np.clip(feats.get('veg_frac', 0.5), 0.0, 1.0))\n",
    "    \n",
    "            # combined score \n",
    "            MIN_SCORE = 1e-2\n",
    "            combined_score = (\n",
    "                0.35 * ndvi +\n",
    "                0.25 * texture_norm +\n",
    "                0.20 * green_intensity +\n",
    "                0.10 * brightness +\n",
    "                0.10 * height_proxy)\n",
    "            combined_score = float(\n",
    "                np.clip(combined_score * (0.5 + 0.5 * feats.get('veg_frac', 1.0)),\n",
    "                        MIN_SCORE, 1.0))\n",
    "    \n",
    "            height_cm = None\n",
    "    \n",
    "            # 1) USE TRAINED MODEL IF AVAILABLE\n",
    "            # --------------------------------------\n",
    "            if hasattr(self, \"height_model\") and self.height_model is not None:\n",
    "                try:\n",
    "                    vec = np.array([[ndvi, texture_norm, green_intensity,\n",
    "                                     brightness, height_proxy, veg_frac]], dtype=float)\n",
    "                    pred_val = float(self.height_model.predict(vec)[0])\n",
    "    \n",
    "                    model_type = getattr(self, \"height_model_type\", \"log1p\")\n",
    "    \n",
    "                    if model_type == \"log\":\n",
    "                        height_cm = float(np.exp(pred_val))\n",
    "                    elif model_type == \"log1p\":\n",
    "                        height_cm = float(np.expm1(pred_val))\n",
    "                    else:\n",
    "                        height_cm = float(pred_val)\n",
    "                except Exception as e:\n",
    "                    logger.info(f\"Calibrated height_model predict failed: {e}\")\n",
    "                    height_cm = None\n",
    "    \n",
    "            # 2) POWER-LAW FALLBACK (use saved a/b if available)\n",
    "            # --------------------------------------\n",
    "            if height_cm is None or not np.isfinite(height_cm):\n",
    "                a = getattr(self, \"height_a\", None)\n",
    "                b = getattr(self, \"height_b\", None)\n",
    "                model_type = getattr(self, \"height_model_type\", \"log1p_powerlaw\")\n",
    "    \n",
    "                cs = max(float(combined_score), 1e-6)\n",
    "    \n",
    "                if a is not None and b is not None:\n",
    "                    try:\n",
    "                        # If calibration used log1p \n",
    "                        if model_type == \"log1p_powerlaw\":\n",
    "                            height_cm = float(np.expm1(a + b * np.log1p(cs)))\n",
    "                        elif model_type == \"log\":\n",
    "                            # classic log form: log(h) = log(a) + b*log(score)\n",
    "                            height_cm = float(np.exp(np.log(a) + b * np.log(max(cs, 1e-6))))\n",
    "                        else:\n",
    "                            # classic powerlaw a * cs ** b\n",
    "                            height_cm = float(a * (cs ** b))\n",
    "                    except Exception as e:\n",
    "                        logger.info(f\"Powerlaw computation failed: {e}\")\n",
    "                        height_cm = None\n",
    "                else:\n",
    "                    #emergency defaults\n",
    "                    height_cm = 7.7\n",
    "    \n",
    "            # Final clip\n",
    "            return float(np.clip(height_cm, 0.0, getattr(self, \"HEIGHT_MAX\", 100.0)))\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"estimate_height_final failed: {e}\")\n",
    "            return 7.6\n",
    "\n",
    "    \n",
    "    def compute_features_from_image(self, image):\n",
    "        \"\"\"\n",
    "        Return a dict of features needed by calibrator:\n",
    "        keys: ndvi, texture, green, brightness, height_proxy, veg_frac\n",
    "        Accepts PIL Image or numpy array.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(image, Image.Image):\n",
    "                img_pil = image.convert(\"RGB\")\n",
    "                img_np = np.asarray(img_pil, dtype=np.float32)\n",
    "            else:\n",
    "                # if it's a numpy array, create a PIL for sentinel check\n",
    "                img_np = np.asarray(image, dtype=np.float32)\n",
    "                try:\n",
    "                    img_pil = Image.fromarray(\n",
    "                        (np.clip(img_np, 0.0, 1.0) * 255).astype('uint8')\n",
    "                        if img_np.max() <= 1.0 else img_np.astype('uint8')\n",
    "                    ).convert(\"RGB\")\n",
    "                except Exception:\n",
    "                    img_pil = None\n",
    "\n",
    "            # sentinel check \n",
    "            if img_pil is not None and self._is_sentinel_image(img_pil):\n",
    "                return {\n",
    "                    'ndvi': 0.0,\n",
    "                    'texture': 0.0,\n",
    "                    'green': 0.0,\n",
    "                    'brightness': 0.0,\n",
    "                    'height_proxy': 0.0,\n",
    "                    'veg_frac': 0.0}\n",
    "\n",
    "            if img_np.size == 0:\n",
    "                return {'ndvi':0.5,'texture':0.02,'green':0.4,'brightness':0.5,'height_proxy':0.4,'veg_frac':0.5}\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np = img_np / 255.0\n",
    "            gray = np.mean(img_np, axis=2) if img_np.ndim==3 else img_np\n",
    "            lap = laplace(gray)\n",
    "            texture = float(np.nanmean(np.abs(lap)))\n",
    "            texture = float(np.clip(texture/100.0, 0.0, 1.0))\n",
    "            green = img_np[:,:,1] if img_np.ndim==3 and img_np.shape[2]>=2 else gray\n",
    "            green = float(np.nanmean(green))\n",
    "            green = float(np.clip(green,0.0,1.0))\n",
    "            brightness = float(np.nanmean(gray))\n",
    "            height_proxy = self._get_canopy_height_proxy(img_np)\n",
    "            # veg_frac: fraction of pixels considered vegetation\n",
    "            try:\n",
    "                R = img_np[:,:,0] if img_np.ndim==3 else gray\n",
    "                G = img_np[:,:,1] if img_np.ndim==3 else gray\n",
    "                veg_mask = (G > R*1.02) & (G > 0.08)\n",
    "                veg_frac = float(np.clip(np.sum(veg_mask)/veg_mask.size, 0.0, 1.0))\n",
    "            except Exception:\n",
    "                veg_frac = 0.5\n",
    "            # vNDVI fallback\n",
    "            try:\n",
    "                R = img_np[:,:,0] if img_np.ndim==3 else gray\n",
    "                G = img_np[:,:,1] if img_np.ndim==3 else gray\n",
    "                denom = G + R\n",
    "                denom[denom==0] = 1e-8\n",
    "                vndvi = float(np.nanmean((G-R)/denom))\n",
    "                vndvi = float(np.clip(vndvi, 0.0, 1.0))\n",
    "            except Exception:\n",
    "                vndvi = 0.5\n",
    "            return {'ndvi': vndvi, 'texture': texture, 'green': green, 'brightness': brightness, 'height_proxy': height_proxy, 'veg_frac': veg_frac}\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"compute_features_from_image failed: {e}\")\n",
    "            return {'ndvi':0.5,'texture':0.02,'green':0.4,'brightness':0.5,'height_proxy':0.4,'veg_frac':0.5}\n",
    "\n",
    "    \n",
    "    def _get_canopy_height_proxy(self, img_np):\n",
    "        \"\"\"\n",
    "        Extract canopy height proxy from image (robustified).\n",
    "        Expects img_np normalized to [0,1] range (function will attempt to normalize).\n",
    "        Returns float in [0,1].\n",
    "    \n",
    "        \"\"\"\n",
    "        try:\n",
    "            arr = np.asarray(img_np, dtype=np.float32)\n",
    "            if arr.size == 0:\n",
    "                return 0.4\n",
    "    \n",
    "            if arr.max() > 1.0:\n",
    "                arr = arr / 255.0\n",
    "    \n",
    "            # grayscale\n",
    "            if arr.ndim == 3:\n",
    "                gray = np.mean(arr, axis=2)\n",
    "            else:\n",
    "                gray = arr\n",
    "    \n",
    "            # vegetation mask \n",
    "            try:\n",
    "                if arr.ndim == 3 and arr.shape[2] >= 2:\n",
    "                    R = arr[:, :, 0]\n",
    "                    G = arr[:, :, 1]\n",
    "                    factor = 1.05\n",
    "                    min_green = max(0.08, np.percentile(G.ravel(), 25) * 0.6)\n",
    "                    veg_mask = (G > R * factor) & (G > min_green)\n",
    "                    if np.sum(veg_mask) < max(10, 0.01 * gray.size):\n",
    "                        veg_mask = (G > R * 1.02) & (G > np.percentile(G.ravel(), 10) * 0.4)\n",
    "                    if np.sum(veg_mask) == 0:\n",
    "                        veg_mask = np.ones_like(gray, dtype=bool)\n",
    "                else:\n",
    "                    veg_mask = np.ones_like(gray, dtype=bool)\n",
    "            except Exception:\n",
    "                veg_mask = np.ones_like(gray, dtype=bool)\n",
    "    \n",
    "            try:\n",
    "                if np.any(veg_mask):\n",
    "                    texture_variance = float(np.var(gray[veg_mask]))\n",
    "                else:\n",
    "                    texture_variance = float(np.var(gray))\n",
    "            except Exception:\n",
    "                texture_variance = 0.02\n",
    "    \n",
    "            # local contrast \n",
    "            try:\n",
    "                values = gray[veg_mask].ravel()\n",
    "                p90 = float(np.percentile(values, 90))\n",
    "                p10 = float(np.percentile(values, 10))\n",
    "                contrast = max(0.0, p90 - p10)\n",
    "            except Exception:\n",
    "                contrast = 0.1\n",
    "    \n",
    "            proxy_raw = 0.7 * texture_variance + 0.3 * (contrast ** 1.0)\n",
    "            # robust normalization: divide by reasonable expected max (0.08) then clip\n",
    "            height_proxy = float(np.clip(proxy_raw / (0.08 + 1e-8), 0.0, 1.0))\n",
    "    \n",
    "            logger.debug(f\"Canopy height proxy (var={texture_variance:.4f}, contrast={contrast:.4f}) -> {height_proxy:.3f}\")\n",
    "            return height_proxy\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Canopy height proxy estimation failed: {e}\")\n",
    "            return 0.4\n",
    "\n",
    "    \n",
    "    def estimate_month_and_ndvi_from_image(self, image):\n",
    "        \"\"\"\n",
    "        Estimate growing season month AND vegetation health (NDVI) from image.\n",
    "    \n",
    "        Args:\n",
    "            image: numpy array of shape (H, W, C) or PIL Image\n",
    "    \n",
    "        Returns:\n",
    "            tuple: (estimated_month (int), estimated_ndvi (float))\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(image, Image.Image):\n",
    "                img_np = np.asarray(image, dtype=np.float32)\n",
    "            else:\n",
    "                img_np = np.asarray(image, dtype=np.float32)\n",
    "    \n",
    "            # Validate shape\n",
    "            if img_np.ndim != 3:\n",
    "                logger.warning(f\"Unexpected image shape: {getattr(img_np, 'shape', None)}\")\n",
    "                return 6, 0.5\n",
    "    \n",
    "            h, w, c = img_np.shape\n",
    "            img_np = img_np.astype(np.float32)\n",
    "    \n",
    "            # scale to [0,1] if necessary\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np = img_np / 255.0\n",
    "    \n",
    "            RED = img_np[:, :, 0]\n",
    "            GREEN = img_np[:, :, 1]\n",
    "            BLUE = img_np[:, :, 2] if c >= 3 else np.zeros_like(RED)\n",
    "    \n",
    "            denom = GREEN + RED\n",
    "            denom_safe = denom.copy()\n",
    "            denom_safe[np.isclose(denom_safe, 0.0)] = 1e-8\n",
    "    \n",
    "            # vNDVI = (GREEN - RED) / (GREEN + RED)\n",
    "            vndvi_array = (GREEN - RED) / denom_safe\n",
    "            # Clip individual pixel index to reasonable range then mean\n",
    "            vndvi_array_clipped = np.clip(vndvi_array, -1.0, 1.0)\n",
    "            mean_vndvi = float(np.nanmean(vndvi_array_clipped))\n",
    "    \n",
    "            # Validate\n",
    "            if np.isnan(mean_vndvi) or np.isinf(mean_vndvi):\n",
    "                logger.warning(\"Invalid vNDVI detected, using fallback\")\n",
    "                return 6, 0.5\n",
    "    \n",
    "            # Map vNDVI (raw) to [0,1] reasonable range for calibration\n",
    "            # Some vNDVI may be slightly negative for non-vegetation; clamp to 0..1 for month mapping\n",
    "            mean_vndvi_clipped = float(np.clip(mean_vndvi, 0.0, 1.0))\n",
    "    \n",
    "            default_true_min = 0.16\n",
    "            default_true_max = 0.91\n",
    "    \n",
    "            # Default expected raw RGB-ensemble/vNDVI range \n",
    "            rgb_raw_min = 0.0\n",
    "            rgb_raw_max = 0.80\n",
    "    \n",
    "            # Try to read calibration stats from /mnt/data/test.csv if available and has useful columns\n",
    "            try:\n",
    "                calib_path = \"/kaggle/working/outputs/ndvidata.csv\"\n",
    "                if os.path.exists(calib_path):\n",
    "                    try:\n",
    "                        df_cal = pd.read_csv(calib_path, nrows=5)\n",
    "                        # Look for common columns names: avg, min, max OR ndvi_avg, ndvi_min, ndvi_max OR avg_ndvi, min_ndvi, max_ndvi\n",
    "                        if set(['avg','min','max']).issubset(set(df_cal.columns)):\n",
    "                            true_min = float(df_cal['min'].dropna().iat[0])\n",
    "                            true_max = float(df_cal['max'].dropna().iat[0])\n",
    "                            logger.info(\"Calibration loaded from test.csv using columns avg/min/max\")\n",
    "                        elif set(['ndvi_avg','ndvi_min','ndvi_max']).issubset(set(df_cal.columns)):\n",
    "                            true_min = float(df_cal['ndvi_min'].dropna().iat[0])\n",
    "                            true_max = float(df_cal['ndvi_max'].dropna().iat[0])\n",
    "                            logger.info(\"Calibration loaded from test.csv using ndvi_avg/min/max\")\n",
    "                        elif set(['avg_ndvi','min_ndvi','max_ndvi']).issubset(set(df_cal.columns)):\n",
    "                            true_min = float(df_cal['min_ndvi'].dropna().iat[0])\n",
    "                            true_max = float(df_cal['max_ndvi'].dropna().iat[0])\n",
    "                            logger.info(\"Calibration loaded from test.csv using avg_ndvi/min_ndvi/max_ndvi\")\n",
    "                        else:\n",
    "                            # Fallback to using first-row numeric values if present \n",
    "                            first_row = df_cal.iloc[0].to_dict()\n",
    "                            nums = [v for v in first_row.values() if isinstance(v, (int, float, np.floating, np.integer))]\n",
    "                            if len(nums) >= 3:\n",
    "                                # assume ordering avg,min,max or avg,min,max-like â€” pick min and max heuristically\n",
    "                                true_min = float(min(nums))\n",
    "                                true_max = float(max(nums))\n",
    "                                logger.info(\"Calibration heuristically inferred from test.csv first row\")\n",
    "                            else:\n",
    "                                true_min, true_max = default_true_min, default_true_max\n",
    "                    except Exception as e:\n",
    "                        logger.debug(f\"Calibration read failed: {e}\")\n",
    "                        true_min, true_max = default_true_min, default_true_max\n",
    "                else:\n",
    "                    true_min, true_max = default_true_min, default_true_max\n",
    "            except Exception:\n",
    "                true_min, true_max = default_true_min, default_true_max\n",
    "    \n",
    "            # If the inferred true range is degenerate, fall back\n",
    "            if not (np.isfinite(true_min) and np.isfinite(true_max) and (true_max > true_min)):\n",
    "                true_min, true_max = default_true_min, default_true_max\n",
    "    \n",
    "            fused = mean_vndvi_clipped  \n",
    "            denom_scale = (rgb_raw_max - rgb_raw_min) if (rgb_raw_max - rgb_raw_min) != 0 else 1e-8\n",
    "            fused_calibrated = (fused - rgb_raw_min) / denom_scale\n",
    "            fused_calibrated = fused_calibrated * (true_max - true_min) + true_min\n",
    "            fused_calibrated = float(np.clip(fused_calibrated, true_min, true_max))\n",
    "    \n",
    "            # Final month estimate \n",
    "            month = self._estimate_month_from_ndvi(fused_calibrated)\n",
    "            logger.info(f\"Image analysis: raw_vNDVI={mean_vndvi:.3f}, clipped={mean_vndvi_clipped:.3f} \"\n",
    "                        f\"â†’ calibrated_NDVI={fused_calibrated:.3f} â†’ Month {month}\")\n",
    "    \n",
    "            return month, fused_calibrated\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in NDVI estimation: {e}\")\n",
    "            return 6, 0.5\n",
    "\n",
    "    \n",
    "    def estimate_month_and_ndvi_ensemble(self, image, species=None):\n",
    "        \"\"\"\n",
    "        RGB-based NDVI ensemble estimator with calibration.\n",
    "    \n",
    "        If `species` is provided and `/kaggle/working/outputs/ndvidata.csv` exists,\n",
    "        calibration uses that species' ndvi_min/ndvi_max (and ndvi_mean) for mapping.\n",
    "        Otherwise fall back to the old test.csv heuristics and defaults.\n",
    "        Returns (month:int, calibrated_ndvi:float)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import PIL.Image as PILImage   \n",
    "            # --- Normalize / ensure numpy array ---\n",
    "            img_np = np.asarray(image, dtype=np.float32)\n",
    "            # build a PIL copy for sentinel check if needed\n",
    "            if not isinstance(image, PILImage.Image):\n",
    "                try:\n",
    "                    if img_np.max() <= 1.0:\n",
    "                        img_pil_for_check = PILImage.fromarray((img_np * 255).astype('uint8'))\n",
    "                    else:\n",
    "                        img_pil_for_check = PILImage.fromarray((img_np).astype('uint8'))\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        img_pil_for_check = PILImage.fromarray(np.uint8(image))\n",
    "                    except Exception:\n",
    "                        img_pil_for_check = None\n",
    "            else:\n",
    "                img_pil_for_check = image\n",
    "            if self._is_sentinel_image(img_pil_for_check):\n",
    "                month = self._estimate_month_from_ndvi(0.0) if hasattr(self, \"_estimate_month_from_ndvi\") else 6\n",
    "                return month, 0.0\n",
    "            # scale to [0,1]\n",
    "            if img_np.max() > 1.0:\n",
    "                img_np = img_np / 255.0\n",
    "            MAX_NDVI_SIZE = 512\n",
    "            if img_np.ndim == 3:\n",
    "                h, w = img_np.shape[:2]\n",
    "                max_side = max(h, w)\n",
    "                if max_side > MAX_NDVI_SIZE:\n",
    "                    scale = MAX_NDVI_SIZE / float(max_side)\n",
    "                    new_w, new_h = int(round(w * scale)), int(round(h * scale))\n",
    "                    # use cv2 if available for speed; fall back to PIL\n",
    "                    try:\n",
    "                        img_small = cv2.resize(img_np, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "                    except Exception:\n",
    "                        from PIL import Image\n",
    "                        img_pil = Image.fromarray((img_np * 255).astype('uint8'))\n",
    "                        img_pil = img_pil.resize((new_w, new_h), Image.BILINEAR)\n",
    "                        img_small = np.asarray(img_pil, dtype=np.float32) / 255.0\n",
    "                    img_np = img_small\n",
    "    \n",
    "            # Basic shape check\n",
    "            if img_np.ndim != 3 or img_np.shape[2] < 3:\n",
    "                logger.warning(\"estimate_month_and_ndvi_ensemble: unexpected image shape\")\n",
    "                return 6, 0.5\n",
    "\n",
    "            R = img_np[:, :, 0]\n",
    "            G = img_np[:, :, 1]\n",
    "            B = img_np[:, :, 2]\n",
    "            \n",
    "            eps = 1e-6  \n",
    "            \n",
    "            # ---- vNDVI \n",
    "            vndvi = (G - R) / (G + R + eps)\n",
    "            vndvi = np.clip(vndvi, -1.0, 1.0)\n",
    "            vndvi_mean = float(np.nanmean(vndvi))\n",
    "            \n",
    "            # ---- RGBVI \n",
    "            rgbvi = (G*G - R*B) / (G*G + R*B + eps)\n",
    "            rgbvi = np.clip(rgbvi, -1.0, 1.0)\n",
    "            rgbvi_mean = float(np.nanmean(rgbvi))\n",
    "            rgbvi_mean = max(rgbvi_mean, 0.0)  \n",
    "            \n",
    "            # ---- VARI\n",
    "            den = (G + R - B)\n",
    "            vari = (G - R) / (den + eps)\n",
    "            vari = np.clip(vari, -1.0, 1.0)\n",
    "            vari_mean = float(np.nanmean(vari))\n",
    "            vari_mean = max(vari_mean, 0.0)  \n",
    "            \n",
    "            texture = float(np.std(G) / (np.mean(G) + eps))\n",
    "            texture = np.clip(texture, 0.0, 1.0)\n",
    "            \n",
    "            # STEP 3 â€” Adaptive Fusion (raw RGB NDVI) \n",
    "            green_intensity = float(np.nanmean(G))\n",
    "            \n",
    "            if green_intensity < 0.30:                      \n",
    "                fused_raw = (\n",
    "                    0.25 * vndvi_mean +\n",
    "                    0.25 * rgbvi_mean +\n",
    "                    0.35 * vari_mean +\n",
    "                    0.15 * texture\n",
    "                )\n",
    "            \n",
    "            elif green_intensity > 0.65:                   \n",
    "                fused_raw = (\n",
    "                    0.40 * vndvi_mean +\n",
    "                    0.30 * rgbvi_mean +\n",
    "                    0.15 * vari_mean +\n",
    "                    0.15 * texture\n",
    "                )\n",
    "            \n",
    "            else:                                        \n",
    "                fused_raw = (\n",
    "                    0.33 * vndvi_mean +\n",
    "                    0.33 * rgbvi_mean +\n",
    "                    0.22 * vari_mean +\n",
    "                    0.12 * texture\n",
    "                )\n",
    "            \n",
    "            fused_raw = float(np.clip(fused_raw, 0.0, 1.0))\n",
    "    \n",
    "            #  STEP 4 â€” Load Calibration Stats (prefer species table) \n",
    "            default_true_min = 0.16\n",
    "            default_true_max = 0.91\n",
    "    \n",
    "            # typical observed range of raw fused RGB index (tunable)\n",
    "            rgb_raw_min = 0.0\n",
    "            rgb_raw_max = 0.80\n",
    "    \n",
    "            true_min, true_max = default_true_min, default_true_max\n",
    "    \n",
    "            # 1) If species provided, try per-species NDVI table first\n",
    "            try:\n",
    "                if species is not None:\n",
    "                    ndvi_table_path = \"/kaggle/working/outputs/ndvidata.csv\" \n",
    "                    if hasattr(self, \"_ndvi_table\") and getattr(self, \"_ndvi_table\") is not None:\n",
    "                        ndvi_df = self._ndvi_table\n",
    "                    else:\n",
    "                        if pd.io.common.file_exists(ndvi_table_path):\n",
    "                            ndvi_df = pd.read_csv(ndvi_table_path)\n",
    "                            self._ndvi_table = ndvi_df\n",
    "                        else:\n",
    "                            ndvi_df = None\n",
    "    \n",
    "                    if ndvi_df is not None and 'species' in ndvi_df.columns:\n",
    "                        # match species \n",
    "                        mask = ndvi_df['species'].astype(str).str.lower() == str(species).lower()\n",
    "                        if mask.any():\n",
    "                            row = ndvi_df[mask].iloc[0]\n",
    "                            # prefer ndvi_min/ndvi_max or ndvi_raw_min/raw_max if present:\n",
    "                            if 'ndvi_min' in row.index and 'ndvi_max' in row.index:\n",
    "                                candidate_min = float(row.get('ndvi_min', np.nan))\n",
    "                                candidate_max = float(row.get('ndvi_max', np.nan))\n",
    "                            elif 'min' in row.index and 'max' in row.index:\n",
    "                                candidate_min = float(row.get('min', np.nan))\n",
    "                                candidate_max = float(row.get('max', np.nan))\n",
    "                            else:\n",
    "                                candidate_min = float(row.get('ndvi_mean', np.nan)) - 0.15\n",
    "                                candidate_max = float(row.get('ndvi_mean', np.nan)) + 0.15\n",
    "    \n",
    "                            if np.isfinite(candidate_min) and np.isfinite(candidate_max) and candidate_max > candidate_min:\n",
    "                                true_min, true_max = float(candidate_min), float(candidate_max)\n",
    "                                logger.debug(f\"Calibration using species '{species}' stats: min={true_min:.3f}, max={true_max:.3f}\")\n",
    "                            else:\n",
    "                                logger.info(f\"Species stats found but invalid for '{species}', falling back.\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to use per-species ndvi table for calibration: {e}\")\n",
    "    \n",
    "            # 2) If species not used or failed, try the old test.csv calibration (as fallback)\n",
    "            if (true_max <= true_min) or (true_min == default_true_min and true_max == default_true_max):\n",
    "                try:\n",
    "                    calib_path = \"/kaggle/working/outputs/ndvidata.csv\" \n",
    "                    if pd.io.common.file_exists(calib_path):\n",
    "                        df_cal = pd.read_csv(calib_path)\n",
    "                        cols = set(df_cal.columns.str.lower())\n",
    "                        # support multiple naming conventions\n",
    "                        if {'avg', 'min', 'max'}.issubset(cols):\n",
    "                            true_min = float(df_cal['min'].dropna().iloc[0])\n",
    "                            true_max = float(df_cal['max'].dropna().iloc[0])\n",
    "                        elif {'ndvi_avg', 'ndvi_min', 'ndvi_max'}.issubset(cols):\n",
    "                            true_min = float(df_cal['ndvi_min'].dropna().iloc[0])\n",
    "                            true_max = float(df_cal['ndvi_max'].dropna().iloc[0])\n",
    "                        elif {'avg_ndvi', 'min_ndvi', 'max_ndvi'}.issubset(cols):\n",
    "                            true_min = float(df_cal['min_ndvi'].dropna().iloc[0])\n",
    "                            true_max = float(df_cal['max_ndvi'].dropna().iloc[0])\n",
    "                        else:\n",
    "                            # try first numeric min/max-looking columns\n",
    "                            for c in df_cal.columns:\n",
    "                                if 'min' in c.lower():\n",
    "                                    true_min = float(df_cal[c].dropna().iloc[0])\n",
    "                                if 'max' in c.lower():\n",
    "                                    true_max = float(df_cal[c].dropna().iloc[0])\n",
    "                        logger.debug(f\"Calibration from {calib_path}: min={true_min:.3f}, max={true_max:.3f}\")\n",
    "                except Exception as e:\n",
    "                    logger.info(f\"No calibration csv usable or failed to parse: {e}\")\n",
    "    \n",
    "            # final safety checks & fallback\n",
    "            if not np.isfinite(true_min) or not np.isfinite(true_max) or true_max <= true_min:\n",
    "                true_min, true_max = default_true_min, default_true_max\n",
    "                logger.info(f\"Using default calibration min={true_min}, max={true_max}\")\n",
    "    \n",
    "            #  STEP 5 â€” Linear Calibration (map fused_raw -> true_min..true_max)\n",
    "            denom_scale = (rgb_raw_max - rgb_raw_min) if (rgb_raw_max - rgb_raw_min) != 0 else 1e-8\n",
    "            fused_calibrated = (fused_raw - rgb_raw_min) / denom_scale\n",
    "            fused_calibrated = fused_calibrated * (true_max - true_min) + true_min\n",
    "            fused_calibrated = float(np.clip(fused_calibrated, true_min, true_max))\n",
    "    \n",
    "            # STEP 6 â€” Compute Month and return \n",
    "            month = self._estimate_month_from_ndvi(fused_calibrated)\n",
    "    \n",
    "            logger.debug(\n",
    "                f\"RGB Ensemble: vNDVI={vndvi_mean:.3f}, RGBVI={rgbvi_mean:.3f}, VARI={vari_mean:.3f}, \"\n",
    "                f\"FusedRaw={fused_raw:.3f} â†’ Calibrated={fused_calibrated:.3f}, Month={month}\")\n",
    "            return month, fused_calibrated\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Ensemble RGB NDVI calculation failed: {e}\")\n",
    "            return 6, 0.5\n",
    "\n",
    "    \n",
    "    def _estimate_month_from_ndvi(self, ndvi):\n",
    "        \"\"\"\n",
    "        Estimate month from NDVI using data-driven approach.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not hasattr(self, '_month_profiles'):\n",
    "                self._build_month_profiles()\n",
    "    \n",
    "            if not self._month_profiles:\n",
    "                logger.warning(\"No month profiles available, returning default month 6\")\n",
    "                return 6\n",
    "    \n",
    "            best_month = 6\n",
    "            best_score = -1.0\n",
    "    \n",
    "            for month, profile in self._month_profiles.items():\n",
    "                # Use safe std\n",
    "                profile_std = float(profile.get('std', 0.05))\n",
    "                profile_mean = float(profile.get('mean', 0.5))\n",
    "                # z-score\n",
    "                z_score = (ndvi - profile_mean) / (profile_std + 1e-8)\n",
    "                likelihood = math.exp(-0.5 * (z_score * z_score))\n",
    "                frequency_weight = profile.get('count', 1) / max(p['count'] for p in self._month_profiles.values())\n",
    "                score = likelihood # *frequency_weight removed to prevent bias\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_month = int(month)\n",
    "    \n",
    "            return best_month\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error estimating month: {e}\")\n",
    "            return 6\n",
    "\n",
    "    \n",
    "    def _build_month_profiles(self):\n",
    "        \"\"\"\n",
    "        Build NDVI statistical profiles for each month from training data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.train_df is None:\n",
    "                logger.warning(\"train_df not available, cannot build month profiles\")\n",
    "                self._month_profiles = {}\n",
    "                return\n",
    "    \n",
    "            train_df_copy = self.train_df.copy()\n",
    "            train_df_copy['Month'] = pd.to_datetime(train_df_copy['Sampling_Date'], errors='coerce').dt.month\n",
    "    \n",
    "            self._month_profiles = {}\n",
    "            for month in range(1, 13):\n",
    "                month_data = train_df_copy[train_df_copy['Month'] == month]['Pre_GSHH_NDVI'].dropna().astype(float)\n",
    "                if len(month_data) > 0:\n",
    "                    mean_val = float(month_data.mean())\n",
    "                    std_val = float(month_data.std()) if month_data.std() > 0 else 0.05\n",
    "                    std_val = max(std_val, 0.05)  # floor\n",
    "                    self._month_profiles[month] = {\n",
    "                        'mean': mean_val,\n",
    "                        'std': std_val,\n",
    "                        'count': int(len(month_data)),\n",
    "                    }\n",
    "    \n",
    "            logger.debug(f\"âœ“ Built month profiles for {len(self._month_profiles)} months\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error building month profiles: {e}\")\n",
    "            self._month_profiles = {}\n",
    "\n",
    "    def _intelligent_feature_fetch(self, test_row, species_model=None, prediction=None, device=None):\n",
    "        \"\"\"\n",
    "        Intelligent fallback with image-level caching to avoid recomputing NDVI/height/species \n",
    "        for rows that share the same image_id / sample_id.\n",
    "        \"\"\"\n",
    "        sample_id = test_row.get(\"sample_id\")\n",
    "        target_name = test_row.get(\"target_name\")\n",
    "    \n",
    "        # Normalize keys to match lookups built with .strip().lower()\n",
    "        target_name_norm = str(target_name).strip().lower() if target_name is not None else \"\"\n",
    "        sample_id_norm = str(sample_id).strip().lower() if sample_id is not None else \"\"\n",
    "        image_id = sample_id_norm.split(\"__\")[0] if sample_id_norm else None\n",
    "    \n",
    "        # initialize lookups safely\n",
    "        TRAIN_BY_SAMPLE_ID_TARGET = self.lookups_dict.get('TRAIN_BY_SAMPLE_ID_TARGET', {})\n",
    "        TRAIN_BY_IMAGE_SPECIES_TARGET = self.lookups_dict.get('TRAIN_BY_IMAGE_SPECIES_TARGET', {})\n",
    "        TRAIN_BY_IMAGE_ID_TARGET = self.lookups_dict.get('TRAIN_BY_IMAGE_ID_TARGET', {})\n",
    "        TRAIN_BY_TARGET_STATE_SPECIES = self.lookups_dict.get('TRAIN_BY_TARGET_STATE_SPECIES', {})\n",
    "        \n",
    "        # Diagnostics \n",
    "        lvl1_count = 0\n",
    "        if target_name_norm in TRAIN_BY_SAMPLE_ID_TARGET:\n",
    "            try:\n",
    "                lvl1_count = sum(len(v) for v in TRAIN_BY_SAMPLE_ID_TARGET.get(target_name_norm, {}).values())\n",
    "            except Exception:\n",
    "                lvl1_count = len(TRAIN_BY_SAMPLE_ID_TARGET.get(target_name_norm, {}))\n",
    "        lvl2_image_count = len(TRAIN_BY_IMAGE_ID_TARGET.get(target_name_norm, {}))\n",
    "        lvl2_species_count = len(TRAIN_BY_IMAGE_SPECIES_TARGET.get(target_name_norm, {}))\n",
    "        lvl3_count = len(TRAIN_BY_TARGET_STATE_SPECIES.get(target_name_norm, {}))\n",
    "        logger.debug(f\"_intelligent_feature_fetch: target_name_norm='{target_name_norm}', image_id='{image_id}'\")\n",
    "        logger.debug(f\"Lookup sizes: level1={lvl1_count}, level2_image={lvl2_image_count}, level2_species={lvl2_species_count}, level3={lvl3_count}\")\n",
    "    \n",
    "        # IMAGE-LEVEL CACHE (keyed by image_id if available, else sample_id_norm) \n",
    "        cache_key = image_id or sample_id_norm or test_row.get('image_path', '')\n",
    "        if not hasattr(self, 'test_features_cache') or self.test_features_cache is None:\n",
    "            # ensure cache exists\n",
    "            self.test_features_cache = {}\n",
    "    \n",
    "        cached = self.test_features_cache.get(cache_key, None)\n",
    "    \n",
    "        # If we have a cached computed-image object, reuse it\n",
    "        if cached is None:\n",
    "            # compute and store\n",
    "            img_path = self._resolve_image_path(test_row.get('image_path', ''))\n",
    "            test_image = self._load_image(img_path)\n",
    "            test_image_np = np.array(test_image)\n",
    "    \n",
    "            # expensive computations we want to cache\n",
    "            try:\n",
    "                estimated_height = self.estimate_height_final(test_image_np)\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"estimate_height_final failed: {e}\")\n",
    "                estimated_height = 7.5\n",
    "    \n",
    "            try:\n",
    "                estimated_month, estimated_ndvi = self.estimate_month_and_ndvi_ensemble(test_image_np, species=prediction)\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"estimate_month_and_ndvi_from_image failed: {e}\")\n",
    "                try:\n",
    "                    estimated_month, estimated_ndvi =  self.estimate_month_and_ndvi_from_image(test_image_np)\n",
    "                except Exception:\n",
    "                    estimated_month, estimated_ndvi = 6, 0.5\n",
    "\n",
    "            MONTH_TO_DOY = {\n",
    "                        1: 16, 2: 47, 3: 75, 4: 106, 5: 136, 6: 167,\n",
    "                        7: 197, 8: 228, 9: 259, 10: 289, 11: 320, 12: 350}\n",
    "            estimated_month = int(estimated_month)\n",
    "            estimated_doy = MONTH_TO_DOY.get(estimated_month, 180)\n",
    "            estimated_quarter = max(1, (estimated_month - 1) // 3 + 1)\n",
    "    \n",
    "            # veg_frac computed by compute_features_from_image \n",
    "            try:\n",
    "                feats = self.compute_features_from_image(test_image)\n",
    "                veg_frac = float(np.clip(feats.get('veg_frac', 0.5), 0.0, 1.0))\n",
    "            except Exception:\n",
    "                veg_frac = 0.5\n",
    "    \n",
    "            # species prediction: allow a pre-supplied 'prediction' to override; otherwise compute once\n",
    "            predicted_species = prediction\n",
    "            if (predicted_species is None) and (species_model is not None):\n",
    "                try:\n",
    "                    # predicting_species will do patching and model inference; expensive so we cache result\n",
    "                    predicted_species = self.predicting_species(test_row, species_model=species_model, device=device)\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"predicting_species failed: {e}\")\n",
    "                    predicted_species = None\n",
    "    \n",
    "            # normalize some cached values\n",
    "            def _norm_species_name(s):\n",
    "                if s is None:\n",
    "                    return None\n",
    "                s2 = str(s).strip().lower()\n",
    "                s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "                s2 = s2.replace('.', '')\n",
    "                return s2\n",
    "    \n",
    "            predicted_species_norm = _norm_species_name(predicted_species)\n",
    "    \n",
    "            cached = {\n",
    "                'image_path': str(img_path),\n",
    "                'ndvi': float(np.clip(estimated_ndvi, 0.0, 1.0)),\n",
    "                'month': int(estimated_month),\n",
    "                'doy': int(estimated_doy),\n",
    "                'quarter': int(estimated_quarter),\n",
    "                'estimated_height': float(estimated_height),\n",
    "                'veg_frac': float(veg_frac),\n",
    "                'predicted_species': predicted_species,\n",
    "                'predicted_species_norm': predicted_species_norm\n",
    "            }\n",
    "            cached['state'] = None\n",
    "            # store in cache\n",
    "            try:\n",
    "                self.test_features_cache[cache_key] = cached\n",
    "            except Exception:\n",
    "                # if cache write fails for any reason, ignore â€” caching is optional\n",
    "                logger.debug(\"Warning: failed to write to test_features_cache\")\n",
    "    \n",
    "        else:\n",
    "            # update with any new 'prediction' passed in (higher-level caller may have predicted species already)\n",
    "            if prediction is not None:\n",
    "                cached['predicted_species'] = prediction\n",
    "                # also normalized form\n",
    "                try:\n",
    "                    s = prediction\n",
    "                    s2 = str(s).strip().lower()\n",
    "                    s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "                    s2 = s2.replace('.', '')\n",
    "                    cached['predicted_species_norm'] = s2\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "        # Now reuse cached values for fallback decisions\n",
    "        estimated_ndvi = float(np.clip(cached.get('ndvi', 0.5), 0.0, 1.0))\n",
    "        estimated_month = int(cached.get('month', 6))\n",
    "        estimated_doy = int(cached.get('doy', int(estimated_month * 30.4)))\n",
    "        estimated_quarter = int(cached.get('quarter', max(1, (estimated_month - 1) // 3 + 1)))\n",
    "        estimated_height = float(cached.get('estimated_height', 7.6))\n",
    "        veg_frac = float(cached.get('veg_frac', 0.5))\n",
    "        predicted_species = cached.get('predicted_species', None)\n",
    "        predicted_species_norm = cached.get('predicted_species_norm', None)\n",
    "    \n",
    "        # If predictor returned a dict, extract the 'pred' field\n",
    "        if isinstance(predicted_species, dict):\n",
    "            predicted_species = predicted_species.get('pred', None)\n",
    "    \n",
    "        # convenience normalizer used by lookup matching later\n",
    "        def _norm_species_name(s):\n",
    "            if s is None:\n",
    "                return None\n",
    "            s2 = str(s).strip().lower()\n",
    "            s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "            s2 = s2.replace('.', '')\n",
    "            return s2\n",
    "    \n",
    "        REVERSE_STATE_MAP = {'tas': 'Tas', 'nsw': 'NSW', 'wa': 'WA', 'vic': 'Vic'} \n",
    "        predicted_species_norm = predicted_species_norm or _norm_species_name(predicted_species)\n",
    "        logger.debug(f\"Cached image-level features used: ndvi={estimated_ndvi:.3f}, month={estimated_month}, height={estimated_height:.2f}, species_norm={predicted_species_norm}\")\n",
    "        cached_state = cached.get('state', None)\n",
    "        # LEVEL 1: state + species\n",
    "        try:\n",
    "            level3 = TRAIN_BY_TARGET_STATE_SPECIES.get(target_name_norm, {})\n",
    "            if not level3:\n",
    "                logger.info(f\"LEVEL 3 empty for target '{target_name_norm}' (no TRAIN_BY_TARGET_STATE_SPECIES entries)\")\n",
    "            else:\n",
    "                if predicted_species_norm:\n",
    "                    for state, species_dict in level3.items():\n",
    "                        if predicted_species_norm in species_dict:\n",
    "                            # use cached image-level estimates for ndvi/height/month\n",
    "                            row = random.choice(species_dict[predicted_species_norm])\n",
    "                            state_counts = {'tas': 690, 'vic': 560, 'nsw': 375, 'wa': 160}\n",
    "                            state0 = state  \n",
    "                            states = np.array(list(state_counts.keys()), dtype=object)\n",
    "                            counts = np.array(list(state_counts.values()), dtype=float)\n",
    "                            total = counts.sum()\n",
    "                            emp_probs = counts / total\n",
    "                            state_frequency = state_counts[state0] / total\n",
    "                            alpha = 0.3 if state_frequency < 0.25 else 0.5\n",
    "                            prior = np.zeros_like(emp_probs)\n",
    "                            prior[states == state0] = 1.0\n",
    "                            final_probs = alpha * prior + (1.0 - alpha) * emp_probs\n",
    "                            final_probs = final_probs / final_probs.sum() \n",
    "                            state_new = np.random.choice(states, p=final_probs)\n",
    "                            state_final = cached_state.lower() if cached_state is not None else state_new \n",
    "                            fetched = {\n",
    "                                'ndvi': estimated_ndvi,\n",
    "                                'height': estimated_height,\n",
    "                                'month': estimated_month,\n",
    "                                'doy': estimated_doy,\n",
    "                                'quarter': estimated_quarter,\n",
    "                                'state': REVERSE_STATE_MAP.get(state_final, state),\n",
    "                                'species': predicted_species,\n",
    "                                'level': 1,\n",
    "                                'source': f\"State+Species: {state_new}-{predicted_species_norm}\",\n",
    "                                'species_source': 'predicted'\n",
    "                            }\n",
    "                            logger.debug(\"Level 1a Fallback Used (The Best)\")\n",
    "                            # cache the state for future rows of the same image\n",
    "                            try:\n",
    "                                state_lower = str(fetched['state']).strip().lower()\n",
    "                                self.test_features_cache[cache_key]['state'] = state_lower\n",
    "                            except:\n",
    "                                pass\n",
    "                            logger.debug(\n",
    "                                    f\"Prediction complete | state={fetched['state']} | \"\n",
    "                                    f\"species={fetched['species']} | ndvi={fetched['ndvi']:.3f} | \"\n",
    "                                    f\"height={fetched['height']:.2f} | source={fetched['source']}\"\n",
    "                                    )\n",
    "                            return fetched\n",
    "    \n",
    "                    # try normalized key matching inside species_dict\n",
    "                    for state, species_dict in level3.items():\n",
    "                        for sp_k in species_dict.keys():\n",
    "                            if _norm_species_name(sp_k) == predicted_species_norm:\n",
    "                                row = random.choice(species_dict[sp_k])\n",
    "                                fetched = {\n",
    "                                    'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                                    'height': row['Height_Ave_cm'],\n",
    "                                    'month': row['Month'],\n",
    "                                    'doy': row['DayOfYear'],\n",
    "                                    'quarter': row['Quarter'],\n",
    "                                    'state': state,\n",
    "                                    'species': row.get('Species', sp_k),\n",
    "                                    'level': 1,\n",
    "                                    'source': f\"State+Species (norm-match): {state}-{sp_k}\",\n",
    "                                    'species_source': 'predicted'\n",
    "                                }\n",
    "                                logger.info(\"Level 1a v2 Fallback Used\")\n",
    "                                return fetched\n",
    "    \n",
    "                # fallback random pick from level1 if any entries exist\n",
    "                if level3:\n",
    "                    state = random.choice(list(level3.keys()))\n",
    "                    species = random.choice(list(level3[state].keys()))\n",
    "                    row = random.choice(level3[state][species])\n",
    "                    fetched = {\n",
    "                        'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                        'height': row['Height_Ave_cm'],\n",
    "                        'month': row['Month'],\n",
    "                        'doy': row['DayOfYear'],\n",
    "                        'quarter': row['Quarter'],\n",
    "                        'state': state,\n",
    "                        'species': species,\n",
    "                        'level': 1,\n",
    "                        'source': f\"State+Species: {state}-{species}\",\n",
    "                        'species_source': 'training_data'\n",
    "                    }\n",
    "                    logger.info(\"Level 1b Fallback Used\")\n",
    "                    return fetched\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 1 failed: {e}\")\n",
    "    \n",
    "        # LEVEL 2: sample_id + target\n",
    "        try:\n",
    "            level1 = TRAIN_BY_SAMPLE_ID_TARGET.get(target_name_norm, {})\n",
    "            if sample_id_norm and sample_id_norm in level1:\n",
    "                row = random.choice(level1[sample_id_norm])\n",
    "                fetched = {\n",
    "                    'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                    'height': row['Height_Ave_cm'],\n",
    "                    'month': row['Month'],\n",
    "                    'doy': row['DayOfYear'],\n",
    "                    'quarter': row['Quarter'],\n",
    "                    'state': row['State'],\n",
    "                    'species': row['Species'],\n",
    "                    'level': 2,\n",
    "                    'source': f\"Exact: {sample_id_norm}\",\n",
    "                    'species_source': 'training_data'\n",
    "                }\n",
    "                logger.info(\"Level 2 Fallback Used\")\n",
    "                return fetched\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 2 failed: {e}\")\n",
    "    \n",
    "        # LEVEL 3: image_id + species\n",
    "        try:\n",
    "            level2_species_map = TRAIN_BY_IMAGE_SPECIES_TARGET.get(target_name_norm, {})\n",
    "            level2_image_map = TRAIN_BY_IMAGE_ID_TARGET.get(target_name_norm, {})\n",
    "    \n",
    "            # 2a: image + species\n",
    "            if image_id and predicted_species_norm:\n",
    "                # try tuple-key first\n",
    "                key_candidates = [\n",
    "                    (image_id, predicted_species_norm),\n",
    "                    (image_id, predicted_species_norm.replace('_', ' ')),\n",
    "                    (image_id, predicted_species_norm.replace('_', ''))\n",
    "                ]\n",
    "                rows = []\n",
    "                for key in key_candidates:\n",
    "                    rows = level2_species_map.get(key, [])\n",
    "                    if rows:\n",
    "                        break\n",
    "    \n",
    "                # if not found, try scanning level2 map for matching image_id and normalized species\n",
    "                if not rows:\n",
    "                    for kk, vals in list(level2_species_map.items()):\n",
    "                        try:\n",
    "                            ik, sk = kk\n",
    "                            if str(ik) == image_id and _norm_species_name(sk) == predicted_species_norm:\n",
    "                                rows = vals\n",
    "                                break\n",
    "                        except Exception:\n",
    "                            # could be string key; try to match roughly\n",
    "                            if isinstance(kk, str) and image_id in kk and predicted_species_norm in kk:\n",
    "                                rows = vals\n",
    "                                break\n",
    "    \n",
    "                if rows:\n",
    "                    row = random.choice(rows)\n",
    "                    fetched = {\n",
    "                        'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                        'height': row['Height_Ave_cm'],\n",
    "                        'month': row['Month'],\n",
    "                        'doy': row['DayOfYear'],\n",
    "                        'quarter': row['Quarter'],\n",
    "                        'state': row['State'],\n",
    "                        'species': row['Species'],\n",
    "                        'level': 3,\n",
    "                        'source': f\"Image {image_id} + Predicted Species\",\n",
    "                        'species_source': 'predicted'\n",
    "                    }\n",
    "                    logger.info(\"Level 3a Fallback Used\")\n",
    "                    return fetched\n",
    "    \n",
    "            # 3b: image only\n",
    "            if image_id and image_id in level2_image_map:\n",
    "                row = random.choice(level2_image_map[image_id])\n",
    "                fetched = {\n",
    "                    'ndvi': row['Pre_GSHH_NDVI'],\n",
    "                    'height': row['Height_Ave_cm'],\n",
    "                    'month': row['Month'],\n",
    "                    'doy': row['DayOfYear'],\n",
    "                    'quarter': row['Quarter'],\n",
    "                    'state': row['State'],\n",
    "                    'species': row['Species'],\n",
    "                    'level': 3,\n",
    "                    'source': f\"Image {image_id}\",\n",
    "                    'species_source': 'training_data'\n",
    "                }\n",
    "                logger.info(\"Level 3b Fallback Used\")\n",
    "                return fetched\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 3 failed: {e}\")\n",
    "    \n",
    "        # LEVEL 4: target statistics\n",
    "        try:\n",
    "            stats = self.lookups_dict.get('TABULAR_STATS_BY_TARGET', {}).get(target_name_norm,\n",
    "                                                                            self.lookups_dict.get('TABULAR_STATS', {}))\n",
    "            ndvi = np.clip(np.random.normal(stats.get('ndvi_mean', estimated_ndvi if 'estimated_ndvi' in locals() else 0.65),\n",
    "                                           stats.get('ndvi_std', 0.15)), 0.0, 1.0)\n",
    "            HEIGHT_MAX = getattr(self, \"HEIGHT_MAX\", self.lookups_dict.get(\"HEIGHT_MAX\", 80.0))\n",
    "            height = np.clip(np.random.normal(stats.get('height_mean', estimated_height if 'estimated_height' in locals() else 7.6),\n",
    "                                              stats.get('height_std', 10.3)), 0.0, HEIGHT_MAX)\n",
    "            doy = int(stats.get('sampling_date_mean', estimated_doy if 'estimated_doy' in locals() else 197))\n",
    "            month = max(1, (doy - 1) // 30 + 1)\n",
    "            quarter = max(1, (month - 1) // 3 + 1)\n",
    "            unique_states = self.lookups_dict.get('UNIQUE_STATES', ['NSW'])\n",
    "            state = np.random.choice(unique_states)\n",
    "            species = predicted_species_norm or np.random.choice(self.lookups_dict.get('UNIQUE_SPECIES', ['clover']))\n",
    "            species_source = 'predicted' if predicted_species_norm else 'training_data'\n",
    "            logger.info(\"Level 4 Fallback Used\")\n",
    "            return {\n",
    "                'ndvi': float(ndvi), 'height': float(height),\n",
    "                'month': int(month), 'doy': int(doy), 'quarter': int(quarter),\n",
    "                'state': state, 'species': species,\n",
    "                'level': 4, 'source': f\"Target stats {target_name_norm}\",\n",
    "                'species_source': species_source\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"LEVEL 4 failed: {e}\")\n",
    "    \n",
    "        # default fallback\n",
    "        logger.info(\"Default Fallback is Being Used.\")\n",
    "        return self._get_default_features(test_row)\n",
    "\n",
    "\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        try:\n",
    "            p = self._resolve_image_path(image_path)\n",
    "\n",
    "            # Missing file â†’ sentinel image\n",
    "            if not p.exists():\n",
    "                self._missing_count = getattr(self, '_missing_count', 0) + 1\n",
    "                if self._missing_count <= 10:\n",
    "                    logger.warning(f\"Image missing {p} â€“ using SENTINEL MAGENTA (#{self._missing_count})\")\n",
    "                return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "            # Load image with OpenCV\n",
    "            img = cv2.imread(str(p), cv2.IMREAD_UNCHANGED)\n",
    "            if img is None:\n",
    "                self._missing_count = getattr(self, '_missing_count', 0) + 1\n",
    "                if self._missing_count <= 10:\n",
    "                    logger.warning(f\"Image unreadable {p} â€“ using SENTINEL MAGENTA (#{self._missing_count})\")\n",
    "                return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "            # Convert various channel formats\n",
    "            if img.ndim == 2:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            elif img.shape[2] == 3:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            elif img.shape[2] == 4:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "            else:\n",
    "                try:\n",
    "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                except Exception:\n",
    "                    return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "            return Image.fromarray(img_rgb)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error loading {image_path}: {e}\")\n",
    "            return Image.new('RGB', (self.image_width, self.image_height), color=self.SENTINEL_COLOR)\n",
    "\n",
    "\n",
    "\n",
    "    def _crop_patches(self, image):\n",
    "        patches = []\n",
    "        w, h = image.size\n",
    "        target_w, target_h = 2000, 1000\n",
    "        if (w,h) != (target_w, target_h):\n",
    "            image = image.resize((target_w, target_h), Image.BILINEAR)\n",
    "        crop_coords = [\n",
    "            (0, 0, 500, 500), (500, 0, 1000, 500),\n",
    "            (1000, 0, 1500, 500), (1500, 0, 2000, 500),\n",
    "            (0, 500, 500, 1000), (500, 500, 1000, 1000),\n",
    "            (1000, 500, 1500, 1000), (1500, 500, 2000, 1000),\n",
    "        ]\n",
    "        for left, top, right, bottom in crop_coords:\n",
    "            patch = F.crop(image, top=top, left=left,\n",
    "                          height=bottom-top, width=right-left)\n",
    "            patch = patch.resize((self.model_input_size[0], self.model_input_size[1]), Image.BILINEAR)\n",
    "            patches.append(patch)\n",
    "        return patches\n",
    "\n",
    "    def _get_default_features(self, test_row):\n",
    "        return {\n",
    "            'month': 6,\n",
    "            'doy': 180,\n",
    "            'quarter': 2,\n",
    "            'state': 'NSW',\n",
    "            'species': 'Clover',\n",
    "            'ndvi': 0.6,\n",
    "            'height': 15.0,\n",
    "            'level': -1,\n",
    "            'source': \"Hardcoded defaults (no lookups)\",\n",
    "        }\n",
    "\n",
    "    def _build_features_from_fetch(self, test_row, lookups_dict):\n",
    "        \"\"\"\n",
    "        Build complete tabular feature vector for test row.\n",
    "        \n",
    "        Column order MUST match training:\n",
    "        [numeric_cols | state_cols | species_cols | target_type_cols]\n",
    "        \n",
    "        Returns: (features_tensor, target_idx)\n",
    "        \"\"\"\n",
    "        numeric_cols = lookups_dict.get('TAB_NUMERIC_COLS', [])\n",
    "        state_cols = lookups_dict.get('STATE_COLS', [])\n",
    "        species_cols = lookups_dict.get('SPECIES_COLS', [])\n",
    "        target_type_cols = lookups_dict.get('TARGET_TYPE_COLS', [])\n",
    "        scaler = lookups_dict.get('TAB_SCALER', None)\n",
    "        \n",
    "        # ===== NUMERIC FEATURES =====\n",
    "        raw_numeric = []\n",
    "        for col in numeric_cols:\n",
    "            if col == 'Pre_GSHH_NDVI':\n",
    "                val = float(test_row.get('Pre_GSHH_NDVI', 0.5))\n",
    "                raw_numeric.append(np.clip(val, 0.0, 1.0))\n",
    "            elif col == 'Height_Ave_cm':\n",
    "                val = float(test_row.get('Height_Ave_cm', 10.0))\n",
    "                raw_numeric.append(np.clip(val, 0.0, 100.0))\n",
    "            elif col == 'Month':\n",
    "                val = float(test_row.get('Month', 6))\n",
    "                raw_numeric.append(np.clip(val, 1.0, 12.0))\n",
    "            elif col == 'DayOfYear':\n",
    "                val = float(test_row.get('DayOfYear', 1))\n",
    "                raw_numeric.append(np.clip(val, 1.0, 365.0))\n",
    "            elif col == 'Quarter':\n",
    "                val = float(test_row.get('Quarter', 1))\n",
    "                raw_numeric.append(np.clip(val, 1.0, 4.0))\n",
    "            else:\n",
    "                raw_numeric.append(float(test_row.get(col, 0.0)))\n",
    "        \n",
    "        # Scale numeric features if scaler available\n",
    "        if scaler is not None and len(raw_numeric) > 0:\n",
    "            try:\n",
    "                scaled_numeric = scaler.transform([raw_numeric])[0].tolist()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Scaler transform failed: {e}, using raw values\")\n",
    "                scaled_numeric = raw_numeric\n",
    "        else:\n",
    "            scaled_numeric = raw_numeric\n",
    "        \n",
    "        features = list(scaled_numeric)\n",
    "        \n",
    "        # ===== STATE ONE-HOT =====\n",
    "        def _safe_to_float(x):\n",
    "            if isinstance(x, (bool, np.bool_)):\n",
    "                return 1.0 if x else 0.0\n",
    "            try:\n",
    "                return float(x)\n",
    "            except Exception:\n",
    "                return 0.0\n",
    "        \n",
    "        for col in state_cols:\n",
    "            features.append(_safe_to_float(test_row.get(col, 0)))\n",
    "        \n",
    "        # ===== SPECIES ONE-HOT =====\n",
    "        for col in species_cols:\n",
    "            features.append(_safe_to_float(test_row.get(col, 0)))\n",
    "        \n",
    "        # ===== TARGET TYPE ONE-HOT =====\n",
    "        target_onehot = []\n",
    "        for col in target_type_cols:\n",
    "            target_onehot.append(_safe_to_float(test_row.get(col, 0)))\n",
    "        \n",
    "        for val in target_onehot:\n",
    "            features.append(val)\n",
    "        \n",
    "        # ===== EXTRACT TARGET_IDX (CRITICAL FOR META-LEARNER) =====\n",
    "        # target_idx is the argmax of the one-hot encoding at the END\n",
    "        target_idx = 0\n",
    "        if len(target_onehot) > 0:\n",
    "            try:\n",
    "                target_idx = int(np.argmax(target_onehot))\n",
    "            except Exception:\n",
    "                target_idx = 0\n",
    "        \n",
    "        # ===== RETURN =====\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "        \n",
    "        logger.debug(f\"Built features: {len(features)} dims, target_idx={target_idx}\")\n",
    "        logger.debug(f\"  Numeric: {len(scaled_numeric)} | State: {len(state_cols)} | Species: {len(species_cols)} | Target: {len(target_onehot)}\")\n",
    "        \n",
    "        return features_tensor, target_idx\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = self._load_image(row['image_path'])\n",
    "        patches = self._crop_patches(img)\n",
    "    \n",
    "        # build image tensor batch (8 patches)\n",
    "        if self.transform:\n",
    "            images = torch.stack([self.transform(p) for p in patches])\n",
    "        else:\n",
    "            images = torch.stack([transforms.ToTensor()(p) for p in patches])\n",
    "    \n",
    "        # features: test uses intelligent fetch, train/val uses _extract_train_tabular\n",
    "        target_idx = 0  # NEW: Initialize target_idx\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            prediction = self.predicting_species(row, species_model=self.species_model, device=self.device)\n",
    "            fetched = self._intelligent_feature_fetch(\n",
    "                row, species_model=self.species_model, prediction=prediction, device=self.device)\n",
    "            if fetched is None:\n",
    "                fetched = self._get_default_features(row)\n",
    "            \n",
    "            # NEW: Get both features AND target_idx\n",
    "            features_tensor, target_idx = self._build_features_from_fetch(fetched, self.lookups_dict)\n",
    "            features_1d = features_tensor.numpy()\n",
    "        else:\n",
    "            features_1d = self._extract_train_tabular(row).numpy()\n",
    "            \n",
    "            # EXTRACT target_idx from training row (from one-hot encoding)\n",
    "            target_type_cols = self.lookups_dict.get('TARGET_TYPE_COLS', [])\n",
    "            numeric_cols = self.lookups_dict.get('TAB_NUMERIC_COLS', [])\n",
    "            state_cols = self.lookups_dict.get('STATE_COLS', [])\n",
    "            species_cols = self.lookups_dict.get('SPECIES_COLS', [])\n",
    "            \n",
    "            # Position where target one-hot starts\n",
    "            target_start = len(numeric_cols) + len(state_cols) + len(species_cols)\n",
    "            target_end = target_start + len(target_type_cols)\n",
    "            \n",
    "            if target_end <= len(features_1d):\n",
    "                target_onehot = features_1d[target_start:target_end]\n",
    "                try:\n",
    "                    target_idx = int(np.argmax(target_onehot))\n",
    "                except Exception:\n",
    "                    target_idx = 0\n",
    "            else:\n",
    "                target_idx = 0\n",
    "    \n",
    "        # repeat per patch\n",
    "        features = np.repeat(features_1d[np.newaxis, :], self.num_patches, axis=0).astype(np.float32)\n",
    "        features = torch.from_numpy(features).float()\n",
    "    \n",
    "        sample_id = row.get('sample_id', None)\n",
    "        target_name = row.get('target_name', None)\n",
    "    \n",
    "        species_idx = None\n",
    "    \n",
    "        def _norm_species_name_val(s):\n",
    "            if s is None:\n",
    "                return \"mixed\"\n",
    "            s2 = str(s).strip().lower()\n",
    "            s2 = re.sub(r\"[\\s\\-]+\", \"_\", s2)\n",
    "            s2 = s2.replace(\".\", \"\")\n",
    "            # treat empty-like values as \"nothing\"\n",
    "            if s2 == \"\" or s2 in {\"nan\", \"none\", \"null\"}:\n",
    "                return \"mixed\"\n",
    "            return s2\n",
    "    \n",
    "        fixed_species_norm = None\n",
    "        try:\n",
    "            scols = self.lookups_dict.get(\"SPECIES_COLS\", None)\n",
    "            if scols:\n",
    "                fixed_species_norm = [\n",
    "                    _norm_species_name_val(c.replace(\"Species_\", \"\")) if isinstance(c, str) else _norm_species_name_val(c)\n",
    "                    for c in scols\n",
    "                ]\n",
    "        except Exception:\n",
    "            fixed_species_norm = None\n",
    "    \n",
    "        if (not fixed_species_norm) and ('FIXED_SPECIES_LIST' in globals()):\n",
    "            fixed_species_norm = [\n",
    "                _norm_species_name_val(s) for s in globals().get('FIXED_SPECIES_LIST', [])\n",
    "            ]\n",
    "        if not fixed_species_norm:\n",
    "            try:\n",
    "                if getattr(self, \"train_df\", None) is not None and 'Species' in self.train_df.columns:\n",
    "                    tmp_list = self.train_df['Species'].fillna('').astype(str).apply(_norm_species_name_val).unique().tolist()\n",
    "                    fixed_species_norm = list(dict.fromkeys(tmp_list))\n",
    "                else:\n",
    "                    fixed_species_norm = [\"nothing\"]\n",
    "            except Exception:\n",
    "                fixed_species_norm = [\"nothing\"]\n",
    "        if \"nothing\" not in fixed_species_norm:\n",
    "            fixed_species_norm = fixed_species_norm + [\"nothing\"]\n",
    "    \n",
    "        if not hasattr(self, \"species_to_idx\") or not isinstance(self.species_to_idx, dict) or len(self.species_to_idx) != len(fixed_species_norm):\n",
    "            self.species_to_idx = {s: i for i, s in enumerate(fixed_species_norm)}\n",
    "            # also store reverse for convenience\n",
    "            self.idx_to_species = {i: s for s, i in self.species_to_idx.items()}\n",
    "    \n",
    "        species_raw = None\n",
    "        if 'Species_canon' in row.index and pd.notna(row.get('Species_canon', None)) and str(row.get('Species_canon')).strip() != \"\":\n",
    "            species_raw = row.get('Species_canon')\n",
    "        else:\n",
    "            species_raw = row.get('Species', None)\n",
    "    \n",
    "        species_norm = _norm_species_name_val(species_raw)\n",
    "    \n",
    "        if species_norm not in self.species_to_idx:\n",
    "            logger.debug(f\"Species '{species_raw}' normalized -> '{species_norm}' not in fixed vocab; mapping to 'nothing'\")\n",
    "            species_norm = \"mixed\"\n",
    "        species_idx = int(self.species_to_idx.get(species_norm, self.species_to_idx.get(\"mixed\", 0)))\n",
    "    \n",
    "        # FINAL RETURNS - NOW INCLUDES target_idx\n",
    "        if self.mode == 'test':\n",
    "            return images, features, species_idx, target_idx, None, sample_id, target_name\n",
    "        else:\n",
    "            target = float(row['target'])\n",
    "            return images, features, species_idx, target_idx, target, sample_id, target_name\n",
    "\n",
    "\n",
    "    def calibrate_height_model(\n",
    "        self,\n",
    "        image_col='image_path',\n",
    "        height_col='Height_Ave_cm',\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        min_positive_samples=5,\n",
    "        fit_ridge=True,\n",
    "        ridge_alphas=(0.01, 0.1, 1.0, 10.0),\n",
    "        verbose=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calibrate height estimator from training images:\n",
    "          - compute features and combined_score using self.compute_features_from_image(image)\n",
    "          - fit power-law (log-linear): log(h) = log(a) + b * log(score) -> saves self.height_a, self.height_b\n",
    "          - optionally fit  to predict log(height) from features -> saves self.height_model and self.height_model_type='log'\n",
    "          - evaluate on a holdout set and return metrics & trained models.\n",
    "    \n",
    "        Returns:\n",
    "            dict with:\n",
    "              - 'n_samples', 'n_positive', 'powerlaw': {'a','b','rmse','mae','r2'}, \n",
    "                'ridge': {model, 'rmse','mae','r2'} (if fit_ridge True), \n",
    "              - 'df_features' (pandas DataFrame used for fitting)\n",
    "        \"\"\"\n",
    "    \n",
    "        # defensive checks\n",
    "        if not hasattr(self, 'train_df') or self.train_df is None:\n",
    "            raise ValueError(\"train_df not found on self. Populate self.train_df first.\")\n",
    "    \n",
    "        df = self.train_df.copy()\n",
    "    \n",
    "        # find image column\n",
    "        if image_col not in df.columns:\n",
    "            # try common alternatives\n",
    "            if 'image_id' in df.columns and 'image_path' in df.columns:\n",
    "                image_col = 'image_path' if 'image_path' in df.columns else 'image_id'\n",
    "            elif 'image_path' in df.columns:\n",
    "                image_col = 'image_path'\n",
    "            else:\n",
    "                raise ValueError(f\"Image column '{image_col}' not found in train_df\")\n",
    "\n",
    "        # collect features\n",
    "        features_rows = []\n",
    "        total_rows = len(df)\n",
    "        iterator = range(total_rows)\n",
    "        if verbose:\n",
    "            iterator = tqdm(iterator, desc=\"Extract features\", unit=\"rows\")\n",
    "    \n",
    "        for i in iterator:\n",
    "            r = df.iloc[i]\n",
    "            img_identifier = r.get(image_col, None)\n",
    "            img = None\n",
    "    \n",
    "            if pd.isna(img_identifier) or img_identifier is None:\n",
    "                img_identifier = None\n",
    "    \n",
    "            try:\n",
    "              \n",
    "                if isinstance(img_identifier, str) and img_identifier.strip() != \"\":\n",
    "                    img_id = img_identifier.strip()\n",
    "                    # Remove leading 'train/' or 'test/'\n",
    "                    if img_id.startswith(\"train/\"):\n",
    "                        img_id = img_id[len(\"train/\"):]\n",
    "                    elif img_id.startswith(\"test/\"):\n",
    "                        img_id = img_id[len(\"test/\"):]\n",
    "                    \n",
    "                    # Build correct absolute path\n",
    "                    p = Path(self.image_dir) / img_id\n",
    "    \n",
    "                    try:\n",
    "                        with Image.open(str(p)) as _img:\n",
    "                            img = _img.convert(\"RGB\").copy()\n",
    "                    except Exception:\n",
    "                        try:\n",
    "                            arr = cv2.imread(str(p))\n",
    "                            if arr is not None:\n",
    "                                arr_rgb = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)\n",
    "                                img = Image.fromarray(arr_rgb)\n",
    "                            else:\n",
    "                                img = None\n",
    "                        except Exception:\n",
    "                            img = None\n",
    "    \n",
    "                elif isinstance(img_identifier, (np.ndarray,)):\n",
    "                    try:\n",
    "                        img = Image.fromarray(np.uint8(img_identifier)).convert(\"RGB\")\n",
    "                    except Exception:\n",
    "                        img = None\n",
    "    \n",
    "\n",
    "                elif isinstance(img_identifier, Image.Image):\n",
    "                    img = img_identifier.convert(\"RGB\")\n",
    "    \n",
    "            except Exception:\n",
    "                img = None\n",
    "    \n",
    "            if img is None:\n",
    "                try:\n",
    "                    img = Image.new(\"RGB\", (self.image_width, self.image_height), color=(255, 0, 255))\n",
    "                except Exception:\n",
    "                    img = Image.new(\"RGB\", (200, 200), color=(255, 0, 255))\n",
    "\n",
    "            #=========================================\n",
    "            #Remove Later to use Full size Image\n",
    "            #========================================\n",
    "            # Resize image for consistent calibration \n",
    "            MAX_SIZE = 512\n",
    "            w, h = img.size\n",
    "            scale = MAX_SIZE / max(w, h)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            img = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "            #====================================================\n",
    "            try:\n",
    "                feats = self.compute_features_from_image(img)\n",
    "            except Exception:\n",
    "                feats = {'ndvi': 0.5, 'texture': 0.02, 'green': 0.4, 'brightness': 0.5, 'height_proxy': 0.4, 'veg_frac': 0.5}\n",
    "    \n",
    "            combined_score = (\n",
    "                0.35 * feats['ndvi'] +\n",
    "                0.25 * feats['texture'] +\n",
    "                0.20 * feats['green'] +\n",
    "                0.10 * feats['brightness'] +\n",
    "                0.10 * feats['height_proxy']\n",
    "            )\n",
    "            MIN_SCORE = 1e-2   \n",
    "            combined_score = float(np.clip(combined_score * (0.5 + 0.5 * feats.get('veg_frac', 1.0)), MIN_SCORE, 1.0))\n",
    "    \n",
    "            features_rows.append({\n",
    "                'index': i,\n",
    "                'image_id': img_identifier if isinstance(img_identifier, str) else f\"img_{i}\",\n",
    "                'ndvi': float(feats['ndvi']),\n",
    "                'texture': float(feats['texture']),\n",
    "                'green': float(feats['green']),\n",
    "                'brightness': float(feats['brightness']),\n",
    "                'height_proxy': float(feats['height_proxy']),\n",
    "                'veg_frac': float(feats.get('veg_frac', 0.5)),\n",
    "                'combined_score': combined_score,\n",
    "                'height_cm_true': float(r[height_col]) if (height_col in df.columns and not pd.isna(r[height_col])) else np.nan\n",
    "            })\n",
    "    \n",
    "    \n",
    "        df_features = pd.DataFrame(features_rows)\n",
    "        cs = df_features['combined_score'].astype(float)\n",
    "        cs_norm = (cs - cs.min()) / (cs.max() - cs.min() + 1e-6)\n",
    "        cs_norm = cs_norm.clip(1e-3, 1.0)\n",
    "        \n",
    "        df_features['combined_score_norm'] = cs_norm\n",
    "        feat_cols = ['ndvi','texture','green','brightness','height_proxy','veg_frac']\n",
    "        for c in feat_cols:\n",
    "            df_features[c] = pd.to_numeric(df_features[c], errors='coerce')\n",
    "        medians = df_features[feat_cols].median()\n",
    "        # if many rows have all NaNs, they should be dropped for calibrationX_log\n",
    "        all_missing_mask = df_features[feat_cols].isna().all(axis=1)\n",
    "        if all_missing_mask.sum() > 0:\n",
    "            logger.info(f\"Dropping {all_missing_mask.sum()} rows with all features missing for height calibration.\")\n",
    "        df_features.loc[:, feat_cols] = df_features.loc[:, feat_cols].fillna(medians)\n",
    "        # only rows with ground truth\n",
    "        mask_gt = df_features['height_cm_true'].notnull()\n",
    "        n_total = len(df_features)\n",
    "        n_gt = int(mask_gt.sum())\n",
    "    \n",
    "        results = {'n_samples': n_total, 'n_positive': n_gt, 'powerlaw': None, 'ridge': None, 'df_features': df_features}\n",
    "    \n",
    "        if n_gt < min_positive_samples:\n",
    "            # not enough GT to fit\n",
    "            logger.warning(f\"Not enough ground-truth samples to fit calibration (found {n_gt}, need >= {min_positive_samples}).\")\n",
    "            return results\n",
    "    \n",
    "        # prepare arrays for fitting\n",
    "        df_gt = df_features.loc[mask_gt].copy()\n",
    "        # ensure positive combined_score & height\n",
    "        pos_mask = (df_gt['combined_score'] > 0) & (df_gt['height_cm_true'] > 0)\n",
    "        df_gt = df_gt.loc[pos_mask].copy()\n",
    "        if len(df_gt) < min_positive_samples:\n",
    "            logger.warning(f\"After removing nonpositive samples, only {len(df_gt)} samples remain. Aborting fit.\")\n",
    "            return results\n",
    "    \n",
    "        # Fit power-law: log(height) = log(a) + b * log(score)\n",
    "        X_log = np.log1p(df_gt['combined_score_norm'].values).reshape(-1, 1)\n",
    "        y_log = np.log1p(df_gt['height_cm_true'].values).reshape(-1, 1)\n",
    "        lr = LinearRegression().fit(X_log, y_log)\n",
    "        b = float(lr.coef_[0][0])\n",
    "        loga = float(lr.intercept_[0])\n",
    "        a = float(np.exp(loga))\n",
    "        # Save to self\n",
    "        self.height_a = a\n",
    "        self.height_b = b\n",
    "    \n",
    "        # Evaluate on holdout split for power-law\n",
    "        bins = pd.qcut(df_gt['height_cm_true'], q=10, duplicates='drop')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_gt['combined_score_norm'].values,\n",
    "            df_gt['height_cm_true'].values,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=bins\n",
    "        )\n",
    "        \n",
    "        mask_train = (X_train > 0) & (y_train > 0)\n",
    "        if mask_train.sum() >= 3:\n",
    "            lr2 = LinearRegression().fit(\n",
    "                np.log1p(X_train[mask_train]).reshape(-1, 1),\n",
    "                np.log1p(y_train[mask_train]).reshape(-1, 1))\n",
    "        \n",
    "            loga_train = float(np.ravel(lr2.intercept_)[0])\n",
    "            b_train = float(np.ravel(lr2.coef_)[0])\n",
    "        \n",
    "            X_test_pos = np.maximum(X_test, 1e-6)\n",
    "            preds_power = np.expm1(loga_train + b_train * np.log1p(X_test_pos))\n",
    "        \n",
    "            # data-driven cap (robust fallback)\n",
    "            q99 = df_gt['height_cm_true'].dropna().quantile(0.99)\n",
    "        \n",
    "            HEIGHT_MAX = getattr(self, \"HEIGHT_MAX\", self.lookups_dict.get(\"HEIGHT_MAX\", 80.0))\n",
    "            preds_power = np.clip(preds_power, 0.0, HEIGHT_MAX * 1.3)\n",
    "\n",
    "            rmse_p = float(np.sqrt(mean_squared_error(y_test, preds_power)))\n",
    "            mae_p = float(mean_absolute_error(y_test, preds_power))\n",
    "            if np.allclose(y_test, y_test[0]):\n",
    "                r2_p = float('nan')\n",
    "            else:\n",
    "                r2_p = r2_score(np.log1p(y_test), np.log1p(preds_power))\n",
    "        else:\n",
    "            rmse_p = mae_p = r2_p = float('nan')\n",
    "\n",
    "        results['powerlaw'] = {'a': a, 'b': b, 'rmse': rmse_p, 'mae': mae_p, 'r2': r2_p}\n",
    "    \n",
    "        if fit_ridge:\n",
    "            # Prepare features & log1p target\n",
    "            X_feats = df_gt[['ndvi','texture','green','brightness','height_proxy','veg_frac']].values.astype(float)\n",
    "            y_log_all = np.log1p(df_gt['height_cm_true'].values)\n",
    "        \n",
    "            # Holdout split\n",
    "            X_tr, X_te, ytr, yte = train_test_split(\n",
    "                X_feats, y_log_all,\n",
    "                test_size=test_size,\n",
    "                random_state=random_state\n",
    "            )\n",
    "        \n",
    "            try:\n",
    "                # Train tree-based model predicting log1p(height)\n",
    "                ridge = RandomForestRegressor(\n",
    "                    n_estimators=200,\n",
    "                    max_depth=15,\n",
    "                    min_samples_leaf=5,\n",
    "                    min_samples_split=10,\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                ).fit(X_tr, ytr)\n",
    "        \n",
    "                # Predict on holdout\n",
    "                logpred = ridge.predict(X_te)\n",
    "                pred_cm = np.expm1(logpred)\n",
    "                yte_cm = np.expm1(yte)\n",
    "        \n",
    "                # Compute metrics\n",
    "                rmse_r = float(np.sqrt(mean_squared_error(yte_cm, pred_cm)))\n",
    "                mae_r  = float(mean_absolute_error(yte_cm, pred_cm))\n",
    "        \n",
    "                # Weighted RÂ² requires a target-type â†’ use dummy GDM_g\n",
    "                target_names_test = np.array(['GDM_g'] * len(yte_cm))\n",
    "                r2_r = compute_weighted_r2_metric(pred_cm, yte_cm, target_names_test)\n",
    "        \n",
    "                # Save model into class\n",
    "                self.height_model = ridge\n",
    "                self.height_model_type = 'log1p'\n",
    "        \n",
    "                # Store metrics and the model object (so propagation can find it)\n",
    "                results['ridge'] = {\n",
    "                    'model': ridge,\n",
    "                    'rmse': rmse_r,\n",
    "                    'mae': mae_r,\n",
    "                    'r2':  r2_r,\n",
    "                    'height_model_type': 'log1p'\n",
    "                }\n",
    "                results['_ridge_model_obj'] = ridge\n",
    "        \n",
    "                # Persist artifacts to disk\n",
    "                try:\n",
    "                    import joblib, json, os\n",
    "                    out_dir = OUTPUTS_DIR if isinstance(OUTPUTS_DIR, Path) else Path(OUTPUTS_DIR)\n",
    "                    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    # powerlaw\n",
    "                    pl_path = out_dir / \"height_powerlaw.json\"\n",
    "                    json.dump({'a': float(a), 'b': float(b)}, pl_path.open(\"w\"))\n",
    "                    # ridge model\n",
    "                    ridge_path = out_dir / \"height_ridge.joblib\"\n",
    "                    joblib.dump(ridge, ridge_path)\n",
    "                    logger.info(f\"Saved height calibration artifacts to {out_dir}\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Failed to save height calibration artifacts: {e}\")\n",
    "        \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Ridge model fitting failed: {e}\")\n",
    "                results['ridge'] = None\n",
    "                # ensure we don't leave partial model refs\n",
    "                results.pop('_ridge_model_obj', None)\n",
    "        \n",
    "        # Final logging (powerlaw + ridge summary)\n",
    "        powerlaw_rmse = results.get('powerlaw', {}).get('rmse', float('nan'))\n",
    "        logger.info(\n",
    "            f\"Calibrated powerlaw: a={a:.4f}, b={b:.4f} \"\n",
    "            f\"(trained on {len(df_gt)} samples). Powerlaw test RMSE={powerlaw_rmse:.3f}\"\n",
    "        )\n",
    "        \n",
    "        if results.get('ridge'):\n",
    "            logger.info(\n",
    "                f\"Trained Ridge (log-target) test RMSE={results['ridge']['rmse']:.3f}, \"\n",
    "                f\"RÂ²={results['ridge']['r2']:.4f}\"\n",
    "            )\n",
    "        \n",
    "        results['_source_dataset'] = self\n",
    "        return results\n",
    "\n",
    "\n",
    "def create_data_loaders(train_df, test_df, lookups_dict, TOTAL_TABULAR_DIM, model=None):\n",
    "    \"\"\"\n",
    "    Create training, validation, and test data loaders with patch-based processing.\n",
    "    Integrates intelligent TARGET-SPECIFIC test feature fetching.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader, train_split_df, val_split_df)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"CREATING DATA LOADERS WITH INTELLIGENT TEST FEATURE FETCHING\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    # STEP 1: SPLIT DATA\n",
    "    logger.info(\"\\nStep 1: Train/Val Split\")\n",
    "    \n",
    "    train_df['image_id'] = train_df['sample_id'].fillna('').astype(str).str.split('__').str[0]\n",
    "    unique_images = train_df[['image_id', 'image_path']].drop_duplicates()\n",
    "    n_unique = len(unique_images)\n",
    "    \n",
    "    # Split by image (not by row!)\n",
    "    train_images, val_images = train_test_split(\n",
    "        unique_images,\n",
    "        test_size=CONFIG['val_split'],\n",
    "        random_state=CONFIG['random_seed']\n",
    "    )\n",
    "    \n",
    "    train_split_df = train_df[\n",
    "        train_df['image_id'].isin(train_images['image_id'])\n",
    "    ].reset_index(drop=True)\n",
    "    \n",
    "    val_split_df = (\n",
    "        train_df[train_df['image_id'].isin(val_images['image_id'])]   \n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    logger.info(f\"  Total unique images: {n_unique}\")\n",
    "    logger.info(f\"  Training: {len(train_images)} images â†’ {len(train_split_df)} rows\")\n",
    "    logger.info(f\"    After cropping: {len(train_split_df) * 8} patches\")\n",
    "    logger.info(f\"  Validation: {len(val_images)} images â†’ {len(val_split_df)} rows\")\n",
    "    logger.info(f\"    After cropping: {len(val_split_df) * 8} patches\")\n",
    "    \n",
    "    # STEP 2: DEFINE TRANSFORMS\n",
    "    logger.info(\"\\nStep 2: Defining Transforms\")\n",
    "\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        # PIL Image transforms (BEFORE ToTensor)\n",
    "        transforms.RandomHorizontalFlip(p=0.7),\n",
    "        transforms.RandomVerticalFlip(p=0.7),\n",
    "        transforms.RandomRotation(60),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=45,\n",
    "            translate=(0.25, 0.25),\n",
    "            scale=(0.7, 1.3),\n",
    "            shear=20\n",
    "        ),\n",
    "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "        \n",
    "        # Lighting conditions\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.6,\n",
    "            contrast=0.6,\n",
    "            saturation=0.5,\n",
    "            hue=0.15\n",
    "        ),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        \n",
    "        # Normalize (tensor transform)\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        \n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 3.0)),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "    ])\n",
    "\n",
    "    \n",
    "    val_test_transform = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # STEP 3: CREATE DATASETS\n",
    "    logger.info(\"\\nStep 3: Creating Datasets with Intelligent Test Feature Fetching\")\n",
    "    \n",
    "    train_dataset = BiomassDataset(\n",
    "        train_split_df,\n",
    "        RAW_DATA_DIR / 'train',\n",
    "        transform=train_transform,\n",
    "        mode='train',\n",
    "        train_df=train_split_df,\n",
    "        lookups_dict=lookups_dict\n",
    "    )\n",
    "    \n",
    "    val_dataset = BiomassDataset(\n",
    "        val_split_df,\n",
    "        RAW_DATA_DIR / 'train',\n",
    "        transform=val_test_transform,\n",
    "        mode='val',\n",
    "        train_df=train_df,\n",
    "        lookups_dict=lookups_dict\n",
    "    )\n",
    "    \n",
    "    test_dataset = BiomassDataset(\n",
    "        test_df,\n",
    "        RAW_DATA_DIR / 'test',\n",
    "        transform=val_test_transform,\n",
    "        mode='test',\n",
    "        train_df=train_df, \n",
    "        lookups_dict=lookups_dict,\n",
    "        species_model = model,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    # --- QUICK SANITY CHECK: total tabular dim consistent with lookups ---\n",
    "    try:\n",
    "        numeric_cols = lookups_dict.get(\"TAB_NUMERIC_COLS\", [])\n",
    "        STATE_COLS = lookups_dict.get(\"STATE_COLS\", [])\n",
    "        SPECIES_COLS = lookups_dict.get(\"SPECIES_COLS\", [])\n",
    "        TARGET_TYPE_COLS = lookups_dict.get(\"TARGET_TYPE_COLS\", [])\n",
    "        calc = len(numeric_cols) + len(STATE_COLS) + len(SPECIES_COLS) + len(TARGET_TYPE_COLS)\n",
    "        if calc != TOTAL_TABULAR_DIM:\n",
    "            logger.warning(f\"TOTAL_TABULAR_DIM mismatch: computed={calc}, declared={TOTAL_TABULAR_DIM}\")\n",
    "        else:\n",
    "            logger.info(\"TOTAL_TABULAR_DIM consistent\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"TOTAL_TABULAR_DIM sanity check failed: {e}\")\n",
    "\n",
    "    logger.info(f\"  âœ“ Train dataset: {len(train_dataset)} rows\")\n",
    "    logger.info(f\"  âœ“ Val dataset: {len(val_dataset)} rows\")\n",
    "    \n",
    "    # --- Calibrate height model on training dataset and propagate to val/test ---\n",
    "    logger.info(\"Calibrating height estimator using train dataset features...\")\n",
    "    \n",
    "    # Create a static flag on the function to ensure ONE-TIME calibration\n",
    "    if not hasattr(create_data_loaders, \"_height_calibrated_once\"):\n",
    "        create_data_loaders._height_calibrated_once = False\n",
    "    \n",
    "    calib_res = None\n",
    "    def _propagate_calibration(dst_dataset, calib_res):\n",
    "        \"\"\"Copy fitted artifacts onto dataset instance (powerlaw a,b and ridge model).\"\"\"\n",
    "        if calib_res is None:\n",
    "            return\n",
    "        # powerlaw\n",
    "        pl = calib_res.get('powerlaw')\n",
    "        if pl and 'a' in pl and 'b' in pl:\n",
    "            setattr(dst_dataset, 'height_a', float(pl['a']))\n",
    "            setattr(dst_dataset, 'height_b', float(pl['b']))\n",
    "    \n",
    "        # ridge/model: check several possible locations\n",
    "        ridge_info = calib_res.get('ridge', {}) or {}\n",
    "        model_obj = ridge_info.get('model', None) or calib_res.get('_ridge_model_obj', None)\n",
    "    \n",
    "        # if still None, try to read from train_dataset attr (if calib_res came from that instance)\n",
    "        if model_obj is None:\n",
    "            try:\n",
    "                src = calib_res.get('_source_dataset', None)\n",
    "                if src is not None and hasattr(src, 'height_model') and getattr(src, 'height_model', None) is not None:\n",
    "                    model_obj = getattr(src, 'height_model')\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "        if model_obj is not None:\n",
    "            try:\n",
    "                setattr(dst_dataset, 'height_model', model_obj)\n",
    "                # prefer explicit type if present\n",
    "                ht = ridge_info.get('height_model_type') or calib_res.get('height_model_type') or getattr(model_obj, 'height_model_type', None)\n",
    "                if ht:\n",
    "                    setattr(dst_dataset, 'height_model_type', ht)\n",
    "                else:\n",
    "                    # fallback default\n",
    "                    setattr(dst_dataset, 'height_model_type', 'log1p')\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"_propagate_calibration: failed to set height_model: {e}\")\n",
    "\n",
    "    \n",
    "    # ====== CASE A: First call â†’ run calibration ======\n",
    "    if not create_data_loaders._height_calibrated_once:\n",
    "    \n",
    "        try:\n",
    "            calib_res = train_dataset.calibrate_height_model(\n",
    "                image_col='image_path',\n",
    "                height_col='Height_Ave_cm',\n",
    "                test_size=0.2,\n",
    "                random_state=CONFIG.get('random_seed', 42),\n",
    "                min_positive_samples=5,\n",
    "                fit_ridge=True,\n",
    "                ridge_alphas=(0.01, 0.1, 1.0, 10.0)\n",
    "            )\n",
    "            logger.info(f\"Calibration results: {calib_res.get('powerlaw')}\")\n",
    "            if calib_res.get('ridge') is not None:\n",
    "                logger.info(f\"  Ridge test RMSE: {calib_res['ridge']['rmse']:.3f}\")\n",
    "    \n",
    "            # mark as done so we NEVER run this again\n",
    "            create_data_loaders._height_calibrated_once = True\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Height calibration failed: {e}\")\n",
    "            calib_res = None\n",
    "    \n",
    "    # ====== CASE B: Later calls â†’ load stored calibration only ======\n",
    "    else:\n",
    "        logger.info(\"âœ“ Skipping height calibration (already performed once).\")\n",
    "        # Attempt to load saved calibration if available\n",
    "        try:\n",
    "            import json, joblib\n",
    "            calib_res = {}\n",
    "            out_dir = OUTPUTS_DIR if isinstance(OUTPUTS_DIR, Path) else Path(OUTPUTS_DIR)\n",
    "            pl_path = out_dir / \"height_powerlaw.json\"\n",
    "            ridge_path = out_dir / \"height_ridge.joblib\"\n",
    "    \n",
    "            if pl_path.exists():\n",
    "                try:\n",
    "                    calib_res['powerlaw'] = json.loads(pl_path.read_text())\n",
    "                    logger.info(\"Loaded saved powerlaw calibration from disk.\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Failed to read powerlaw json: {e}\")\n",
    "    \n",
    "            if ridge_path.exists():\n",
    "                try:\n",
    "                    ridge_model = joblib.load(ridge_path)\n",
    "                    calib_res['ridge'] = {'model': ridge_model, 'height_model_type': 'log1p'}\n",
    "                    logger.info(\"Loaded saved ridge calibration from disk.\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Failed to load ridge model: {e}\")\n",
    "    \n",
    "            # If loaded nothing, leave calib_res None to maintain previous behavior\n",
    "            if not calib_res:\n",
    "                calib_res = None\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Failed loading saved calibration: {e}\")\n",
    "            calib_res = None\n",
    "\n",
    "    # Always propagate whatever calibration we have\n",
    "    _propagate_calibration(train_dataset, calib_res)\n",
    "    _propagate_calibration(val_dataset, calib_res)\n",
    "    _propagate_calibration(test_dataset, calib_res)\n",
    "    \n",
    "    \n",
    "    # Quick sanity checks\n",
    "    try:\n",
    "        logger.info(\"Sanity check - sample calibrated heights:\")\n",
    "        sample_img_path = train_dataset.df.iloc[0]['image_path']\n",
    "        img = train_dataset._load_image(sample_img_path)\n",
    "        h_train = train_dataset.estimate_height_final(np.array(img))\n",
    "        logger.info(f\"  sample train estimated height: {h_train} cm\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Sanity check train failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        sample_img_path = test_dataset.df.iloc[0]['image_path']\n",
    "        img = test_dataset._load_image(sample_img_path)\n",
    "        h_test = test_dataset.estimate_height_final(np.array(img))\n",
    "        logger.info(f\"  sample test estimated height: {h_test} cm\")\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Sanity check test failed: {e}\")\n",
    "\n",
    "\n",
    "    def collate_patches(batch):\n",
    "        \"\"\"\n",
    "        Collate function for patch-based dataset.\n",
    "        \n",
    "        Input batch items (7 elements):\n",
    "            (images, tabular, species_idx, target_idx, target, sample_id, target_name)\n",
    "        \n",
    "        Returns:\n",
    "            (images_batch, tabular_batch, species_batch, target_idx_batch, targets_batch, \n",
    "             sample_ids, target_names)\n",
    "        \"\"\"\n",
    "        PATCHES_PER_IMAGE = 8\n",
    "        C, H, W = 3, 224, 224\n",
    "    \n",
    "        # detect TAB_DIM\n",
    "        TAB_DIM = None\n",
    "        for item in batch:\n",
    "            try:\n",
    "                tab = item[1]\n",
    "                TAB_DIM = tab.shape[-1]\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "        if TAB_DIM is None:\n",
    "            TAB_DIM = 30  # default for meta-learner\n",
    "    \n",
    "        sentinel_images = torch.zeros((PATCHES_PER_IMAGE, C, H, W))\n",
    "        sentinel_tab = torch.zeros((PATCHES_PER_IMAGE, TAB_DIM))\n",
    "        sentinel_target = torch.tensor(0.0)\n",
    "        sentinel_target_idx = torch.tensor(0, dtype=torch.long)\n",
    "    \n",
    "        per_sample_images = []\n",
    "        per_sample_tabular = []\n",
    "        per_sample_species = []\n",
    "        per_sample_target_idx = []  # NEW: store target_idx per sample\n",
    "        per_sample_targets = []\n",
    "        per_sample_sample_ids = []\n",
    "        per_sample_target_names = []\n",
    "    \n",
    "        # parse batch items safely and collect per-sample scalars\n",
    "        for item in batch:\n",
    "            try:\n",
    "                # Handle 7-item return (NEW FORMAT with target_idx)\n",
    "                if len(item) == 7:\n",
    "                    images, tabular, species, target_idx, target, sample_id, target_name = item\n",
    "                # Handle 6-item return (OLD FORMAT - backward compat)\n",
    "                elif len(item) == 6:\n",
    "                    images, tabular, species, target, sample_id, target_name = item\n",
    "                    target_idx = 0  # default fallback\n",
    "                # Handle 5-item return (even older format - backward compat)\n",
    "                elif len(item) == 5:\n",
    "                    images, tabular, target, sample_id, target_name = item\n",
    "                    species = None\n",
    "                    target_idx = 0\n",
    "                else:\n",
    "                    # flexible fallback\n",
    "                    images = item[0] if len(item) > 0 else sentinel_images.clone()\n",
    "                    tabular = item[1] if len(item) > 1 else sentinel_tab.clone()\n",
    "                    species = item[2] if len(item) > 2 else None\n",
    "                    target_idx = item[3] if len(item) > 3 else 0  # NEW: try to get from position 3\n",
    "                    target = item[4] if len(item) > 4 else None\n",
    "                    sample_id = item[-2] if len(item) >= 2 else \"None\"\n",
    "                    target_name = item[-1] if len(item) >= 1 else \"None\"\n",
    "    \n",
    "                sample_id = \"None\" if sample_id is None else sample_id\n",
    "                target_name = \"None\" if target_name is None else target_name\n",
    "    \n",
    "                # ensure images shape = (PATCHES_PER_IMAGE, C, H, W)\n",
    "                if not (isinstance(images, torch.Tensor) and images.ndim == 4 and images.size(0) == PATCHES_PER_IMAGE):\n",
    "                    logger.warning(f\"[collate] BAD IMAGES for sample {sample_id} -> shape={getattr(images, 'shape', None)}; using sentinel\")\n",
    "                    images = sentinel_images.clone()\n",
    "    \n",
    "                # ensure tabular shape = (PATCHES_PER_IMAGE, TAB_DIM) or (TAB_DIM,) (convert)\n",
    "                if isinstance(tabular, torch.Tensor) and tabular.ndim == 1:\n",
    "                    tabular = tabular.unsqueeze(0).repeat(PATCHES_PER_IMAGE, 1)\n",
    "                if not (isinstance(tabular, torch.Tensor) and tabular.ndim == 2 and tabular.size(0) == PATCHES_PER_IMAGE):\n",
    "                    logger.warning(f\"[collate] BAD TABULAR for sample {sample_id} -> shape={getattr(tabular, 'shape', None)}; using sentinel\")\n",
    "                    tabular = sentinel_tab.clone()\n",
    "    \n",
    "                per_sample_images.append(images)\n",
    "                per_sample_tabular.append(tabular)\n",
    "                per_sample_species.append(species)\n",
    "                \n",
    "                # NEW: Store target_idx (convert to tensor if needed)\n",
    "                if isinstance(target_idx, torch.Tensor):\n",
    "                    per_sample_target_idx.append(target_idx.long())\n",
    "                else:\n",
    "                    per_sample_target_idx.append(torch.tensor(int(target_idx), dtype=torch.long))\n",
    "    \n",
    "                # store one scalar or None\n",
    "                if target is None:\n",
    "                    per_sample_targets.append(None)\n",
    "                else:\n",
    "                    # ensure scalar float tensor\n",
    "                    t = torch.tensor(float(target), dtype=torch.float32) if not isinstance(target, torch.Tensor) else target.float().reshape(())\n",
    "                    per_sample_targets.append(t)\n",
    "    \n",
    "                per_sample_sample_ids.append(str(sample_id))\n",
    "                per_sample_target_names.append(str(target_name))\n",
    "    \n",
    "            except Exception as e:\n",
    "                logger.exception(f\"[collate] EXCEPTION parsing sample -> {e}\")\n",
    "                per_sample_images.append(sentinel_images.clone())\n",
    "                per_sample_tabular.append(sentinel_tab.clone())\n",
    "                per_sample_species.append(None)\n",
    "                per_sample_target_idx.append(sentinel_target_idx.clone())  # NEW: add sentinel\n",
    "                per_sample_targets.append(sentinel_target)\n",
    "                per_sample_sample_ids.append(\"None\")\n",
    "                per_sample_target_names.append(\"None\")\n",
    "    \n",
    "        # Now expand per-sample -> per-patch deterministically\n",
    "        images_batch = torch.cat(per_sample_images, dim=0)          # shape (B*P, C, H, W)\n",
    "        tabular_batch = torch.cat(per_sample_tabular, dim=0)       # shape (B*P, TAB_DIM)\n",
    "    \n",
    "        # species batch: convert to tensor if all ints else keep list\n",
    "        species_is_int = all((x is None) or isinstance(x, (int, np.integer, torch.Tensor)) for x in per_sample_species)\n",
    "        if species_is_int:\n",
    "            clean_species = []\n",
    "            for x in per_sample_species:\n",
    "                if x is None:\n",
    "                    clean_species.append(0)\n",
    "                elif isinstance(x, torch.Tensor):\n",
    "                    clean_species.append(int(x.item()))\n",
    "                else:\n",
    "                    clean_species.append(int(x))\n",
    "            species_batch = torch.tensor(clean_species, dtype=torch.long)\n",
    "        else:\n",
    "            species_batch = [None if x is None else x for x in per_sample_species]\n",
    "    \n",
    "        # NEW: target_idx_batch (repeat per patch, per sample)\n",
    "        target_idx_list = []\n",
    "        for tidx in per_sample_target_idx:\n",
    "            # Each sample's target_idx repeated PATCHES_PER_IMAGE times\n",
    "            tidx_val = tidx.item() if isinstance(tidx, torch.Tensor) else int(tidx)\n",
    "            target_idx_list.extend([tidx_val] * PATCHES_PER_IMAGE)\n",
    "        target_idx_batch = torch.tensor(target_idx_list, dtype=torch.long)\n",
    "    \n",
    "        # Build targets_list (per patch) from per_sample_targets to avoid accidental length mismatch\n",
    "        targets_list = []\n",
    "        for t in per_sample_targets:\n",
    "            if t is None:\n",
    "                # keep no-target marker (we use None > caller expects None for test)\n",
    "                targets_list.extend([None] * PATCHES_PER_IMAGE)\n",
    "            else:\n",
    "                targets_list.extend([t] * PATCHES_PER_IMAGE)\n",
    "    \n",
    "        # sample_ids and target_names repeated per patch\n",
    "        sample_ids = []\n",
    "        target_names = []\n",
    "        for sid, tn in zip(per_sample_sample_ids, per_sample_target_names):\n",
    "            sample_ids.extend([sid] * PATCHES_PER_IMAGE)\n",
    "            target_names.extend([tn] * PATCHES_PER_IMAGE)\n",
    "    \n",
    "        # Final alignment checks & conversions\n",
    "        expected_len = len(batch) * PATCHES_PER_IMAGE\n",
    "        assert images_batch.size(0) == expected_len, f\"images length {images_batch.size(0)} != expected {expected_len}\"\n",
    "        assert tabular_batch.size(0) == expected_len, f\"tabular length {tabular_batch.size(0)} != expected {expected_len}\"\n",
    "        assert target_idx_batch.size(0) == expected_len, f\"target_idx length {target_idx_batch.size(0)} != expected {expected_len}\"  # NEW\n",
    "        assert len(sample_ids) == expected_len, f\"sample_ids length {len(sample_ids)} != expected {expected_len}\"\n",
    "        assert len(target_names) == expected_len, f\"target_names length {len(target_names)} != expected {expected_len}\"\n",
    "        assert len(targets_list) == expected_len, f\"targets_list length {len(targets_list)} != expected {expected_len}\"\n",
    "    \n",
    "        # If we have no targets (test mode -> all targets None) return None target batch\n",
    "        if all(t is None for t in targets_list):\n",
    "            # NEW: return 7 items including target_idx_batch\n",
    "            return images_batch, tabular_batch, species_batch, target_idx_batch, None, sample_ids, target_names\n",
    "    \n",
    "        # else convert targets_list (some elements may be torch tensors already)\n",
    "        targ_tensors = []\n",
    "        for t in targets_list:\n",
    "            if t is None:\n",
    "                targ_tensors.append(torch.tensor(0.0))   # sentinel for safety (shouldn't happen in train/val)\n",
    "            elif isinstance(t, torch.Tensor) and t.numel() == 1:\n",
    "                targ_tensors.append(t.reshape(()))\n",
    "            else:\n",
    "                targ_tensors.append(torch.tensor(float(t), dtype=torch.float32))\n",
    "        targets_batch = torch.stack(targ_tensors, dim=0).float()\n",
    "    \n",
    "        # NEW: return 7 items including target_idx_batch\n",
    "        return images_batch, tabular_batch, species_batch, target_idx_batch, targets_batch, sample_ids, target_names\n",
    "\n",
    "\n",
    "    # STEP 5: CREATE DATALOADERS\n",
    "    logger.info(\"\\nStep 5: Creating DataLoaders\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=CONFIG['pin_memory'],\n",
    "        collate_fn=collate_patches,\n",
    "        drop_last=True \n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=CONFIG['pin_memory'],\n",
    "        collate_fn=collate_patches,\n",
    "        drop_last=True \n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=CONFIG['pin_memory'],\n",
    "        collate_fn=collate_patches,\n",
    "        drop_last=False \n",
    "    )\n",
    "    \n",
    "    logger.info(f\"  âœ“ Train loader: {len(train_loader)} batches\")\n",
    "    logger.info(f\"  âœ“ Val loader: {len(val_loader)} batches\")\n",
    "    logger.info(f\"  âœ“ Test loader: {len(test_loader)} batches\")\n",
    "    logger.info(f\"\\n  Batch size: {CONFIG['batch_size']} images\")\n",
    "    logger.info(f\"  Per batch: {CONFIG['batch_size']} images Ã— 8 patches = {CONFIG['batch_size']*8} patches\")\n",
    "    logger.info(f\"  Batch shapes:\")\n",
    "    logger.info(f\"    - images: [{CONFIG['batch_size']*8}, 3, 224, 224]\")\n",
    "    logger.info(f\"    - tabular: [{CONFIG['batch_size']*8}, {TOTAL_TABULAR_DIM}]\")\n",
    "    logger.info(f\"    - targets: [{CONFIG['batch_size']*8}]\")\n",
    "    logger.info(\"\\nâœ“ Data loaders created successfully!\")\n",
    "    logger.info(\"  âœ“ Test feature fetching: TARGET-SPECIFIC at ALL LEVELS\")\n",
    "    logger.info(\"  âœ“ Patches per image: 8 (4Ã—2 grid from 2000Ã—1000 images)\")\n",
    "    logger.info(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_split_df, val_split_df\n",
    "\n",
    "logger.info(\"âœ“ Data Augmentation and Preparation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e67d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
